{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to tensorflow\n",
    "\n",
    "In this tutorial we are going to learn the essentials of `tensorflow` which is a Python Machine Learning library which is particularly suitable for building neural networks.\n",
    "\n",
    "This tutorial is based on the tutorial by [Alexey Ozerin](https://github.com/m12sl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "We will be using `tensorflow` for CPU, version 1.3 or above. It can be installed with the following command:\n",
    "```\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "You can use other ways of installing TF, see the [official website](https://www.tensorflow.org/install/)\n",
    "\n",
    "## Tutorial plan\n",
    "\n",
    "1. [Intro](#Intro)\n",
    "2. [Graphs and sessions](#Graph-and-Session)\n",
    "3. [Variables](#Variables)\n",
    "4. [Exercises on tensor operations](#Exercises)\n",
    "5. [Linear regression](#Linear-regression)\n",
    "6. [MNIST classification](#MNIST-classification)\n",
    "7. [\\*Extra task - Variable scopes](#*Extra-task)\n",
    "\n",
    "\n",
    "TF is a tool for machine learning. It supports automatic differentiation and is capable of working on distributed systems. \n",
    "\n",
    "[Tensorboard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard) - package for monitoring your model's parameters.\n",
    "\n",
    "[Tensorflow Hub](https://www.tensorflow.org/hub/) - a set of pre-trained models.\n",
    "\n",
    "This notebook has a couple of exercises. We recommend doing them on your own to get a grasp of TF. We also strongly advise to run cells with different parameters and variations in code -- this will help you to get used to TF faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Let's first recall `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2.]\n",
      "[[2. 3.]\n",
      " [2. 3.]]\n",
      "(2, 2)\n",
      "[[0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.zeros((2, 2))\n",
    "b = np.ones((2, 2))\n",
    "c = np.array([1,2])\n",
    "\n",
    "print(np.sum(b, axis=1))\n",
    "print(b + c)\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "print(np.reshape(a, (1, 4)))\n",
    "print(np.reshape(a, (-1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do the same in `tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x1821b31410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.InteractiveSession()  # We'll discuss sessions later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objects `a`, `b`, and `c` are instances of `tf.constant` (i.e. their values cannot change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.zeros((2, 2))\n",
    "b = tf.ones((2, 2))\n",
    "c = tf.constant([1,2], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assigned values to `a`, `b`, and `c` -- they are now a part of our computational graph (althought there are no connections between them).\n",
    "\n",
    "Try checking their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"a\": ', <tf.Tensor 'zeros:0' shape=(2, 2) dtype=float32>)\n",
      "('\"b\": ', <tf.Tensor 'ones:0' shape=(2, 2) dtype=float32>)\n",
      "('\"c\": ', <tf.Tensor 'Const:0' shape=(2,) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print('\"a\": ', a)\n",
    "print('\"b\": ', b)\n",
    "print('\"c\": ', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not get the values, but only types of the objects. That is because in order to get a value of any node in a TF graph you should execute the graph.\n",
    "\n",
    "The execution is done with eval() command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Value of \"a\": ', array([[0., 0.],\n",
      "       [0., 0.]], dtype=float32))\n",
      "('Value of \"b\": ', array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32))\n",
      "('Value of \"c\": ', array([1., 2.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print('Value of \"a\": ', a.eval())\n",
    "print('Value of \"b\": ', b.eval())\n",
    "print('Value of \"c\": ', c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create more complicated nodes that require actual computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2.]\n",
      "[[2. 3.]\n",
      " [2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_sum(b, axis=1).eval())  # don't forget about eval()\n",
    "print(tf.add(b, c).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, operations on `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "[[0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# This is not an operation on graph - it just gets the information about the node,\n",
    "# so we don't need eval()\n",
    "print(a.get_shape())\n",
    "\n",
    "# These operations change the node, though\n",
    "print(tf.reshape(a, (1, 4)).eval())\n",
    "print(tf.reshape(a, (-1, 4)).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph and Session\n",
    "\n",
    "There are essential objects in TF which have to appear in any code that uses TF - these are `Session` and `Graph`. In the above code we used them implicitly, let's now look into them in more detail.\n",
    "\n",
    "### Graph\n",
    "\n",
    "A computational graph is a network of nodes, with each node representing an arithmetic operation.\n",
    "For example, let's consider the following code:\n",
    "```\n",
    "a = tf.constant(1)\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "```\n",
    "The computational graph will look as follows:\n",
    "<img src=\"graph_example.png\" style=\"width: 400px\">\n",
    "\n",
    "The actuall TF graphs look different because of TF internal operations, but the idea is the same.\n",
    "\n",
    "Note that all constants and variables that you define are added to graph, even if you don't define the graph object explicitly. In this case they are saved in `default graph`. You can get the access to your graph with procedure `tf.get_default_graph()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save the graph with the following line of code\n",
    "file_writer = tf.summary.FileWriter('/Users/yaroina-kente/just-initial/', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FileWriter object writes all information about your TF graph (graph itself, values of variables, etc.) in a file. You should provide a directory to save the information, and the graph to save.\n",
    "\n",
    "After running the above cell you'll be able to see the graph using `tensorboard` tool you should go to the directory of this notebook and run the following command in shell:\n",
    "```\n",
    "tensorboard --logdir=./\n",
    "```\n",
    "and then open the page http://localhost:6006 in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session\n",
    "\n",
    "Building of a graph does not automatically execute it. In order to get the values of nodes you should compute your graph in a `Session`. `Session` creates an environment to execute a graph, you can't do it outside a session.\n",
    "\n",
    "The method `run()` of a session performs computations. It has one required element -- a node to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones(5)\n",
    "with tf.Session() as session:\n",
    "    print(session.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike `Graph`, `Session` is not defined implicitly. There is a function `tf.get_default_session()`, but you need to specify which `Session` you will use as default.\n",
    "In iPython it is convenient to use `InteractiveSession` object (as we did above). If an instance of the `InteractiveSession` class has been created, it is treated as a default session. If you have an `InteractiveSession`, you can use `eval()` procedure in your code which is in fact equivalent to \n",
    "\n",
    "```tf.get_default_session().run()```\n",
    "\n",
    "**NB**: In notebooks it is easier to use `InteractiveSession`, but it is not recommended in scripts. There, you  should separate building of the graph from computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul_1:0\", shape=(), dtype=float32)\n",
      "-6.0\n",
      "-6.0\n"
     ]
    }
   ],
   "source": [
    "# let's recap different ways of evaluating nodes of a graph\n",
    "a = tf.constant(-2.0)\n",
    "b = tf.constant(3.0)\n",
    "c = a * b\n",
    "\n",
    "# let's create a session explicitly\n",
    "with tf.Session() as sess:\n",
    "    print(c)              # print the name of a node in the graph\n",
    "    print(sess.run(c))    # compute the node and print the result\n",
    "    print(c.eval())       # another way of computing the node\n",
    "\n",
    "# the graph is saved, you can look at it using `tensorboard`\n",
    "file_writer = tf.summary.FileWriter('./second-try', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - arithmetic operations\n",
    "\n",
    "Let's now practice in using `tensorflow` for basic computations. \n",
    "\n",
    "You decided to put $10000 in your bank for 2 years. The bank has a fixed deposit plan with an interest rate of 3%. This means that the sum of money that bank returns you is computed according to the following formula:\n",
    "\n",
    "$$return = initial \\times (1+interest)^{years}$$\n",
    "\n",
    "Use tensorflow arithmetic operations to compute the sum you will have on your account in 2 years.\n",
    "\n",
    "**NB**: don't forget to declare the data types of tensors. Types assigned by default can lead to an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10609.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "####Your code here#####\n",
    "\n",
    "i = tf.constant(10000.0)\n",
    "rate = tf.constant(0.03)\n",
    "years = tf.constant(2.0)\n",
    "\n",
    "r = i*((1+rate)**years)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(r.eval()) \n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check yourself: you should get `10609.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "So far we experimented only with constant tensors - they can be created using functions `tf.Tensor()`, `tf.constant()`, `tf.zeros()`, etc. They don't save values between runs of a graph - which means that you can't use them to store weights of our model, accumulated statistics and other information that you need to save between runs.\n",
    "\n",
    "For that we will use `Variable` objects.\n",
    "\n",
    "`Variable` constructor accepts constant of any type. An important difference between `Variable` and `constant` is that variable requires initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # reset the graph\n",
    "\n",
    "W1 = tf.ones((2, 2))  # a 2x2 tensor of ones\n",
    "#W2 = tf.Variable(tf.zeros((2, 2)), name='weights')\n",
    "W2 = tf.get_variable('weights', shape = (2,2), initializer = tf.zeros_initializer())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(W1))\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # initialises all Variables, try running the code without it\n",
    "    print(sess.run(W2))\n",
    "    \n",
    "# check the graph for variables\n",
    "file_writer = tf.summary.FileWriter('./vars', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of creating a `Variable` is to call `tf.get_variable()`. It is called as follows:\n",
    "```\n",
    "var = tf.get_variable('my_var', shape=(3,4), initializer=tf.random_normal_initializer())\n",
    "```\n",
    "The first argument is variable name. \n",
    "\n",
    "The difference between `tf.get_variable` and `Variable` constructor is that you need to pass the initial value of a variable to the constructor, whereas when using `tf.get_variable` you need to define variable shape and the way of initializing it (e.g. from the normal distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Change the above code so that variable `W2` is created with the function `tf.get_variable`.\n",
    "\n",
    "**NB:** you can use `tf.zeros_initializer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a graph multiple times\n",
    "\n",
    "Once we have `Variables` which save values between the runs, we can try computing a graph multiple times.\n",
    "\n",
    "All the computations in a graph should be organised differently from how you would do it in regular Python code.\n",
    "\n",
    "This is an example of making a counter in a graph to count the number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # try commenting out and running the cell multiple times\n",
    "                         # what happens with the computational graph?\n",
    "\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "new_value = tf.add(state, tf.constant(1))\n",
    "\n",
    "update_op = tf.assign(state, new_value)   # state <- new_value\n",
    "\n",
    "file_writer = tf.summary.FileWriter('./counter', tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(state.eval())\n",
    "    \n",
    "    for i in range(10):\n",
    "        sess.run(update_op)\n",
    "        print(state.eval())\n",
    "        \n",
    "file_writer = tf.summary.FileWriter('./counter', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Recall the task about the bank deposit. You put \\$10000 in your bank, and the amout of money you have is computed as $return = initial \\times (1+interest)^{years}$. You want to compute how much money you will have in 1, 2, 3, ..., 20 years. You can now do that in `tensorflow` using one graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "10300.0\n",
      "2.0\n",
      "10609.0\n",
      "3.0\n",
      "10927.27\n",
      "4.0\n",
      "11255.087\n",
      "5.0\n",
      "11592.738\n",
      "6.0\n",
      "11940.521\n",
      "7.0\n",
      "12298.736\n",
      "8.0\n",
      "12667.697\n",
      "9.0\n",
      "13047.729\n",
      "10.0\n",
      "13439.16\n",
      "11.0\n",
      "13842.335\n",
      "12.0\n",
      "14257.604\n",
      "13.0\n",
      "14685.332\n",
      "14.0\n",
      "15125.891\n",
      "15.0\n",
      "15579.667\n",
      "16.0\n",
      "16047.057\n",
      "17.0\n",
      "16528.469\n",
      "18.0\n",
      "17024.322\n",
      "19.0\n",
      "17535.05\n",
      "20.0\n",
      "18061.104\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# define years as a Variable\n",
    "# define an operation to update the value of `years`\n",
    "# define other data in the same way as before.\n",
    "####Your code here####\n",
    "\n",
    "i = tf.constant(10000.0)\n",
    "rate = tf.constant(0.03)\n",
    "years = tf.Variable(0.0, name=\"years\")\n",
    "new_value = tf.add(years, tf.constant(1.0))\n",
    "\n",
    "update_op = tf.assign(years, new_value)\n",
    "r = i*((1+rate)**years)\n",
    "\n",
    "######################\n",
    "\n",
    "# and now compute the value in a loop\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(years.eval())\n",
    "    \n",
    "    for k in range(20):\n",
    "        ####Your code here####\n",
    "        sess.run(update_op)\n",
    "        print(years.eval())\n",
    "        print(r.eval())\n",
    "        ######################\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading external data\n",
    "\n",
    "`Variables` serve for changeable objects (e.g. model weights). We don't need them to store the input data, because it doesn't change.\n",
    "\n",
    "However, the graph is built before actual computations or loading the data. It means that we cannot use `constant` tensors for inputs. Instead of that we will use `placehoders`. They are tensors that can be placed in a graph without initialisation.\n",
    "\n",
    "When a graph has already been created, you can insert your data into a `placehoder` using `feed_dict`.\n",
    "\n",
    "`feed_dict` is a dictionary where keys are **placeholders** which you need to compute the node, and values are **data objects** you need to use instead of these placeholders.\n",
    "\n",
    "When defining a `placeholder` you need to define its type and shape. However, if you don't know some of the dimensions (e.g. size of your dataset), you can replace them with `None`:\n",
    "```\n",
    "my_input = tf.placeholder(tf.float32, (None, 5))\n",
    "```\n",
    "`my_input` is a matrix with 5 columns and unknown number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-40.0\n"
     ]
    }
   ],
   "source": [
    "# placeholders for vectors of unknown size\n",
    "inp1 = tf.placeholder(tf.float32, (None))\n",
    "inp2 = tf.placeholder(tf.float32, (None))\n",
    "\n",
    "out = inp1 * inp2\n",
    "\n",
    "# we first feed in single numbers\n",
    "with tf.Session() as sess:\n",
    "    feed_dict = {inp1: 10, inp2: -4}\n",
    "    print(sess.run(out, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -40.  100. 1000.]\n"
     ]
    }
   ],
   "source": [
    "# And now try arrays\n",
    "with tf.Session() as sess:\n",
    "    # make sure that the operation can be done on objects of given sizes\n",
    "    feed_dict = {inp1: np.array([10]), inp2: np.array([-4, 10, 100])}\n",
    "    print(sess.run(out, feed_dict=feed_dict))\n",
    "file_writer = tf.summary.FileWriter('./placeholders', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Recall the task about the bank deposit once again. Your friend asked you to compute the sum of money they will have at their account in 2 years. But your friend has a different initial sum of money. With `placeholders` you can now create a graph to compute the return value for different initial sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5304.5\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "rate = tf.constant(0.03)\n",
    "years = tf.constant(2.0)\n",
    "i = tf.placeholder(tf.float32, (None))\n",
    "\n",
    "r = i*((1+rate)**years)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    feed_dict = {i: 5000}\n",
    "    print(sess.run(r, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "\n",
    "Change your code so that you can vary all parameters: initial sum, interest rate, and number of years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10927.27\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "rate = tf.placeholder(tf.float32, (None)) \n",
    "years = tf.placeholder(tf.float32, (None))\n",
    "i = tf.placeholder(tf.float32, (None))\n",
    "\n",
    "r = i*((1+rate)**years)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    feed_dict = {i: 10000, rate: 0.03, years : 3}\n",
    "    print(sess.run(r, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "In order to familiarise yourself with tensor operations in TF we suggest you reading help about the following  functions:\n",
    "\n",
    "**hint: use `<func_name>?` command in a new cell to get help on function `<func_name>` in iPython***\n",
    "\n",
    "```\n",
    "tf.cond\n",
    "tf.greater\n",
    "tf.case\n",
    "tf.equal\n",
    "tf.where\n",
    "tf.gather\n",
    "tf.range\n",
    "tf.diag\n",
    "tf.matrix_determinant\n",
    "tf.unique\n",
    "```\n",
    "\n",
    "Below you'll find exercises that require using these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**. Example. Create two tensors `x` and `y` with values picked randomly from any distribution\n",
    "Create a tensor which contains `x + y` if `x > y` and `x - y` otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3705044\n",
      "0.7459717\n",
      "0.718709\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.random_uniform([])  # Empty array given as shape creates a scalar.\n",
    "y = tf.random_uniform([])\n",
    "\n",
    "out = tf.cond(tf.greater(x, y), lambda: x + y, lambda: x - y)\n",
    "print(sess.run(out))\n",
    "\n",
    "print(x.eval())\n",
    "print(y.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**. Create two tensors `x` and `y` which contain random values from \\[-1, 1\\).\n",
    "Create a tensor which contains `x + y` if `x < y`, `x - y` if `x > y` and `17` if `x == y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform:0\", shape=(), dtype=float32)\n",
      "0.2550707\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.random_uniform([], -1, 1, dtype=tf.float32)\n",
    "y = tf.random_uniform([], -1, 1, dtype=tf.float32)\n",
    "out = tf.case({tf.less(x, y): lambda: tf.add(x, y), \n",
    "        tf.greater(x, y): lambda: tf.subtract(x, y)}, \n",
    "        default=lambda: tf.constant(17.0), exclusive=True)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(sess.run(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task will help you to compute masks\n",
    "\n",
    "**3**. Create a tensor `x` which contains `[[0, -2, -1], [0, 1, 2]]` and a zero tensor `y` of the same shape as `x`. Compute a boolean tensor of the same shape as `x` and `y` with True values in places where values from `x` and `y` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False False]\n",
      " [ True False False]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.constant([[0.0,-2.0, -1.0], [0.0, 1.0, 2.0]])\n",
    "y = tf.zeros_like (x)\n",
    "out = tf.equal(x,y)\n",
    "\n",
    "print(sess.run(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**. Create a tensor with shape `[20, ]` filled with random numbers from 99 to 101. Compute indices of elements with values grater than 100. Get values of these elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101]\n",
      " [101]\n",
      " [101]\n",
      " [101]\n",
      " [101]\n",
      " [101]\n",
      " [101]\n",
      " [101]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.random_uniform(shape=[20,], minval=99, maxval=102, dtype=tf.int32)\n",
    "idx = tf.where(x > 100)\n",
    "vals = tf.gather(x, idx)\n",
    "\n",
    "print(sess.run(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with matrices\n",
    "\n",
    "**5**. Create a diagonal 5x5 matrix where main diagonal stores values `1...5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 0 3 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "values = tf.range(1,6)\n",
    "d = tf.diag(values)\n",
    "print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6**. Create a square matrix 10x10 filled with random numbers from any distribution and compute the determinant of this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 9.8642435, 10.398303 ,  9.79235  , 10.343996 ,  9.729421 ,\n",
      "         9.319011 ,  9.98748  ,  8.998725 ,  8.808565 , 10.42958  ],\n",
      "       [10.377178 ,  9.645718 , 10.126844 , 11.405236 ,  8.873443 ,\n",
      "         9.131749 , 11.947019 ,  9.33957  , 10.95904  , 11.327178 ],\n",
      "       [12.050882 ,  9.465801 ,  9.498543 ,  9.350488 , 11.905168 ,\n",
      "         9.806078 ,  9.788611 ,  8.5228815,  9.72491  , 10.019714 ],\n",
      "       [ 9.659422 , 10.085979 , 12.172923 , 11.838638 , 11.597965 ,\n",
      "         9.466216 ,  9.885148 , 11.078767 ,  9.971878 , 10.146133 ],\n",
      "       [ 8.57479  ,  8.642513 ,  9.698847 ,  9.624564 ,  8.862152 ,\n",
      "         9.42959  ,  9.108872 , 11.17779  , 12.413511 ,  9.624547 ],\n",
      "       [12.559023 ,  9.888772 ,  8.744758 , 10.835577 ,  9.108432 ,\n",
      "         9.569823 ,  9.758384 , 11.340021 , 10.828331 , 10.096112 ],\n",
      "       [ 8.5281925,  9.342571 ,  9.126167 , 10.289856 , 12.045213 ,\n",
      "        11.127957 ,  9.091891 ,  9.032965 , 12.026509 , 11.58018  ],\n",
      "       [10.217165 , 11.011111 ,  8.9850645, 10.113665 , 10.67785  ,\n",
      "         9.967373 , 10.459428 , 10.309277 ,  8.512064 ,  9.255442 ],\n",
      "       [10.490964 , 10.836328 ,  9.745403 ,  9.783274 , 11.48842  ,\n",
      "        10.385264 ,  9.322505 , 11.448506 , 10.713481 , 10.9105215],\n",
      "       [ 9.192316 , 10.632565 ,  9.872098 , 10.256935 ,  8.3027935,\n",
      "        10.532239 , 11.124182 , 10.288436 ,  8.208212 ,  7.9195323]],\n",
      "      dtype=float32), 40563.285)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "m = tf.random_normal([10, 10], mean = 10, stddev = 1)\n",
    "det = tf.matrix_determinant(m)\n",
    "print(sess.run((m, det)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7**. Create a tensor with values \\[6, 6, 7, 8, 8, 3, 8, 9, 6, 2, 6, 0, 1, 5, 5, 7, 2, 7, 7, 9\\]. Get an array of unique elements of this tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique(y=array([6, 7, 8, 3, 9, 2, 0, 1, 5], dtype=int32), idx=array([0, 0, 1, 2, 2, 3, 2, 4, 0, 5, 0, 6, 7, 8, 8, 1, 5, 1, 1, 4],\n",
      "      dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.constant([6, 6, 7, 8, 8, 3, 8, 9, 6, 2, 6, 0, 1, 5, 5, 7, 2, 7, 7, 9])\n",
    "u = tf.unique(x)\n",
    "print(sess.run(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "Let's solve linear regression task on Boston Housing dataset. \n",
    "The dataset contains the information about houses in Boston area. The features are various parameters of houses. The target value (value you should predict) is the median price of houses in a given neighbourhood.\n",
    "\n",
    "You can learn more about this dataset [here](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html).\n",
    "\n",
    "Let's first look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXuYHNV14H9nWg3qEQ4jjExgQAh7HSmRZSGQDbYSEmEHxebhiXjILM7aCRuSXTYGhygWWa8R/kiQV2tDnM+Pj9iJ8WJj8fIgjI1wjDA2DjgSg8AKsIl5CDfYyEGDQRpEz8zZP6pq1NNTr66u6q7qPr/vm296qqvuPVU9fc+955x7jqgqhmEYRu/S12kBDMMwjM5iisAwDKPHMUVgGIbR45giMAzD6HFMERiGYfQ4pggMwzB6HFMEhmEYPY4pAsMwjB7HFIFhGEaPM6vTAsTh8MMP1wULFnRaDMMwjEKxffv2X6jqvKjzCqEIFixYwLZt2zothmEYRqEQkWfinGemIcMwjB7HFIFhGEaPY4rAMAyjxzFFYBiG0eOYIjAMw+hxMo0aEpGngZeBCWBcVZeLyGHAJmAB8DRwnqruyVIOIznDI1U2bnmC50bHOGqgwtpVCxlaNthpsVoi7Xtq5zNKs692f7Zp9ee1Ux0doyTChOrU7/5yH2Pjk6hCSYTzTzqGq4aWtNx/47UrF81j6+O7U/0c6u9nsM3fNcmyQpmrCJar6i/qjv1v4EVV3SAi64C5qvrRsHaWL1+uFj7afoZHqlx+26OM1SamjlXKJa5evaSwyiDte2rnM0qzr3Z/tmn159dOFB84eT7Ljz0scf9x+kzzc2i1zXpEZLuqLo86rxOmofcB17uvrweGOiCDEYONW56Y8Q86Vptg45YnOiRR66R9T+18Rmn21e7PNq3+/NqJ4sYHn22p/zh9pvk5tNpmErJWBArcLSLbReQi99gRqvo8gPv7DX4XishFIrJNRLbt3r07YzENP54bHWvqeBFI+57a+YzS7Kvdn21a/SWRb0K1pf7j9pnm59BKm0nIWhGsUNUTgPcAF4vIKXEvVNXrVHW5qi6fNy9yh7SRAUcNVJo6XgTSvqd2PqM0+2r3Z5tWf0nkK4m01H/cPtP8HFppMwmZKgJVfc79/QLwDeDtwM9F5EgA9/cLWcpgJGftqoVUyqVpxyrlEmtXLeyQRK2T9j218xml2Ve7P9u0+vNrJ4rzTzqmpf7j9Jnm59Bqm0nILGpIROYAfar6svv6NOATwGbgg8AG9/ftWclgtIbnpOqmqKG076mdzyjNvtr92abVX307zUYNJe3fT3YvasiTod6e38w9Bd1P10QNicgbcVYB4Cicr6nqX4vI64GbgPnALuBcVX0xrC2LGjIMw49OhjcXIaoubtRQZisCVX0SWOpz/D+Ad2XVr2EYvUHjQFwdHePy2x4FmpuVh7UfpmTCIpHyogjiYjuLDcMoJFmGwHpKpjo6hnJAyQyPVKfO6aaoOlMEhmEUkiwH4jhKppui6kwRGIZRSLIciOMomW6KqjNFYBhGIclyII6jZIaWDXL16iUMDlQQYHCgkitHcTMUolSlYRhGI1mGwK5dtdA3IqhRyQwtGyzkwN+IKQLDMApLVgNxN+6hCcMUgWEYuSMP6c+7ZbYfB1MEhmHkiqz3BxgzMWexYRi5ohvTn+cdUwSGYeSG4ZEq1S7aqFUUTBEYhpELPJNQEEXcqFUUzEdgGEYuCKvW1Ri6mQdncjdhisAwjFwQZvqp36hlzuT0MdOQYRi5IMj0MzhQiZ3100iGKQLDMHJB3JQR7cz6OTxSZcWGezhu3Z2s2HDPtOyj3YSZhgzDyAVxd/MeNVDxjSxK25ncSyYoUwSGYeSGOLt54+YBapVuKjwThSkCwzAKRbvyAHVT4ZkoTBEYhpEpWYR6tiMPULtMUHnAnMWGYWRGnJKPSdvN2onbTYVnojBFYBhGZgTZ2ddv3pm4zayUSyPdVHgmCjMNGYaRGUH29NGxGsMj1USDajuduL2SitpWBIZhZEaYPf3STQ8nMuv0khO3XZgiMAwjM6Ls6UnMOlkWrW+kVzaUmSIwDCMzhpYNMre/HHpOs+kh2uXEbZcvIg+YIjAMI1OuOHPxjIG7keroWOyZd7ucuL2U08icxYZhZEr9BrCgojMCU+/FSeXQDiduL/kibEVgGEbmDC0b5P51p3LtmuNnrA4E0Ibz8zDzbqcvotOYIjAMo234mXUalYBHp2fefr6IcknYu3+865zHZhoyjB4hL1W9Gs06Kzbck8tUDo05jQb6y7zy6jijYzWgu7KR2orAMHqAPEfA5DmVg2fSemrD6fQfNIva5PT1Sx5MWGlgisAweoA8R8AUJZVDNzuPzTRkGD1A3gexIqRy6OZspLYiMIweoJciYLIizyasVjFFYBg9QDcPYu2iKCasJGRuGhKRErANqKrqGSJyHPB14DDgIeAPVPW1rOUwjF6mXVW9up0imLCS0A4fwSXAY8CvuH9/ErhGVb8uIl8ALgQ+3wY5DKOnKfoglpfw124kU9OQiBwNnA580f1bgFOBW9xTrgeGspTBMIzik+fw124gax/BtcBfApPu368HRlV13P37p4CvSheRi0Rkm4hs2717d8ZiGoaRZ/Ic/toNZKYIROQM4AVV3V5/2OdU3x3mqnqdqi5X1eXz5s3LREbDMIpB3sNfi06WPoIVwFki8l5gNo6P4FpgQERmuauCo4HnMpTBMIwuoJtj+PNAZisCVb1cVY9W1QXA+4F7VPUCYCtwjnvaB4Hbs5LBMIzuIM3w116pOtYMndhH8FHgz0Xk33F8Bl/qgAyGYRSItGL4zensj6gGJYHND8uXL9dt27Z1WgzDMApOUKbTwYEK9687tQMSZYuIbFfV5VHnWa4hwzB86ca4fXM6+2MpJgzDmEG3mlAs55I/pggMw5hBN8btD49U2ffa+IzjlnPJTEOG0XPEMfl0mwnFW+E0KreBSpn1Zy0uvMmrVUwRGEYP8bHhR/nqA7umdnEGlVs8tFKeKslYz6GVcjvETB2/FQ7AnINn9bwSADMNGUbPMDxSnaYEPPxMPuKXAyDkeN7pthVO2pgiMIweYeOWJ/zzuTBzQBzdN3M1EHY875iTOBxTBIbRI4TNfhsHxKABUoFln7i7cNFDVpgnHFMEhtEkRU1REDS4C8wYENeuWki55G8H2rOvxqWbHi6UQujm6mJpYM5iw2iCxuiTIGdrHlm7auGMyBkBLjh5vr/sEUkH9uyrTd075L/6WdEL82SJKQLDaIKw+Pq8DzLNlKvcuOUJapPR6WfGahNcecdOXq1NFlI5Gg6hpiEReYeIfFZEHhGR3SKyS0S+JSIXi8ih7RLSMPJC0aNPhpYNsnbVQo4aqPDc6Bgbtzzha95p5n727Kt13eazXiNwRSAi38apFXA78NfACzh1BX4NWAncLiKfVtXN7RDUMPJA0fPixzVtBd1nM7SqHLsx11FeCVsR/IGqXqiqm1X1OVUdV9VXVPUhVf2Uqv4O8MM2yWkYuSDv0SdRjuy4qSP87rNZWlGO3ZrrKK8EKgJV/QWAiBwhIieIyDIROcLvHMPoFfIcfRJn8AyapVdHx6Ypjvr7TEKryrEbcx3lmTDT0PHAF4BDAe8/6WgRGQX+u6o+1Ab5DCN35DX6JI4je6C/zJ6ATWGNZqKhZYNse+ZFbnhgV2TflXIfh805ODUzTtF9MUUjLGroy8CfqOqD9QdF5GTgH4GlGcplGEaTxBk8o+pQNSqOGx98Nlbf45Oaqg2/6L6YohHmI5jTqAQAVPUBYE52IhmGkYQ4aRRe8kkk10i94piIWcGwNqGpmm3y7ovpNsIUwbdF5E4RWSMi73R/1ojIncBd7RLQMIx4xBk848yo688pNZFlLk2zTZ59Md1IoGlIVT8sIu8B3gcM4mxC/CnwWVX9VpvkMwwjJnE2jPntLq6nUXGcf9IxsXwEkL7ZJq++mG7EitcbRo8xPFLlyjt2TjmNBSebxGCAk3fxx+9i72v+isOjUi7NmLHbPoDO03Lxenfn8OU4K4I3uIdfwNlgtkFVR9MQ1DCM9Igz+G575sVp6aSVAysBv4F6X4QSONDKdDnW3rKD2oRzvDo6xtpbdgCWdiKPhEUN3QTcA6xU1Z8BiMivAh8CbgZ+N3PpDMOITZxdw3GK02zc8gTV0TFKIkyoTv0OY6w2ydqbDwz0V96xc0oJeNQmlCvv2GmKIIeEOYsXqOonPSUAoKo/U9UNwPzsRTMMoxnibMIKK07jKQ4vbNMb/GNHDk0eiBwK2qsQdNzoLGErgmdE5C+B61X15+DsMsZZEcQLLjYMo2mS2tbj7CMIi+wpiQQ6keGALyGJDEa+CVMEa4B1wPfqUkv8DNgMnJe1YIbRizRb76BeafQFmHDqo3mCNmoJ0TP/OOsCr6+BSplRnz0LA5VyjFaMdhOWa2iPqn5UVRep6lz359fdYy+2U0jD6BWaybHTmFsoaCDfu398KoeQ314DrzhNq4N0uU+mQk/Xn7WYcp/MeH/9WYtb6sPIhtDCNCKyChjC2UeguGmpVdU2lBlGBjSTY8dPafgxOlabsarwMz3d+cjzgW1UyiVml/sCbfwDlTLrz1o81X4zRXCMzhMWPnotTu2Br+BsJAM4GviwiLxHVS9pg3yG0VM0k2OnGXt8fQ6hoI1aoyGO3LHaBAfP6qNckmnRQH77B8D2EBSNsBXBe1X11xoPisgm4P8BpggMI2VWLpo3I7wzKMdOs8VjohRHVHujYzXKfcLc/jKj+2ozBnhv8K+Ojk1zLFvpyvwTFj76qoi83ef424BXM5LHMHqW4ZEqt26vTlMCApx9ov8MvtniMYdG+ADitFebVPoPmsVTG07n/nWnTlMC9aGnYfsUjPwRtiL4EPB5EXkdB0xDxwC/dN8zDCNF/Gz+Cmx9fLfv+d4gXJ8uIoy9rzlO46BZeaNdPyhKqHFlMTxS5bKbdkRGHVloaX4JSzr3EHCSu5t4Kulc/QYzwzDSI6p6mJ+d3bP3L/vE3ZHKwEsV3WjKabTje++v2HBPpL/CWwnE2XRmtQTyS2jUEDi7iXH2D0whIotU9fHMpDKMHiTMRh+ULiJq9t6Ip2zi7Ffwy1Ta6K+IG7lktQTyTZiPIIy7o04Qkdki8iMR2SEiO0XkSvf4cSLyoIj8m4hsEpGDEspgGF1FlI2+3s7euIcgLt6sPGy/wvBIlRUb7uEjmx7m4Fl9zO0vB9YECDP3eLsIrJZA/gkLH/1M0FvAQIy29wOnquorIlIGfiAi3wb+HLhGVb8uIl8ALgQ+36TchtF11Nvow1YG3jlxZuL11M/Kw8xQ9auA0bEalXKJa9Yc7zuQB61iSiJ86rylNvgXhLAVwR8CPwa2N/xsA16LalgdXnH/LLs/CpwK3OIevx5nw5phGDjKYO2qhYGVwQRnNdBM2CjAnIMOxPsPj1TpC2jfL99QWMRPUFU0UwLFIsxH8C/Aj1X1h41viMj6OI2LSAlHefwn4LPAT4BRVR13T/kpjiPaMApDlpulopyvirMaiJMauh6vpsDHhh/1TUMNzgAetMoIWkHYDuLuIEwRnEPAfgFVPS5O46o6ARwvIgPAN4Bf9zvN71oRuQi4CGD+fMt6beSDZpPCNcuVd+yMNPk04xz2UGD95p28NFbzvbYkwtWrlwSapcIifqykZPEJCx9NLbGcqo6KyL3AycCAiMxyVwVH4+Qv8rvmOuA6cEpVpiWLYbRCmJM1yWBYv7oY6C/H2g/gDcpBtvmglYJfNlCPCVU+sulhBvrLlPuE2uT0NBIW8dPdhEYNicjviMjR7utjReSfROQBETklqmERmeeuBBCRCvBu4DFgK85qA+CDOKUvDaMQNJMULorGyJ84SqBccjJ8rlw0z/f9k984F3/rfzRTMoiTRC4oUsjoPqL2EWzgQEnKv8Fx8o7gRPmcEHHtkcD1rp+gD7hJVb8pIv8KfF1ErnLb+lJS4Q2j3TSTFC6I+pw8zVKb0NBdvE//xxgXnDzfN19RWPbQxj5efnU8MFLI6D7CwkevwClJ+REREWAV8CRwBHC4iHwcuFdV7/O7XlUfAZb5HH8S8MthZBi5J84mqzAafQxJCHMSPzc6xlVDSwC48cFnp2oOn33iIMuPPSx23xOqliiuhwgrTHMlTlTPD4B/B36oqv/LPf6sqn4iSAkYRrcytGyQq1cvYXCg0pTpxNukdemmh1tSAlEcNVBheKTKph89O63m8KYfOdVlG2Wf2x+ciM4SxfUOUaahjwCfxtkcdhGAiCwGHs5YLsMIpZP57puNkmlmFVAuCXMOmhXq2A27du2qhazfvHOasxecrKHrN+/k4StOmyZ7lGyWKK43CFUEqno/cFLDsZ3AxVkKZRhhZB3CmTZxdwEPNii0BevubK4jd+wPUiJ+x72+gvwOliiuN4hMOldkrEpSd5J2CGfWRM2qg6p8DTZZeKY2qYlMOV6/rfg+jGKTNOlc7mkMzfNmjV4Rb6O4pBnC2Q7CZtVhPoYkg3B1dIz+cvDXOuj/P6nvw+gOunZFULRZoxGfNEI4W8VvtQn+qRaCIo3i1PqtlPsYq03GlqskwsHlEvsCrgn7/7cdwr1LLEUgIoPAsfXn5z1iqGizRiM+rYZwtoqfj2LtzTtAmCrs7ue3iDJT+rVbLonvTt8gn8OEamgRevv/N/yIVAQi8klgDfCvgPffp0CuFUEeZo1GNnQ60ZnfarMxSgemr0DjzLZ9251Q5hxUYrI2OW1PwNbHdwf6D0QgaKuByAEn9EClzPqzFtsqwIjlIxgCFqrqe1X1TPfnrKwFa5Wg9Ljm/Co+nQ4CaGZWHedcb49B0MC+97WJaXsCbt1eZeWieYFFbHx0ku97o2M11t68w/xmRixF8CROLYFCYc6v7iQPQQDNrCqjzq2/n7iM1Sb45o7nmR3iFAZn9j/1OuCcpJFGRncRx0ewD3hYRL6Ls7EMAFX9cGZSpYQ5v7qPPAQB+Pkoyn0yzUcA8VagSSqNQXgm0SkUnt5wOgDHhexJML+BEUcRbHZ/DKPj5CEIIMhH4XcsSjmFyT04UGHv/vFEu4xh+mokyGfWeJ7Rm0QqAlW9vh2CGEYc8hIEELTabHZVEnQ/gwMV7l93auIkdV66CY+1qxay9pYd01Ys4KxkzG9mhGUfvUlVzxORR/GpIqaqb81UMsPwodOhox6NDuuVi+ax9fHdTTuwo+7Hb/Wx77Xx0HTSc/vLXHHm9Ggg7/WVd+ycutaihgyPsBXBJe7vM9ohiGHEoVOho42VxF55dXwqZLQ6OsYND+yaOjco99HwSNV3IL569ZJpxw+eFe4EPv2tR3Lr9uo05SE4s7XGfEX1hPnMOh2JZXQW0YCAYxERDXqziXPSYPny5bpt27asuzF6mLCBMKl5piTCpOrUiuHGHz3LhE9sZ3+5j9qETtuL4A3scxuUDjgrhvq9BN659e9fvdqpSRBncPe7v6Cdz0axEJHtqro88rwQRXAvcCtwu6ruqjt+EPCbOGUmt6rql9MQOAxTBEZWNM7SPeoHwrAY/07h+RCCZBuolNk/PhlrcA9qw+vDKC5xFUGYaej3gD8CbhSR44BRYDZQAu4GrlFVq0tgFJawmf5YbYL1m3ey7ZkXc6cE4EDh+qCoI79Io6Aw2zxEYhmdJVARqOqrwOeAz4lIGTgcGFPV0XYJZxhZEhXDPzpWm2b7zxMld7dYWFioH36De14isYzOESvpnKrWgOczlsUw2kIrxePzwoQqx627k4H+sm9SuqBC9V4py8aIp0bns6Vj6S26Ng21USzaFbWSRvH4vKAwY7D3IpHAv9DMykXzZmQ4veGBXVTKfcztLzO6r2ZRQz2IKQKj47Sz9GTSlA5FYf+4U4cgKMw26P6dmgfCNWuONwXQg8StR3As8GZV/ScRqQCzVPXlbEXLBxZfnT1x8wcFfRbNfEbd7gCNSn39kU3B8R1WuKl3iVOP4I+Bi4DDgDcBRwNfAN6VrWidp2hF0otKnKiVoM9i2zMvTrNvR31GzTpXi0iYsou6/25XlIY/cdJQXwysAH4JoKr/BrwhS6HyQthM1UiPoOiU+uNBn8WNDz7b1Ge0ctG8FqXNP2HRPn51OuJea3QvcUxD+1X1NXHD1URkFj65h7oRi69uD3HyBwXNYicCNkR6n9HwSJX1m3cmzuBZNKKiffxyDsW91uhe4qwIvicifwVUROR3gZuBO7IVKx/EmakarROniFBJgkqr+OOFSa69eUfPKIGSSKy0EEPLBhn5+Glcu+Z4K9xkACEpJqZOEOkDLgROw0mBsgX4YjtyDHl0KsWE5WDJDwtCCqs0FnP3PqOi7xVIgkBiR7rRfbSca6iuoTnAq6o64f5dAg5W1X2pSBqDTuYa6vUvUl7uPywfjhcWWR0doyTChCpz+8uhqZq7HS8xnd9GMZvI5J+0vndpKoIHgHer6ivu34cAd6vqO5uWKiGWdK4z5GlFFCVLHjaKeUrI+52Ua9ccz2U37Qhso1wSUKbtJg6TpxFLJpdv0vzexVUEcXwEsz0lAOC+7m9KGqOQ5ClqKsqPkIeNYt6g24oSAOdew9rYeM5SNp67dOpZRMnTiAU75JtOfO/iRA3tFZETVPUhABE5EbD/pB4gb1FTYYVVumVwm9tfBhxFF2QK856B9zvIbBa0IrBgh3zTie9dnBXBpcDNIvJ9Efk+sAn4H5lJZOSGrKOmhkeqrNhwD8etu5MVG+5heKSauI04c/C5/WX6mgs+aivlknDFmU6eIL94/3JJ2Lt/fMbz8ju3Ui5x/knH+B63ENF804loxTjF6/9FRBYBC3GCEh53s5EaXU6W9YHT2LXdjF+gUi6xvzZBhFm9Y5RE2HjO0hmz/cbymF4orN/z8nMuLj/2sFw4+434dKIud1iFslNV9R4RWe33vqrelplUDZizuHNkFTWURlWssMphc/vLqMJLYweyaV4akmenk8RxBFoVsd6i3VFDYSuC3wbuAc70eU+BUEUgIscAXwF+FZgErlPVvxWRw3DMSwuAp4HzVHVPlKBGZwizy7dCmB007pcgqA0BRj5+GnDgCxWWbK1diMBRh1amhbl64a/gDPZB95w3f42RLVl974IIq1B2hbuZ7NuqelOCtseBy1T1IRF5HbBdRL4DfAj4rqpuEJF1wDrgownaNwrMQECc/0B/ObbJKCiBWp8IC9bdSZ+QK1OQKr6z9zhmMqsiZmRJqLNYVSdJ6BhW1ee9SCM3ZfVjwCDwPuB697TrgaEk7RvFZXikyiuvjvu+NzpWix06F5RAzYuUyZMSAMeM08jwSJXLbtoRec9BDmFz/BppECd89Dsi8hc45py93kFVfTFuJyKyAFgGPAgcoarPu208LyI9kcnUOMDGLU8EboYKCp/3M4E0Okn7WtzIlTULXj9dEXgrgTjx/mEOYcNolTiK4I/c3xfXHVPgjXE6cHci3wpcqqq/lJjJw0TkIpw6CMyfPz/WNUYxSGLXrjeB+PkQgNw6gz3u/8mLfGz4Ua4aWgJEb4JrNPu0225s9A5xwkePS9q4iJRxlMBX66KMfi4iR7qrgSOBFwL6vQ64DpyooaQyGPmj2eIw9SYQP3v62lt2MDFRjH+RGx98dkoRhD0DM/sY7SRyQ5mIzBaRPxeR20TkVhG5VERmx7hOgC8Bj6nqp+ve2gx80H39QeD2JIIbxSWqOEo9cVJJ1CaUydSlzAbPDDQ8Ug1MDxE3nbRhpEUc09BXgJeBv3P/Ph/4v8C5EdetAP4AeFREvDX7XwEbgJtE5EJgV4x2jC6jflCPWhk0RtkUPVyyT8L3PwjwqfOWmhIw2kocRbBQVZfW/b1VRHZEXaSqP4DASU/X1zs2wqm3d//G//o2+2oz5/Re3p16Cl9zWMNNQsUwcBndRpxcQyMicrL3h4icBNyfnUhGr/E3q9/qpFauoz7vTj15rDlcCklg1PhOHBPW5bc9mijvkmEkJc6K4CTgv4jILvfv+cBjIvIooKr61sykMxKRl2IycWkmNHLr47vbLV4o/eU+39VMK3h7CPL8mRndRRxF8HuZS2GkRhrJ3NKQoVlFFDc0Mm8+giglkNTUk7f7bIaiTUSMeOGjz7RDECMdwopatOPLmKUiGh6p5n7TWFoUNXVEHiYiRvPE8REYBaLTycmyqq4UtQs3jyQtfeC3hyCN2g3tIE9V7Yz4mCLoMjpR1KKerBRR0lKU5T6Zij5qpShNkksvOHl+7P0SHo37JuCAEqyOjqEcmGXnURl0eiJiJMMUQZfR6eRkWSmiJAOJAGvefgxXnLmYwYFKS0noFBiozAxnDWJwoMJVQ0u4evUSSnHTquBERTWaUIo0y+70RMRIRhxnsVEgOp2cLKvqSkn2DyjwzR3Ps+lfnqXWxhQU9ffrPfc4ldQUuOGBXXxzx/PTCuoUaZbdiepaRusEVijLE1ahrBh40SJ+hVfScBTHLUvZCQYHKqGKd3ikmigpXqVcYna5z7d2g9dv3qJyLGooP6RRocwwgHhf7MaBekJ1aiaYxiDQTFqKJAjOjHxuQMGcMPzKRQZlSG2WsdoEB8/qo1Iu+SrBPEblWJbU4mE+AiOUuI7Kdtixh5YNcv+6U3l6w+mptOfZ7gcHKlxw8nwGByqMRiiBOP6XoGdWKSf7ur00VuPq1Ut8C9tAfv0FRnEwRWCEEneAT9OOHSdUshnHrR8DlTI/ufq9XLvmePbuH+eGB3ZNDdxh11y9esm0vmf7DO5Bz2x2kxFEHkcNVKaUYJDbOY/+AqM4mCIwQok7wKcVLRJnBfKx4UcZHWvOfFNPuU9Yf9biqb7itOVdA7B//MBu4j37ajPkC3pmUasNPxpXHBaVY2SBKQIjlKABpk9k2uCXVthq1ApkeKTKVx/Y5XdpLAYHKmw810nzHGdvgsS4pnGFFDZYB5l3Gvv0ZPX2FHirpOro2IxVgUXlGK1izmIjFL9wQHCcwfVOyrTCVoMcwd7xjVueSJy/R5he3yDKnOLnBI6SD5xntvbmHTPqMj/nrnI8x3QQ2tB3oyO+vo2SyDRF1AknrUUJFR9TBEYo3hf6spt2zEjv0JjDKI1okVJALiHPsduKLfykB+P0AAARuElEQVTQBr9C2N6ESrnEykXzWLHhnmkDXJR8U/gY87Xud5QyqL9Pv1WI14YnS6eihyy3UHdgpiHDl3qH7cYtTwTm+EnbSRnUj3e8FVv46FhtmvM5qGTm3P4yZ584yK3bq9N8FZduejhUPq/djVueiNzA5s36g0xF9fcZ9Iwbe+hE9FCRdj0bwdiKwJiB3ywvaAabhpOy3rQQNOP2BswgU1Vc/GasfvH+fiugKLx24ypHbzXS+Gz9HMRx9060O3qoSLuejWBMERgzCDJF+NFqxTC/jWiN+KVsuPKOnTM2fkWZWzzqTVqN5qxWspx67TabDiPK5u+n/MIUcztt9kH3alFMxcJMQxlTlPTB9TQziLVaMSwqcscvGyfAL8fGZ5zrDahxCJqxJs1y6lEdHQs0OYURZPMfHqkytGyQs08cnPJDlER455sO843SWrloXlszlXY6yaGRDqYIMqRI6YM9hkeqTaVcbtUEEHZ9Y4qK4ZEqx195d6it3rO9g48Dtw6/GevwSDW19BVhO4GDCLL5D49UuXV7deqeJ1R5aNdLnH3iIIMDlakQ16tXL2Hr47vbarMfWjY4da/1cpijuFhY0rkM8eK+G/ELS8wLQTIH0eq9RPXntR836VyjPH7XeWaVwTqfwPrNO1vapBYkQ1j/cRCcaCc/2Tz5GxP9BbXzVEqpOYziYEnnckARHWlRM/Sk6YWD7NZBMfeN8sQx2ZRLwt794xy37s4ZtnFvsKwfhKujY6y9eQeTwERIsYJmBu56mcHfpzG73Mf4pMZKjT0QkgTPW2GG+Vc8zGZvhGGmoQwpYjqAINm8JX8SE0CYiWxo2SCHzA6ej3jyRClPcUfr0bGabx/3rzuVwYHKjAG9NqmhSsBpPPIWfWWu59W6IvdjtclYSqBSLhG2YPccy3HaMZu9EYYpggwpoiMtTGZvQH1qw+ncv+7U2HbgqFjzsBw83rOKUp4CM1YVY7UJrrxj59TfSVZigwOV0MHYT47q6Ni0wIAkDmhP0b4UYq6KE9lkNnsjDqYIMqSIjrQsZI4ykQUN8gOV8lS/UZE4QZP6PftqUwNykpXYykXzYpeahOlmJ29F0qwC8lJhDC0bDJR5bn850hnt+Sry/P9m5ANzFhuZE+U093OoVsolrl69BDiw4Wugv4yqk5+/L8Qx2kw/ca5duWgeN0QkugvyI3iDdVIHfNSzCbof7xxTAr1NXGexrQiMzAmaze97bXzKhu+3CgGm+Rb27Kuxf3ySa9Ycz2QTExhvRu710wzPjY5x1dASPnDy/Glx/CvedNg0eYOkea7JfQWNpsOwFVr9e55cUIyVp5EvbEWQMUXMzJiFzMMjVd8QzbCZa1hoaVioZCONIaVJQmSDnkF9neawvuPULB6olFl/1uLc/38YxcFWBDmgqBvKspB5aNkgcw6eGR3kOXT9dl+H2db9lEC5JJT7ptvz/ZzzfjP0cp9QLvn7AoKeQf2z8qMxNUaUr6G+4I1htBNTBBlSxMyMWcocNLDv2VfzVTxxnLslkQPFY85ZysZzl0Y6uv3MLRvPXcrGc5Y2VRc4LBrIr++oFUze/zeM7sU2lGVIN20oS0PmuMnYvAFx7aqFrL1lR2jM/aTqjB2zcUwrQbUThpYNcty6O31t/o3PIOiZNBbA8RiMcf95/t8wuhdbEWRIN20oS0PmZpymz42OOeakg8LnKklqIkclAYz7DJp9VnHuf6C/XLgkhUbxMUWQId22oaxV/EwyAw1Vwzy8wTRsQ1WzcsX1f8R9Bgte7z/gBx1vjPJp9BiUS8Irr44XyqdkdAdmGsqQtOr4JiFp5E+7ZT5j6ZHcur0amMMoyJxUEmkqRHJ4pBqr3CbEfwYPPLnHt6+g417b9dlU6/vYu398RlSVn3ytUsRINiNbMgsfFZF/AM4AXlDVt7jHDgM2AQuAp4HzVDX4W+NS5PDRThC2CSnsC5/1ABEk19knDrL18d2+/Sa9l6h+60mamXPBujsD33s6QXtBvok0M4em8TyN4pCH8NEvA7/XcGwd8F1VfTPwXfdvI2WSRP60I9Q1SK6tj+8OzGGURsqLqFw/Sf0fYeGgSZ5bO3xKRYxkM7InM9OQqt4nIgsaDr8P+B339fXAvcBHs5KhV0kS+RM2QDSWcky6akgakRQU4ROXsPYFEvs/zj/pmMDUE0nMOX4lKdP2KRUxks3Innb7CI5Q1ecBVPV5EXlDm/vvCZLUkY0zQPgVtW8sBJ+2XGkQFraqxJPdj6uGlgQqgsbn6adAYaYf4urVSzI1z1mNYcOP3EYNichFIrJNRLbt3t1aXdxeI0nkTxyzRKtmhU5FUa1dtTCwpECz5STjXl//3PzMbmtv3sHaW3bMMMUBiVJ9x6WIkWxG9rRbEfxcRI4EcH+/EHSiql6nqstVdfm8efPaJmA3kMSuHmeAaNWs0Km03EPLBrng5PkzlEEaA2Cc5+anQGs+FcraYasvYmp0I3vabRraDHwQ2OD+vr3N/ReCNKJ3mrWrxwmZTMOs0Kq9PylXDS1h+bGHBd5fluG2zdjf22Gr79RnYOSXzBSBiNyI4xg+XER+ClyBowBuEpELgV3AuVn1X1RatcO3QtQA0Q5nph9JBumga4IyiDbzzP3a9ksp4RE3tYZ3rmG0myyjhs4PeOtdWfXZDcSN3ukEaW42izu4J1GMca6p7x9mFpUJeuZJ5PFToOU+AWGaeSgNpWqbxYwk2M7inJH38L7GWbWXu6fZ2XrcwTSJYoy6Jm6lMr9nnkSeIAXqd6yVQbuTq0mj2JgiyBlFCu9LOvA0M5gmUYxR18QtJu/3zNPeC5HmAJ3n1aSRb3IbPtqrFCm8L2k4aTODaZLdtlHXxF1d+T3zPGeUzftq0sgvpghyRl7D+/zSNycdeJoZTJMoxqhr4gzac/vLvs88r4p6eKRKX0DKizwoKSPfmGkoh+QtvC/IBDTQX2bPvplpov0Gnnon5qGVMuWSxHKUJnFQR13j57ytp1IuccWZixO1HXbf9eem6dT1Ph+/Cmh5UFJG/rHi9QWlndEhQcXeBypl9o9PRmay9HPOlvuEQ2bPYnRfjaMGKqxcNC8wA2kWNComEaZkSavvsGyrfqm3k678gj6fkgifOm9priYVRnuJm33UVgQFpN3RIUGmnpfGalyz5vhIhRS0s7b/oFmMfPy0jkS7tGPVFeRDufHBZ2PVRYhL0OczqWpKwIiFKYIC0u7okLBIpjgDapIonm6Idgm676Ai9kmdukWKNDPyiTmLC0i7o0NadZAmjeLJ4n7i1CxOi6D7DqpjkHTgzqsD2ygOpggKSLtDGFuNZEoaxZP2/bSj+E49Qfd9/knHpDpw5zXSzCgOZhoqIJ3I+dOKTT1JFE8W99NuE1TYfYclwEvalw38RlIsaqigdFtOmXbcT5yawN32XI3exqKGupxumwG2436inKqWq8foVcxHYPQMUb4KK+xu9Cq2IjByR5r1B+qJ8lVYrh6jVzFFYOSKrOoPeISZoCwe3+hVzDRk5Iok5pm0TDoWj2/0KrYiMHJFFvUH4pJmBTbDKBKmCIxckcQ8k6ZJp9uisQwjDmYaMnJFFvUHDMMIx1YERq7Iov6AYRjh2M5iwzCMLiXuzmIzDRmGYfQ4pggMwzB6HFMEhmEYPY4pAsMwjB7HFIFhGEaPU4ioIRHZDTzTaTkiOBz4RaeFaAN2n91Fr9wn9M691t/nsao6L+qCQiiCIiAi2+KEaRUdu8/uolfuE3rnXpPcp5mGDMMwehxTBIZhGD2OKYL0uK7TArQJu8/uolfuE3rnXpu+T/MRGIZh9Di2IjAMw+hxTBGkgIiURGRERL7ZaVmyRESeFpFHReRhEenaLIAiMiAit4jI4yLymIi8o9MypY2ILHQ/R+/nlyJyaaflygIR+YiI7BSRH4vIjSIyu9MyZYGIXOLe485mP0tLQ50OlwCPAb/SaUHawEpV7fZY7L8F7lLVc0TkIKC/0wKljao+ARwPzkQGqALf6KhQGSAig8CHgd9Q1TERuQl4P/DljgqWMiLyFuCPgbcDrwF3icidqvpvca63FUGLiMjRwOnAFzsti9E6IvIrwCnAlwBU9TVVHe2sVJnzLuAnqpr3TZtJmQVURGQWjlJ/rsPyZMGvAw+o6j5VHQe+B/x+3ItNEbTOtcBfApOdFqQNKHC3iGwXkYs6LUxGvBHYDfyja+77oojM6bRQGfN+4MZOC5EFqloF/g+wC3geeElV7+6sVJnwY+AUEXm9iPQD7wWOiXuxKYIWEJEzgBdUdXunZWkTK1T1BOA9wMUickqnBcqAWcAJwOdVdRmwF1jXWZGywzV9nQXc3GlZskBE5gLvA44DjgLmiMgHOitV+qjqY8Ange8AdwE7gPG415siaI0VwFki8jTwdeBUEbmhsyJlh6o+5/5+Acee/PbOSpQJPwV+qqoPun/fgqMYupX3AA+p6s87LUhGvBt4SlV3q2oNuA14Z4dlygRV/ZKqnqCqpwAvArH8A2CKoCVU9XJVPVpVF+Asr+9R1a6bbQCIyBwReZ33GjgNZznaVajqz4BnRWShe+hdwL92UKSsOZ8uNQu57AJOFpF+ERGcz/OxDsuUCSLyBvf3fGA1TXyuFjVkxOUI4BvOd4lZwNdU9a7OipQZfwZ81TWbPAn8YYflyQTXlvy7wJ90WpasUNUHReQW4CEcU8kI3bvD+FYReT1QAy5W1T1xL7SdxYZhGD2OmYYMwzB6HFMEhmEYPY4pAsMwjB7HFIFhGEaPY4rAMAyjxzFFYBhtQETuFZGW6uWKyJdF5JzG9kTkWyIykIacRm9i+wiM3OBu+BFVLVzeJhGZ5Sb7ajuq+t5O9Gt0D7YiMDqKiCxwc/5/DmfTzzEicr5b9+DHIvLJunODjr8iIp90k+H9k4i83Z0xPykiZ7nnLBaRH7m59x8RkTf7yPKKiHxKRB4Ske+KyDz3+JtE5C63/e+LyCL3+JdF5NMishUnz0t9WxUR+brb1yag4h4/T0Q+7b6+RESerOvjB+7rE0Xke25/W0TkyIhn+LSIHF73LP/ezUl/t4h4/b7NleWfRWSjiHTdrnAjOaYIjDywEPiKm+SthjOonoqTL/9tIjIkIkf5HXevnwPcq6onAi8DV+HsmP194BPuOX8K/K2qHg8sx8kp1MgcnLw7J+Ck8b3CPX4d8Gdu+38BfK7uml8D3q2qlzW09d+Afar6VuCvgRPd4/cBv+W+/i3gP9yc+b8JfF9EysDfAee4/f2De31c3gx8VlUXA6PA2e7xfwT+VFXfAUw00Z7RA5hpyMgDz6jqA+7rt+EM6rsBROSrOPUBNOD4MG4hDvf6R4H9qloTkUeBBe7xfwb+p1s/4raAgh2TwCb39Q3AbSJyCE6Sspvd9BoAB9ddc7Oq+g2spwCfAVDVR0TkEff1z0TkEDdv0zHA19xzfwsnIdpC4C3Ad9z+Sjjpk+PylKo+7L7eDixw/QevU9Ufuse/BpzRRJtGl2OKwMgDe+teS8A5QccBanogV8oksB9AVSfdYiSo6tdE5EGcIkJbROS/quo9EXIpzqp51F1JRMnud70f/4yTv+gJ4PvAHwHvAC4D5gM73Zl7EvbXvZ7AMUmFPTvDMNOQkTseBH7btXmXcLJjfi/keCxE5I3Ak6r6GWAz8Faf0/qAc9zX/xn4gar+EnhKRM512xERWRqjy/uAC9xr3tLQ3304Jqb7cJKgrcRZxbyEoxzmiVsnWUTKIrI47n364SYfe1lETnYPvb+V9ozuw1YERq5Q1edF5HJgK85M9luqejtA0PGYrAE+ICI14Gcc8B3UsxdYLCLbgZfca8AZ0D8vIh8Dyji1J3ZE9Pd5nCpnjwAPAz+qe+/7OGah+1R1QkSeBR537/81N0T0MyJyKM539FpgZxP36seFwN+LyF7gXvf+DAOw7KOGMYWIvKKqh3RajiwQkUNU9RX39TrgSFW9pMNiGTnBVgSG0Ruc7q6oZgHPAB/qrDhGnrAVgWEYRo9jzmLDMIwexxSBYRhGj2OKwDAMo8cxRWAYhtHjmCIwDMPocUwRGIZh9Dj/H9s1NiAo0QhmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23f9c890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the data is already stored in sklearn library\n",
    "# we'll take it from there\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "x, y = load_boston(return_X_y=True)\n",
    "\n",
    "# we'll use one feature for simplicity\n",
    "# in our case it's the average number of rooms per dwelling\n",
    "x = x[:, 5]\n",
    "\n",
    "p = plt.scatter(x, y)\n",
    "l = plt.xlabel('rooms per dwelling')\n",
    "l = plt.ylabel('price (in $1000)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise feature values and the target value to make training more stable\n",
    "x = x / x.std()\n",
    "y = y / y.std()\n",
    "\n",
    "# training parameters\n",
    "tf.reset_default_graph()\n",
    "batch_size = 32\n",
    "n_samples = len(x)\n",
    "n_features = 1\n",
    "\n",
    "\n",
    "# convert the input data to Tensors\n",
    "X_data = np.reshape(x, (-1, 1))\n",
    "y_data = np.reshape(y, (-1, 1))\n",
    "\n",
    "# create placeholders\n",
    "# these should be tensors of type tf.float32\n",
    "# X should be a matrix of size batch_size * n_features\n",
    "# y should be a matrix of size batch_size * 1\n",
    "X = tf.placeholder(tf.float32,[batch_size, n_features])\n",
    "y = tf.placeholder(tf.float32,[batch_size, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build the graph.\n",
    "\n",
    "You should first define the parameters of the model - weight matrix `W` and bias vector `b`.\n",
    "\n",
    "The shape of `W` is n_features $\\times$ n_outputs (1 $\\times$ 1 in our case).\n",
    "The length of `b` is n_outputs (1 in our case).\n",
    "\n",
    "You should initialise both variables with values from normal distribution (you can use `tf.random_normal_initializer()`).\n",
    "\n",
    "Then you should define the value of prediction: $\\hat{y} = X \\times W + b$.\n",
    "\n",
    "Finally, define the loss: \n",
    "\n",
    "$$L = \\frac{1}{N} \\sum_{i=0}^{N} (y_i-\\hat{y_i})^{2}$$\n",
    "\n",
    "where *N* is the number of samples\n",
    "\n",
    "**NB**: you can multiply matrices with `tf.matmul` and sum vectors with `tf.reduce_sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "with tf.variable_scope(\"my-profession\"):\n",
    "    \n",
    "    # create weights of the model\n",
    "    W = tf.Variable(tf.random_normal([n_features,1]))\n",
    "    b = tf.Variable(tf.random_normal([1]))\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    # define model prediction\n",
    "    y_pred = tf.add(tf.matmul(X, W), b)\n",
    "    # define loss\n",
    "    loss = tf.reduce_sum(tf.square(y_pred - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to minimise `loss`. In order to do that we should define an optimiser and define an operation for it (minimisation). We recommend using Adam optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer()\n",
    "train_op = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write graph to a file\n",
    "file_writer = tf.summary.FileWriter('./boston', tf.get_default_graph())\n",
    "\n",
    "# we'll put values of loss here\n",
    "train_history = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # don't forget to initialise variables\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    # train a model\n",
    "    for _ in range(3000):\n",
    "        idx = np.random.choice(n_samples, batch_size)\n",
    "        X_batch, y_batch = X_data[idx, :], y_data[idx, :]\n",
    "        feed_dict = {X: X_batch, y: y_batch}\n",
    "        loss_value, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "        train_history.append(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Draw a figure showing how the loss changed throughout the training. The values of loss for all epochs are saved in `train_history` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a23741f50>]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23eca2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(train_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST classification\n",
    "\n",
    "Let's now build a neural network.\n",
    "We will classify images from [MNIST](http://yann.lecun.com/exdb/mnist/) dataset.\n",
    "\n",
    "In some tasks you might need to do low-level operations with variables and scopes. However, in most of cases you can use layers which are already defined in TF: `tf.layers`/`tf.contrib.layers`.\n",
    "\n",
    "We will create a simple model with fully-connected layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a simple model with fully connected layers\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "y = tf.placeholder(tf.int32, shape=(None,))\n",
    "\n",
    "with tf.variable_scope(\"mnist-linear-regression\"):\n",
    "    # hidden layer with 40 cells with ReLU activation function\n",
    "    # it takes X as input\n",
    "    \n",
    "    hidden1 = tf.layers.dense(X, 40, activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, 40, activation=tf.nn.relu)\n",
    "    \n",
    "    # output layer has 10 cells (corresponding to 10 classes)\n",
    "    logits = tf.layers.dense(hidden2, 10, activation=None)\n",
    "    \n",
    "    # probability of every class computed as softmax function over outputs\n",
    "    pred = tf.nn.softmax(logits)\n",
    "    #cross-entropy loss\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "# loss is minimised with Adam optimiser\n",
    "opt = tf.train.AdamOptimizer()\n",
    "train_op = opt.minimize(loss)\n",
    "file_writer = tf.summary.FileWriter('./very-mnist', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Add another hidden layer to the above model. It should have 40 cells with ReLU activation function. It should take the output of `hidden1` as input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.3131814\n",
      "loss = 0.20345691\n",
      "loss = 0.009864073\n",
      "loss = 0.03567986\n",
      "loss = 0.27254\n",
      "loss = 0.06893168\n",
      "loss = 0.40891927\n",
      "loss = 0.06520602\n",
      "loss = 0.036216006\n",
      "loss = 0.2733618\n",
      "loss = 0.18074344\n",
      "loss = 0.32324696\n",
      "loss = 0.07783464\n",
      "loss = 0.16077636\n",
      "loss = 0.13533905\n",
      "loss = 0.16160779\n",
      "loss = 0.15340564\n",
      "loss = 0.08558453\n",
      "loss = 0.13110413\n",
      "loss = 0.12667474\n",
      "loss = 0.050170917\n",
      "loss = 0.11001366\n",
      "loss = 0.054229096\n",
      "loss = 0.33468336\n",
      "loss = 0.053189218\n",
      "loss = 0.07486473\n",
      "loss = 0.010296805\n",
      "loss = 0.2679902\n",
      "loss = 0.17846605\n",
      "loss = 0.025911273\n",
      "loss = 0.03871318\n",
      "loss = 0.26883572\n",
      "loss = 0.1591227\n",
      "loss = 0.07261591\n",
      "loss = 0.31047907\n",
      "loss = 0.034402724\n",
      "loss = 0.112137854\n",
      "loss = 0.12232709\n",
      "loss = 0.06014689\n",
      "loss = 0.14924686\n",
      "loss = 0.078402966\n",
      "loss = 0.26090884\n",
      "loss = 0.0432662\n",
      "loss = 0.013744041\n",
      "loss = 0.07387605\n",
      "loss = 0.19609223\n",
      "loss = 0.2652557\n",
      "loss = 0.18775499\n",
      "loss = 0.04843473\n",
      "loss = 0.007804719\n",
      "loss = 0.024128428\n",
      "loss = 0.15345874\n",
      "loss = 0.038940273\n",
      "loss = 0.034242347\n",
      "loss = 0.156949\n",
      "loss = 0.054772977\n",
      "loss = 0.4830235\n",
      "loss = 0.16828975\n",
      "loss = 0.19108798\n",
      "loss = 0.13477224\n",
      "loss = 0.07378709\n",
      "loss = 0.033034842\n",
      "loss = 0.19557835\n",
      "loss = 0.20256104\n",
      "loss = 0.12583514\n",
      "loss = 0.24676193\n",
      "loss = 0.36805877\n",
      "loss = 0.18216917\n",
      "loss = 0.111854196\n",
      "loss = 0.048626028\n",
      "loss = 0.068938404\n",
      "loss = 0.08162149\n",
      "loss = 0.033913113\n",
      "loss = 0.46059215\n",
      "loss = 0.3933255\n",
      "loss = 0.10941436\n",
      "loss = 0.07868172\n",
      "loss = 0.045587085\n",
      "loss = 0.061467797\n",
      "loss = 0.022498846\n",
      "loss = 0.047160864\n",
      "loss = 0.28863978\n",
      "loss = 0.28082108\n",
      "loss = 0.041783255\n",
      "loss = 0.015493452\n",
      "loss = 0.07857459\n",
      "loss = 0.085143656\n",
      "loss = 0.08648332\n",
      "loss = 0.21573713\n",
      "loss = 0.08608337\n",
      "loss = 0.16758582\n",
      "loss = 0.061241843\n",
      "loss = 0.04530201\n",
      "loss = 0.11538078\n",
      "loss = 0.10187036\n",
      "loss = 0.01769803\n",
      "loss = 0.023129744\n",
      "loss = 0.031954527\n",
      "loss = 0.23025236\n",
      "loss = 0.0635952\n",
      "loss = 0.112722054\n",
      "loss = 0.13025971\n",
      "loss = 0.07624729\n",
      "loss = 0.01305928\n",
      "loss = 0.17064795\n",
      "loss = 0.009853827\n",
      "loss = 0.3294484\n",
      "loss = 0.08765881\n",
      "loss = 0.1888364\n",
      "loss = 0.023089908\n",
      "loss = 0.02147358\n",
      "loss = 0.11392708\n",
      "loss = 0.15923288\n",
      "loss = 0.40700305\n",
      "loss = 0.21459928\n",
      "loss = 0.029877853\n",
      "loss = 0.043696627\n",
      "loss = 0.11661711\n",
      "loss = 0.22329985\n",
      "loss = 0.030693036\n",
      "loss = 0.15723583\n",
      "loss = 0.1942467\n",
      "loss = 0.030858325\n",
      "loss = 0.22262068\n",
      "loss = 0.19712822\n",
      "loss = 0.14412613\n",
      "loss = 0.03712696\n",
      "loss = 0.229676\n",
      "loss = 0.016950654\n",
      "loss = 0.073996305\n",
      "loss = 0.2727872\n",
      "loss = 0.043966778\n",
      "loss = 0.2730863\n",
      "loss = 0.13239034\n",
      "loss = 0.2004489\n",
      "loss = 0.18038128\n",
      "loss = 0.15641281\n",
      "loss = 0.17392758\n",
      "loss = 0.08799051\n",
      "loss = 0.04600389\n",
      "loss = 0.1490501\n",
      "loss = 0.31150645\n",
      "loss = 0.14996263\n",
      "loss = 0.07665384\n",
      "loss = 0.17277825\n",
      "loss = 0.03375918\n",
      "loss = 0.0612114\n",
      "loss = 0.1258014\n",
      "loss = 0.108623676\n",
      "loss = 0.0112606445\n",
      "loss = 0.014859254\n",
      "loss = 0.021693574\n",
      "loss = 0.035382397\n",
      "loss = 0.16214016\n",
      "loss = 0.037279025\n",
      "loss = 0.06939615\n",
      "loss = 0.30881083\n",
      "loss = 0.17940892\n",
      "loss = 0.23635635\n",
      "loss = 0.06248057\n",
      "loss = 0.020029046\n",
      "loss = 0.08143182\n",
      "loss = 0.034198225\n",
      "loss = 0.00424305\n",
      "loss = 0.046354078\n",
      "loss = 0.18241706\n",
      "loss = 0.23740204\n",
      "loss = 0.12960577\n",
      "loss = 0.023523431\n",
      "loss = 0.16914862\n",
      "loss = 0.21583644\n",
      "loss = 0.08742563\n",
      "loss = 0.27178574\n",
      "loss = 0.092506446\n",
      "loss = 0.017759617\n",
      "loss = 0.09848707\n",
      "loss = 0.08060118\n",
      "loss = 0.17250255\n",
      "loss = 0.059062567\n",
      "loss = 0.04645902\n",
      "loss = 0.1189922\n",
      "loss = 0.17862861\n",
      "loss = 0.05395104\n",
      "loss = 0.12276053\n",
      "loss = 0.021192946\n",
      "loss = 0.06865396\n",
      "loss = 0.21000655\n",
      "loss = 0.11626665\n",
      "loss = 0.11542283\n",
      "loss = 0.060202613\n",
      "loss = 0.22068354\n",
      "loss = 0.114903584\n",
      "loss = 0.06174675\n",
      "loss = 0.028534044\n",
      "loss = 0.025783192\n",
      "loss = 0.12268355\n",
      "loss = 0.16798423\n",
      "loss = 0.07316789\n",
      "loss = 0.17705332\n",
      "loss = 0.2151219\n",
      "loss = 0.040595308\n",
      "loss = 0.15190485\n",
      "loss = 0.06370199\n",
      "loss = 0.13661048\n",
      "loss = 0.21193469\n",
      "loss = 0.032508735\n",
      "loss = 0.14002337\n",
      "loss = 0.10164393\n",
      "loss = 0.071048334\n",
      "loss = 0.041859053\n",
      "loss = 0.14361203\n",
      "loss = 0.15827966\n",
      "loss = 0.08888209\n",
      "loss = 0.046594456\n",
      "loss = 0.05974563\n",
      "loss = 0.015124168\n",
      "loss = 0.11128162\n",
      "loss = 0.07762187\n",
      "loss = 0.07883267\n",
      "loss = 0.0134884985\n",
      "loss = 0.23516029\n",
      "loss = 0.16999918\n",
      "loss = 0.046457913\n",
      "loss = 0.19473644\n",
      "loss = 0.034458544\n",
      "loss = 0.1339849\n",
      "loss = 0.09952197\n",
      "loss = 0.19442084\n",
      "loss = 0.09755942\n",
      "loss = 0.059787475\n",
      "loss = 0.072993174\n",
      "loss = 0.29596436\n",
      "loss = 0.0655063\n",
      "loss = 0.018650327\n",
      "loss = 0.037446655\n",
      "loss = 0.013269329\n",
      "loss = 0.13413092\n",
      "loss = 0.026394125\n",
      "loss = 0.052626476\n",
      "loss = 0.08468138\n",
      "loss = 0.15727969\n",
      "loss = 0.06294888\n",
      "loss = 0.2573986\n",
      "loss = 0.037615597\n",
      "loss = 0.071046315\n",
      "loss = 0.15163298\n",
      "loss = 0.1044774\n",
      "loss = 0.5313364\n",
      "loss = 0.036381304\n",
      "loss = 0.03125526\n",
      "loss = 0.06026324\n",
      "loss = 0.19731146\n",
      "loss = 0.0370252\n",
      "loss = 0.20002653\n",
      "loss = 0.3243972\n",
      "loss = 0.3042632\n",
      "loss = 0.18067807\n",
      "loss = 0.023211228\n",
      "loss = 0.10632534\n",
      "loss = 0.12908791\n",
      "loss = 0.058990218\n",
      "loss = 0.04318375\n",
      "loss = 0.21484365\n",
      "loss = 0.04377535\n",
      "loss = 0.02080912\n",
      "loss = 0.22053972\n",
      "loss = 0.01355561\n",
      "loss = 0.18855909\n",
      "loss = 0.017016258\n",
      "loss = 0.20997362\n",
      "loss = 0.28828925\n",
      "loss = 0.2146811\n",
      "loss = 0.088936396\n",
      "loss = 0.049402863\n",
      "loss = 0.17425717\n",
      "loss = 0.23622367\n",
      "loss = 0.18566233\n",
      "loss = 0.014370123\n",
      "loss = 0.22514775\n",
      "loss = 0.050683122\n",
      "loss = 0.08225499\n",
      "loss = 0.05491104\n",
      "loss = 0.12422328\n",
      "loss = 0.07207594\n",
      "loss = 0.168084\n",
      "loss = 0.054795787\n",
      "loss = 0.36710328\n",
      "loss = 0.019240983\n",
      "loss = 0.01741986\n",
      "loss = 0.06632443\n",
      "loss = 0.2478585\n",
      "loss = 0.02445294\n",
      "loss = 0.07620944\n",
      "loss = 0.10930394\n",
      "loss = 0.33012456\n",
      "loss = 0.09987903\n",
      "loss = 0.04880265\n",
      "loss = 0.12393157\n",
      "loss = 0.086650185\n",
      "loss = 0.16752806\n",
      "loss = 0.14752017\n",
      "loss = 0.08928382\n",
      "loss = 0.098313436\n",
      "loss = 0.02201233\n",
      "loss = 0.12248429\n",
      "loss = 0.19609003\n",
      "loss = 0.23755166\n",
      "loss = 0.012097118\n",
      "loss = 0.2737752\n",
      "loss = 0.087767944\n",
      "loss = 0.052534275\n",
      "loss = 0.017182127\n",
      "loss = 0.06567467\n",
      "loss = 0.021413855\n",
      "loss = 0.031048993\n",
      "loss = 0.08664443\n",
      "loss = 0.0880543\n",
      "loss = 0.02200441\n",
      "loss = 0.053482853\n",
      "loss = 0.109344654\n",
      "loss = 0.14004359\n",
      "loss = 0.17978173\n",
      "loss = 0.04154681\n",
      "loss = 0.117119506\n",
      "loss = 0.22997932\n",
      "loss = 0.13725945\n",
      "loss = 0.073113225\n",
      "loss = 0.1783125\n",
      "loss = 0.059830647\n",
      "loss = 0.08820512\n",
      "loss = 0.027092094\n",
      "loss = 0.06583892\n",
      "loss = 0.09338073\n",
      "loss = 0.15543023\n",
      "loss = 0.009429254\n",
      "loss = 0.14384387\n",
      "loss = 0.07036376\n",
      "loss = 0.10804434\n",
      "loss = 0.039006624\n",
      "loss = 0.063229114\n",
      "loss = 0.07533918\n",
      "loss = 0.20445003\n",
      "loss = 0.031580802\n",
      "loss = 0.0946401\n",
      "loss = 0.012466781\n",
      "loss = 0.0464207\n",
      "loss = 0.2071392\n",
      "loss = 0.07473204\n",
      "loss = 0.022804024\n",
      "loss = 0.14907789\n",
      "loss = 0.321782\n",
      "loss = 0.018454611\n",
      "loss = 0.08452801\n",
      "loss = 0.07050853\n",
      "loss = 0.2590575\n",
      "loss = 0.042890906\n",
      "loss = 0.13630028\n",
      "loss = 0.069976985\n",
      "loss = 0.045895703\n",
      "loss = 0.027528185\n",
      "loss = 0.15093167\n",
      "loss = 0.0950695\n",
      "loss = 0.06549587\n",
      "loss = 0.10863395\n",
      "loss = 0.055804536\n",
      "loss = 0.028136313\n",
      "loss = 0.03913158\n",
      "loss = 0.05022821\n",
      "loss = 0.22420603\n",
      "loss = 0.027483702\n",
      "loss = 0.06941883\n",
      "loss = 0.032025218\n",
      "loss = 0.059246752\n",
      "loss = 0.055069983\n",
      "loss = 0.02128585\n",
      "loss = 0.18319857\n",
      "loss = 0.072758675\n",
      "loss = 0.06140344\n",
      "loss = 0.104471505\n",
      "loss = 0.11934522\n",
      "loss = 0.06719853\n",
      "loss = 0.021785505\n",
      "loss = 0.22512844\n",
      "loss = 0.085409015\n",
      "loss = 0.15112169\n",
      "loss = 0.04215078\n",
      "loss = 0.027333861\n",
      "loss = 0.15036984\n",
      "loss = 0.11255473\n",
      "loss = 0.019916015\n",
      "loss = 0.049427234\n",
      "loss = 0.106882565\n",
      "loss = 0.13852572\n",
      "loss = 0.082441196\n",
      "loss = 0.026741728\n",
      "loss = 0.08690693\n",
      "loss = 0.048929244\n",
      "loss = 0.01225452\n",
      "loss = 0.14406227\n",
      "loss = 0.081855275\n",
      "loss = 0.015471388\n",
      "loss = 0.027063418\n",
      "loss = 0.03537993\n",
      "loss = 0.08409547\n",
      "loss = 0.24315338\n",
      "loss = 0.11788377\n",
      "loss = 0.072477125\n",
      "loss = 0.040678825\n",
      "loss = 0.046100482\n",
      "loss = 0.22534283\n",
      "loss = 0.107122876\n",
      "loss = 0.06396433\n",
      "loss = 0.01983783\n",
      "loss = 0.017429924\n",
      "loss = 0.041498475\n",
      "loss = 0.028469095\n",
      "loss = 0.04243167\n",
      "loss = 0.16922127\n",
      "loss = 0.10210469\n",
      "loss = 0.040707476\n",
      "loss = 0.06963902\n",
      "loss = 0.13366894\n",
      "loss = 0.061695516\n",
      "loss = 0.0726261\n",
      "loss = 0.024396434\n",
      "loss = 0.15639688\n",
      "loss = 0.50957906\n",
      "loss = 0.02889486\n",
      "loss = 0.010235452\n",
      "loss = 0.026072975\n",
      "loss = 0.027622983\n",
      "loss = 0.023677984\n",
      "loss = 0.07921447\n",
      "loss = 0.11809076\n",
      "loss = 0.019503882\n",
      "loss = 0.20946981\n",
      "loss = 0.2572813\n",
      "loss = 0.04278442\n",
      "loss = 0.063984014\n",
      "loss = 0.054615986\n",
      "loss = 0.03530675\n",
      "loss = 0.08448175\n",
      "loss = 0.09083818\n",
      "loss = 0.028258335\n",
      "loss = 0.07326851\n",
      "loss = 0.14917345\n",
      "loss = 0.0464616\n",
      "loss = 0.15231568\n",
      "loss = 0.04993865\n",
      "loss = 0.050720945\n",
      "loss = 0.005383686\n",
      "loss = 0.17806283\n",
      "loss = 0.0518639\n",
      "loss = 0.07151301\n",
      "loss = 0.02927372\n",
      "loss = 0.005926908\n",
      "loss = 0.06863284\n",
      "loss = 0.05710339\n",
      "loss = 0.026557904\n",
      "loss = 0.012357472\n",
      "loss = 0.079496644\n",
      "loss = 0.014430046\n",
      "loss = 0.026658123\n",
      "loss = 0.007848157\n",
      "loss = 0.086451896\n",
      "loss = 0.047574963\n",
      "loss = 0.03252928\n",
      "loss = 0.036490135\n",
      "loss = 0.11084631\n",
      "loss = 0.06297242\n",
      "loss = 0.10634873\n",
      "loss = 0.069403365\n",
      "loss = 0.052838095\n",
      "loss = 0.11431332\n",
      "loss = 0.06477282\n",
      "loss = 0.02341788\n",
      "loss = 0.10605187\n",
      "loss = 0.1192857\n",
      "loss = 0.11196545\n",
      "loss = 0.19964975\n",
      "loss = 0.13788274\n",
      "loss = 0.004785291\n",
      "loss = 0.03895649\n",
      "loss = 0.020419538\n",
      "loss = 0.029406084\n",
      "loss = 0.0071041556\n",
      "loss = 0.11039199\n",
      "loss = 0.13910303\n",
      "loss = 0.09111868\n",
      "loss = 0.035146296\n",
      "loss = 0.12601775\n",
      "loss = 0.08295869\n",
      "loss = 0.26921943\n",
      "loss = 0.13274956\n",
      "loss = 0.17375526\n",
      "loss = 0.09045756\n",
      "loss = 0.02205608\n",
      "loss = 0.015569858\n",
      "loss = 0.008732496\n",
      "loss = 0.08593324\n",
      "loss = 0.07443694\n",
      "loss = 0.022120664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.1499823\n",
      "loss = 0.06967993\n",
      "loss = 0.021616928\n",
      "loss = 0.08234666\n",
      "loss = 0.044603504\n",
      "loss = 0.038872056\n",
      "loss = 0.13495472\n",
      "loss = 0.074697524\n",
      "loss = 0.019281251\n",
      "loss = 0.02260243\n",
      "loss = 0.046705265\n",
      "loss = 0.018069021\n",
      "loss = 0.016376792\n",
      "loss = 0.036308832\n",
      "loss = 0.13606985\n",
      "loss = 0.12702611\n",
      "loss = 0.14986548\n",
      "loss = 0.27866364\n",
      "loss = 0.23795818\n",
      "loss = 0.23788562\n",
      "loss = 0.061466094\n",
      "loss = 0.038024202\n",
      "loss = 0.0694355\n",
      "loss = 0.099811405\n",
      "loss = 0.09395011\n",
      "loss = 0.0922581\n",
      "loss = 0.11194843\n",
      "loss = 0.024304138\n",
      "loss = 0.092324115\n",
      "loss = 0.23262656\n",
      "loss = 0.36034223\n",
      "loss = 0.08320829\n",
      "loss = 0.25187096\n",
      "loss = 0.025355311\n",
      "loss = 0.02153849\n",
      "loss = 0.035243038\n",
      "loss = 0.18218462\n",
      "loss = 0.06623466\n",
      "loss = 0.11131625\n",
      "loss = 0.0508364\n",
      "loss = 0.06624126\n",
      "loss = 0.027992368\n",
      "loss = 0.07489914\n",
      "loss = 0.115824744\n",
      "loss = 0.049079843\n",
      "loss = 0.09832927\n",
      "loss = 0.052439857\n",
      "loss = 0.14190705\n",
      "loss = 0.13035633\n",
      "loss = 0.032858886\n",
      "loss = 0.013568744\n",
      "loss = 0.02885957\n",
      "loss = 0.011569806\n",
      "loss = 0.033484567\n",
      "loss = 0.046614684\n",
      "loss = 0.04321261\n",
      "loss = 0.017205\n",
      "loss = 0.011476874\n",
      "loss = 0.014876859\n",
      "loss = 0.045235135\n",
      "loss = 0.07934661\n",
      "loss = 0.08439399\n",
      "loss = 0.22674553\n",
      "loss = 0.09608556\n",
      "loss = 0.14501002\n",
      "loss = 0.098244265\n",
      "loss = 0.014081694\n",
      "loss = 0.051561438\n",
      "loss = 0.19788799\n",
      "loss = 0.018795237\n",
      "loss = 0.04184152\n",
      "loss = 0.30210298\n",
      "loss = 0.23527746\n",
      "loss = 0.27217022\n",
      "loss = 0.15882808\n",
      "loss = 0.07335225\n",
      "loss = 0.12056348\n",
      "loss = 0.14151879\n",
      "loss = 0.09126483\n",
      "loss = 0.06147194\n",
      "loss = 0.004686049\n",
      "loss = 0.10233536\n",
      "loss = 0.124349914\n",
      "loss = 0.011455475\n",
      "loss = 0.12595484\n",
      "loss = 0.14595854\n",
      "loss = 0.19323549\n",
      "loss = 0.08825861\n",
      "loss = 0.07836235\n",
      "loss = 0.13883404\n",
      "loss = 0.05218199\n",
      "loss = 0.02379046\n",
      "loss = 0.121274345\n",
      "loss = 0.15034862\n",
      "loss = 0.018567614\n",
      "loss = 0.057363205\n",
      "loss = 0.11839646\n",
      "loss = 0.07301032\n",
      "loss = 0.018315881\n",
      "loss = 0.032092277\n",
      "loss = 0.116985664\n",
      "loss = 0.018772991\n",
      "loss = 0.008294517\n",
      "loss = 0.07014515\n",
      "loss = 0.029135566\n",
      "loss = 0.06619161\n",
      "loss = 0.09674337\n",
      "loss = 0.077591494\n",
      "loss = 0.07574922\n",
      "loss = 0.008492638\n",
      "loss = 0.012483127\n",
      "loss = 0.03119346\n",
      "loss = 0.00768607\n",
      "loss = 0.023406107\n",
      "loss = 0.23994353\n",
      "loss = 0.24120015\n",
      "loss = 0.14297833\n",
      "loss = 0.012695453\n",
      "loss = 0.29261273\n",
      "loss = 0.047421258\n",
      "loss = 0.041632324\n",
      "loss = 0.108735144\n",
      "loss = 0.1267404\n",
      "loss = 0.055693902\n",
      "loss = 0.122149155\n",
      "loss = 0.037667837\n",
      "loss = 0.012897472\n",
      "loss = 0.012654701\n",
      "loss = 0.091125995\n",
      "loss = 0.045076236\n",
      "loss = 0.1043624\n",
      "loss = 0.020627592\n",
      "loss = 0.15926504\n",
      "loss = 0.131968\n",
      "loss = 0.08279145\n",
      "loss = 0.07464938\n",
      "loss = 0.08867183\n",
      "loss = 0.042506978\n",
      "loss = 0.042540696\n",
      "loss = 0.014890862\n",
      "loss = 0.03192143\n",
      "loss = 0.035566494\n",
      "loss = 0.012495551\n",
      "loss = 0.03746246\n",
      "loss = 0.04879462\n",
      "loss = 0.18427949\n",
      "loss = 0.09781036\n",
      "loss = 0.024788618\n",
      "loss = 0.07246678\n",
      "loss = 0.12283521\n",
      "loss = 0.017708862\n",
      "loss = 0.10152988\n",
      "loss = 0.007928266\n",
      "loss = 0.10210793\n",
      "loss = 0.042318054\n",
      "loss = 0.10012853\n",
      "loss = 0.013073481\n",
      "loss = 0.0099185165\n",
      "loss = 0.082518995\n",
      "loss = 0.013771765\n",
      "loss = 0.03484356\n",
      "loss = 0.08104086\n",
      "loss = 0.03504265\n",
      "loss = 0.044601385\n",
      "loss = 0.030689975\n",
      "loss = 0.011879421\n",
      "loss = 0.022062682\n",
      "loss = 0.039058972\n",
      "loss = 0.037740298\n",
      "loss = 0.0053390255\n",
      "loss = 0.07366561\n",
      "loss = 0.0270953\n",
      "loss = 0.053163588\n",
      "loss = 0.039173163\n",
      "loss = 0.06426006\n",
      "loss = 0.021638623\n",
      "loss = 0.05316388\n",
      "loss = 0.14263481\n",
      "loss = 0.039553285\n",
      "loss = 0.021327402\n",
      "loss = 0.029544527\n",
      "loss = 0.023658965\n",
      "loss = 0.19258204\n",
      "loss = 0.033804033\n",
      "loss = 0.046889193\n",
      "loss = 0.014099803\n",
      "loss = 0.065367825\n",
      "loss = 0.005000586\n",
      "loss = 0.047409758\n",
      "loss = 0.07655594\n",
      "loss = 0.09409349\n",
      "loss = 0.042993892\n",
      "loss = 0.026752308\n",
      "loss = 0.013222335\n",
      "loss = 0.026087992\n",
      "loss = 0.11338395\n",
      "loss = 0.07050992\n",
      "loss = 0.06862038\n",
      "loss = 0.02231806\n",
      "loss = 0.0889753\n",
      "loss = 0.26373148\n",
      "loss = 0.076739706\n",
      "loss = 0.17895874\n",
      "loss = 0.029761778\n",
      "loss = 0.011471412\n",
      "loss = 0.036665156\n",
      "loss = 0.021873333\n",
      "loss = 0.09448285\n",
      "loss = 0.10892006\n",
      "loss = 0.1390962\n",
      "loss = 0.13049565\n",
      "loss = 0.024288272\n",
      "loss = 0.010356881\n",
      "loss = 0.022132494\n",
      "loss = 0.08236185\n",
      "loss = 0.11877364\n",
      "loss = 0.005700886\n",
      "loss = 0.14112122\n",
      "loss = 0.16711602\n",
      "loss = 0.02047643\n",
      "loss = 0.03451954\n",
      "loss = 0.015489118\n",
      "loss = 0.047938395\n",
      "loss = 0.041385233\n",
      "loss = 0.04447387\n",
      "loss = 0.067564875\n",
      "loss = 0.10494403\n",
      "loss = 0.06992847\n",
      "loss = 0.09087865\n",
      "loss = 0.08411767\n",
      "loss = 0.05260327\n",
      "loss = 0.023217846\n",
      "loss = 0.050745912\n",
      "loss = 0.03327517\n",
      "loss = 0.017360035\n",
      "loss = 0.08200571\n",
      "loss = 0.012619527\n",
      "loss = 0.02561518\n",
      "loss = 0.027265154\n",
      "loss = 0.05191127\n",
      "loss = 0.035790093\n",
      "loss = 0.102062464\n",
      "loss = 0.08015749\n",
      "loss = 0.11311431\n",
      "loss = 0.07422285\n",
      "loss = 0.025274199\n",
      "loss = 0.07664135\n",
      "loss = 0.009601738\n",
      "loss = 0.11602934\n",
      "loss = 0.05169366\n",
      "loss = 0.08643669\n",
      "loss = 0.035794906\n",
      "loss = 0.012379041\n",
      "loss = 0.02213781\n",
      "loss = 0.0514042\n",
      "loss = 0.011341363\n",
      "loss = 0.15354013\n",
      "loss = 0.055308297\n",
      "loss = 0.017127885\n",
      "loss = 0.08657505\n",
      "loss = 0.12400393\n",
      "loss = 0.05620417\n",
      "loss = 0.05349128\n",
      "loss = 0.031061223\n",
      "loss = 0.056668617\n",
      "loss = 0.026859416\n",
      "loss = 0.1450982\n",
      "loss = 0.09127571\n",
      "loss = 0.032855667\n",
      "loss = 0.056656178\n",
      "loss = 0.029082784\n",
      "loss = 0.03751142\n",
      "loss = 0.14945515\n",
      "loss = 0.036033988\n",
      "loss = 0.019332577\n",
      "loss = 0.089750454\n",
      "loss = 0.0135121755\n",
      "loss = 0.0120690325\n",
      "loss = 0.18188733\n",
      "loss = 0.09667875\n",
      "loss = 0.086930096\n",
      "loss = 0.15751316\n",
      "loss = 0.03610216\n",
      "loss = 0.012645653\n",
      "loss = 0.037346486\n",
      "loss = 0.099135235\n",
      "loss = 0.028052436\n",
      "loss = 0.020295225\n",
      "loss = 0.08959418\n",
      "loss = 0.03843326\n",
      "loss = 0.036125414\n",
      "loss = 0.0064859223\n",
      "loss = 0.13187695\n",
      "loss = 0.124135636\n",
      "loss = 0.07150337\n",
      "loss = 0.07963243\n",
      "loss = 0.050226633\n",
      "loss = 0.007854173\n",
      "loss = 0.06774333\n",
      "loss = 0.17951381\n",
      "loss = 0.1408276\n",
      "loss = 0.011354026\n",
      "loss = 0.011874121\n",
      "loss = 0.068843834\n",
      "loss = 0.19575462\n",
      "loss = 0.04633311\n",
      "loss = 0.14722177\n",
      "loss = 0.04837345\n",
      "loss = 0.04268698\n",
      "loss = 0.07132532\n",
      "loss = 0.006542458\n",
      "loss = 0.0973263\n",
      "loss = 0.015934533\n",
      "loss = 0.025742617\n",
      "loss = 0.054589637\n",
      "loss = 0.06470337\n",
      "loss = 0.10857397\n",
      "loss = 0.0039949\n",
      "loss = 0.014820625\n",
      "loss = 0.095478505\n",
      "loss = 0.08586168\n",
      "loss = 0.014536954\n",
      "loss = 0.017105151\n",
      "loss = 0.08245669\n",
      "loss = 0.07115097\n",
      "loss = 0.09604095\n",
      "loss = 0.09568054\n",
      "loss = 0.041325618\n",
      "loss = 0.0515384\n",
      "loss = 0.021298109\n",
      "loss = 0.08397447\n",
      "loss = 0.047242165\n",
      "loss = 0.06198114\n",
      "loss = 0.03840446\n",
      "loss = 0.020698333\n",
      "loss = 0.038893055\n",
      "loss = 0.007950624\n",
      "loss = 0.011514865\n",
      "loss = 0.074864134\n",
      "loss = 0.017691474\n",
      "loss = 0.013053916\n",
      "loss = 0.21821654\n",
      "loss = 0.046866454\n",
      "loss = 0.007576391\n",
      "loss = 0.010601638\n",
      "loss = 0.03574766\n",
      "loss = 0.03396602\n",
      "loss = 0.019688882\n",
      "loss = 0.014374584\n",
      "loss = 0.02141678\n",
      "loss = 0.18947358\n",
      "loss = 0.06867265\n",
      "loss = 0.066057675\n",
      "loss = 0.020790413\n",
      "loss = 0.23242499\n",
      "loss = 0.09635658\n",
      "loss = 0.14762594\n",
      "loss = 0.13646202\n",
      "loss = 0.12981991\n",
      "loss = 0.13584967\n",
      "loss = 0.11766751\n",
      "loss = 0.17955431\n",
      "loss = 0.002423125\n",
      "loss = 0.078266405\n",
      "loss = 0.05115819\n",
      "loss = 0.016129665\n",
      "loss = 0.059811708\n",
      "loss = 0.02895814\n",
      "loss = 0.048012666\n",
      "loss = 0.017760525\n",
      "loss = 0.08631201\n",
      "loss = 0.060331915\n",
      "loss = 0.182912\n",
      "loss = 0.110251695\n",
      "loss = 0.008971158\n",
      "loss = 0.076566465\n",
      "loss = 0.12730163\n",
      "loss = 0.058181368\n",
      "loss = 0.105596855\n",
      "loss = 0.016138013\n",
      "loss = 0.045279685\n",
      "loss = 0.034381837\n",
      "loss = 0.03571579\n",
      "loss = 0.057536606\n",
      "loss = 0.052703623\n",
      "loss = 0.015915733\n",
      "loss = 0.08429084\n",
      "loss = 0.07275088\n",
      "loss = 0.20165893\n",
      "loss = 0.023927234\n",
      "loss = 0.06273713\n",
      "loss = 0.02191152\n",
      "loss = 0.038254265\n",
      "loss = 0.04587236\n",
      "loss = 0.08397876\n",
      "loss = 0.31751102\n",
      "loss = 0.042532217\n",
      "loss = 0.092283286\n",
      "loss = 0.2452542\n",
      "loss = 0.10016541\n",
      "loss = 0.039667346\n",
      "loss = 0.035687603\n",
      "loss = 0.14263745\n",
      "loss = 0.072880074\n",
      "loss = 0.027346537\n",
      "loss = 0.016339974\n",
      "loss = 0.030313969\n",
      "loss = 0.025033392\n",
      "loss = 0.16871668\n",
      "loss = 0.069361344\n",
      "loss = 0.017080627\n",
      "loss = 0.011611332\n",
      "loss = 0.024529953\n",
      "loss = 0.023780236\n",
      "loss = 0.06293723\n",
      "loss = 0.073286235\n",
      "loss = 0.019730717\n",
      "loss = 0.1422266\n",
      "loss = 0.035521965\n",
      "loss = 0.041837268\n",
      "loss = 0.024388997\n",
      "loss = 0.0968896\n",
      "loss = 0.08347125\n",
      "loss = 0.14767061\n",
      "loss = 0.010951301\n",
      "loss = 0.17823431\n",
      "loss = 0.02216442\n",
      "loss = 0.03722029\n",
      "loss = 0.05428841\n",
      "loss = 0.054681923\n",
      "loss = 0.10279752\n",
      "loss = 0.021333631\n",
      "loss = 0.008234965\n",
      "loss = 0.0306015\n",
      "loss = 0.0064524077\n",
      "loss = 0.04194066\n",
      "loss = 0.07317879\n",
      "loss = 0.011480888\n",
      "loss = 0.03585715\n",
      "loss = 0.038814306\n",
      "loss = 0.048389047\n",
      "loss = 0.036002077\n",
      "loss = 0.03835249\n",
      "loss = 0.03867397\n",
      "loss = 0.08792465\n",
      "loss = 0.021388339\n",
      "loss = 0.020140396\n",
      "loss = 0.026646912\n",
      "loss = 0.06928159\n",
      "loss = 0.056759767\n",
      "loss = 0.009905995\n",
      "loss = 0.019854687\n",
      "loss = 0.042790785\n",
      "loss = 0.015196835\n",
      "loss = 0.097727284\n",
      "loss = 0.0040353704\n",
      "loss = 0.18050319\n",
      "loss = 0.090246335\n",
      "loss = 0.052254684\n",
      "loss = 0.044660933\n",
      "loss = 0.029110793\n",
      "loss = 0.011837658\n",
      "loss = 0.055763807\n",
      "loss = 0.012728413\n",
      "loss = 0.032852564\n",
      "loss = 0.00959599\n",
      "loss = 0.03621389\n",
      "loss = 0.010785544\n",
      "loss = 0.046883106\n",
      "loss = 0.008661816\n",
      "loss = 0.0965801\n",
      "loss = 0.049183786\n",
      "loss = 0.06701942\n",
      "loss = 0.043158136\n",
      "loss = 0.07457642\n",
      "loss = 0.008697746\n",
      "loss = 0.03448227\n",
      "loss = 0.037341382\n",
      "loss = 0.01899623\n",
      "loss = 0.08643522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.009563333\n",
      "loss = 0.032892942\n",
      "loss = 0.050584063\n",
      "loss = 0.033828877\n",
      "loss = 0.019731648\n",
      "loss = 0.005977612\n",
      "loss = 0.012636336\n",
      "loss = 0.04064214\n",
      "loss = 0.030056853\n",
      "loss = 0.09161624\n",
      "loss = 0.0066828253\n",
      "loss = 0.041424185\n",
      "loss = 0.07682994\n",
      "loss = 0.011782762\n",
      "loss = 0.012441025\n",
      "loss = 0.0060166866\n",
      "loss = 0.020220475\n",
      "loss = 0.02221181\n",
      "loss = 0.013231311\n",
      "loss = 0.028693188\n",
      "loss = 0.018208157\n",
      "loss = 0.009710362\n",
      "loss = 0.01035303\n",
      "loss = 0.2067284\n",
      "loss = 0.1184891\n",
      "loss = 0.024093635\n",
      "loss = 0.023487996\n",
      "loss = 0.088068664\n",
      "loss = 0.009293942\n",
      "loss = 0.1264111\n",
      "loss = 0.034827583\n",
      "loss = 0.00925018\n",
      "loss = 0.22049741\n",
      "loss = 0.06549744\n",
      "loss = 0.13205317\n",
      "loss = 0.14246239\n",
      "loss = 0.13410702\n",
      "loss = 0.08239296\n",
      "loss = 0.08183511\n",
      "loss = 0.019117162\n",
      "loss = 0.0088732615\n",
      "loss = 0.060845196\n",
      "loss = 0.042874042\n",
      "loss = 0.0039134705\n",
      "loss = 0.0104563935\n",
      "loss = 0.051712453\n",
      "loss = 0.093725696\n",
      "loss = 0.017368242\n",
      "loss = 0.057959974\n",
      "loss = 0.05505227\n",
      "loss = 0.011468669\n",
      "loss = 0.093250275\n",
      "loss = 0.023138631\n",
      "loss = 0.09813279\n",
      "loss = 0.006881789\n",
      "loss = 0.07374109\n",
      "loss = 0.038862277\n",
      "loss = 0.008210788\n",
      "loss = 0.05661613\n",
      "loss = 0.12491731\n",
      "loss = 0.024138693\n",
      "loss = 0.22128329\n",
      "loss = 0.010042844\n",
      "loss = 0.030067254\n",
      "loss = 0.027312329\n",
      "loss = 0.17780754\n",
      "loss = 0.0077385027\n",
      "loss = 0.028312478\n",
      "loss = 0.055241637\n",
      "loss = 0.05153848\n",
      "loss = 0.013148572\n",
      "loss = 0.042856805\n",
      "loss = 0.012107761\n",
      "loss = 0.015149492\n",
      "loss = 0.0053433934\n",
      "loss = 0.04086627\n",
      "loss = 0.017065614\n",
      "loss = 0.037768997\n",
      "loss = 0.007223733\n",
      "loss = 0.035072148\n",
      "loss = 0.020364475\n",
      "loss = 0.09177717\n",
      "loss = 0.05199269\n",
      "loss = 0.084447116\n",
      "loss = 0.00794714\n",
      "loss = 0.1054569\n",
      "loss = 0.010580532\n",
      "loss = 0.008640871\n",
      "loss = 0.119377784\n",
      "loss = 0.110346474\n",
      "loss = 0.04779365\n",
      "loss = 0.043509264\n",
      "loss = 0.027115555\n",
      "loss = 0.05537217\n",
      "loss = 0.014735174\n",
      "loss = 0.033116527\n",
      "loss = 0.018917464\n",
      "loss = 0.06325842\n",
      "loss = 0.0526696\n",
      "loss = 0.17855233\n",
      "loss = 0.046441685\n",
      "loss = 0.021999754\n",
      "loss = 0.11250558\n",
      "loss = 0.019113295\n",
      "loss = 0.007797893\n",
      "loss = 0.013161714\n",
      "loss = 0.03129536\n",
      "loss = 0.059208445\n",
      "loss = 0.029895948\n",
      "loss = 0.030114517\n",
      "loss = 0.06908702\n",
      "loss = 0.14692721\n",
      "loss = 0.06634649\n",
      "loss = 0.011990158\n",
      "loss = 0.10645984\n",
      "loss = 0.027631782\n",
      "loss = 0.058996946\n",
      "loss = 0.011995695\n",
      "loss = 0.04470165\n",
      "loss = 0.08995305\n",
      "loss = 0.1231753\n",
      "loss = 0.07411947\n",
      "loss = 0.087498635\n",
      "loss = 0.027532058\n",
      "loss = 0.055586383\n",
      "loss = 0.038147457\n",
      "loss = 0.013322163\n",
      "loss = 0.020665273\n",
      "loss = 0.058237776\n",
      "loss = 0.029599067\n",
      "loss = 0.09312093\n",
      "loss = 0.116840936\n",
      "loss = 0.018163238\n",
      "loss = 0.010032698\n",
      "loss = 0.03579515\n",
      "loss = 0.042154312\n",
      "loss = 0.079224095\n",
      "loss = 0.14227346\n",
      "loss = 0.053642686\n",
      "loss = 0.039329413\n",
      "loss = 0.19785905\n",
      "loss = 0.03929333\n",
      "loss = 0.08737125\n",
      "loss = 0.04626835\n",
      "loss = 0.0068324544\n",
      "loss = 0.03131027\n",
      "loss = 0.07133217\n",
      "loss = 0.110505536\n",
      "loss = 0.06478944\n",
      "loss = 0.062953375\n",
      "loss = 0.016929433\n",
      "loss = 0.15692762\n",
      "loss = 0.06295286\n",
      "loss = 0.012096806\n",
      "loss = 0.02009275\n",
      "loss = 0.06322202\n",
      "loss = 0.0066155395\n",
      "loss = 0.022226155\n",
      "loss = 0.029072868\n",
      "loss = 0.05666586\n",
      "loss = 0.01543466\n",
      "loss = 0.024127344\n",
      "loss = 0.012436406\n",
      "loss = 0.0929867\n",
      "loss = 0.02942981\n",
      "loss = 0.24290964\n",
      "loss = 0.075756714\n",
      "loss = 0.078211755\n",
      "loss = 0.060376268\n",
      "loss = 0.0057070525\n",
      "loss = 0.026276972\n",
      "loss = 0.012995493\n",
      "loss = 0.024427697\n",
      "loss = 0.0091243535\n",
      "loss = 0.03201342\n",
      "loss = 0.07298084\n",
      "loss = 0.023289599\n",
      "loss = 0.048637014\n",
      "loss = 0.020213481\n",
      "loss = 0.019103926\n",
      "loss = 0.021927515\n",
      "loss = 0.0227619\n",
      "loss = 0.008037378\n",
      "loss = 0.10128729\n",
      "loss = 0.104601264\n",
      "loss = 0.13362482\n",
      "loss = 0.031713687\n",
      "loss = 0.022780655\n",
      "loss = 0.005797048\n",
      "loss = 0.10924392\n",
      "loss = 0.117444366\n",
      "loss = 0.02078376\n",
      "loss = 0.011898048\n",
      "loss = 0.06355273\n",
      "loss = 0.051177554\n",
      "loss = 0.053261396\n",
      "loss = 0.027109867\n",
      "loss = 0.1540067\n",
      "loss = 0.012553346\n",
      "loss = 0.018480707\n",
      "loss = 0.008236406\n",
      "loss = 0.07034339\n",
      "loss = 0.031905323\n",
      "loss = 0.040965345\n",
      "loss = 0.055454303\n",
      "loss = 0.114577256\n",
      "loss = 0.04003908\n",
      "loss = 0.014599687\n",
      "loss = 0.065109305\n",
      "loss = 0.004256851\n",
      "loss = 0.04168994\n",
      "loss = 0.19260672\n",
      "loss = 0.014467955\n",
      "loss = 0.036569584\n",
      "loss = 0.0049383803\n",
      "loss = 0.04013241\n",
      "loss = 0.012237925\n",
      "loss = 0.008540014\n",
      "loss = 0.028451325\n",
      "loss = 0.06910873\n",
      "loss = 0.012995317\n",
      "loss = 0.11617904\n",
      "loss = 0.007851896\n",
      "loss = 0.0074327453\n",
      "loss = 0.020863213\n",
      "loss = 0.023683712\n",
      "loss = 0.03396476\n",
      "loss = 0.041234877\n",
      "loss = 0.033666547\n",
      "loss = 0.16844773\n",
      "loss = 0.009257283\n",
      "loss = 0.0037435866\n",
      "loss = 0.019668566\n",
      "loss = 0.032458887\n",
      "loss = 0.032854773\n",
      "loss = 0.03571851\n",
      "loss = 0.013665275\n",
      "loss = 0.00503261\n",
      "loss = 0.049829118\n",
      "loss = 0.049399476\n",
      "loss = 0.008419409\n",
      "loss = 0.016395506\n",
      "loss = 0.0020277458\n",
      "loss = 0.072129115\n",
      "loss = 0.23202428\n",
      "loss = 0.026291067\n",
      "loss = 0.029239252\n",
      "loss = 0.016899241\n",
      "loss = 0.019186642\n",
      "loss = 0.18899374\n",
      "loss = 0.004478543\n",
      "loss = 0.058892947\n",
      "loss = 0.13309653\n",
      "loss = 0.07884402\n",
      "loss = 0.018043825\n",
      "loss = 0.048876513\n",
      "loss = 0.016179493\n",
      "loss = 0.10069117\n",
      "loss = 0.024015473\n",
      "loss = 0.008681643\n",
      "loss = 0.07942212\n",
      "loss = 0.11387345\n",
      "loss = 0.019367943\n",
      "loss = 0.021725865\n",
      "loss = 0.005509376\n",
      "loss = 0.17996591\n",
      "loss = 0.06981435\n",
      "loss = 0.034812987\n",
      "loss = 0.0031599663\n",
      "loss = 0.0054735877\n",
      "loss = 0.036647014\n",
      "loss = 0.051631738\n",
      "loss = 0.01916463\n",
      "loss = 0.024275828\n",
      "loss = 0.018043566\n",
      "loss = 0.018493999\n",
      "loss = 0.029919606\n",
      "loss = 0.0386184\n",
      "loss = 0.027268928\n",
      "loss = 0.037966657\n",
      "loss = 0.031577908\n",
      "loss = 0.07814956\n",
      "loss = 0.01843227\n",
      "loss = 0.029119983\n",
      "loss = 0.007793793\n",
      "loss = 0.023331514\n",
      "loss = 0.014666411\n",
      "loss = 0.051419973\n",
      "loss = 0.07317465\n",
      "loss = 0.06336491\n",
      "loss = 0.049830005\n",
      "loss = 0.03689085\n",
      "loss = 0.01370142\n",
      "loss = 0.03112203\n",
      "loss = 0.024584107\n",
      "loss = 0.010807145\n",
      "loss = 0.028698271\n",
      "loss = 0.025509942\n",
      "loss = 0.06084971\n",
      "loss = 0.005115838\n",
      "loss = 0.080316484\n",
      "loss = 0.011031849\n",
      "loss = 0.03684842\n",
      "loss = 0.04605814\n",
      "loss = 0.026034802\n",
      "loss = 0.013329435\n",
      "loss = 0.017721718\n",
      "loss = 0.03993518\n",
      "loss = 0.013283884\n",
      "loss = 0.0106487535\n",
      "loss = 0.012336751\n",
      "loss = 0.03810084\n",
      "loss = 0.009200039\n",
      "loss = 0.006899516\n",
      "loss = 0.060291562\n",
      "loss = 0.015892474\n",
      "loss = 0.15305653\n",
      "loss = 0.001888266\n",
      "loss = 0.00944776\n",
      "loss = 0.086135425\n",
      "loss = 0.007926539\n",
      "loss = 0.015356436\n",
      "loss = 0.040382184\n",
      "loss = 0.06559898\n",
      "loss = 0.14958033\n",
      "loss = 0.029518664\n",
      "loss = 0.06180101\n",
      "loss = 0.00572915\n",
      "loss = 0.069402985\n",
      "loss = 0.015114458\n",
      "loss = 0.02754266\n",
      "loss = 0.031241698\n",
      "loss = 0.016200874\n",
      "loss = 0.047349192\n",
      "loss = 0.0067137424\n",
      "loss = 0.037446246\n",
      "loss = 0.052156053\n",
      "loss = 0.02032554\n",
      "loss = 0.017100465\n",
      "loss = 0.102229744\n",
      "loss = 0.024108773\n",
      "loss = 0.016409636\n",
      "loss = 0.012412576\n",
      "loss = 0.029755875\n",
      "loss = 0.03146863\n",
      "loss = 0.014634431\n",
      "loss = 0.024521302\n",
      "loss = 0.058958292\n",
      "loss = 0.010295706\n",
      "loss = 0.004715807\n",
      "loss = 0.012344823\n",
      "loss = 0.02393904\n",
      "loss = 0.018217776\n",
      "loss = 0.03671532\n",
      "loss = 0.015358663\n",
      "loss = 0.05034623\n",
      "loss = 0.0030004596\n",
      "loss = 0.040174052\n",
      "loss = 0.098298155\n",
      "loss = 0.056555048\n",
      "loss = 0.060244754\n",
      "loss = 0.0070803724\n",
      "loss = 0.0040333625\n",
      "loss = 0.009630505\n",
      "loss = 0.031327773\n",
      "loss = 0.01285959\n",
      "loss = 0.02332694\n",
      "loss = 0.032096125\n",
      "loss = 0.030078353\n",
      "loss = 0.020358581\n",
      "loss = 0.020970218\n",
      "loss = 0.017364051\n",
      "loss = 0.18714726\n",
      "loss = 0.010814611\n",
      "loss = 0.07298377\n",
      "loss = 0.046179526\n",
      "loss = 0.014767493\n",
      "loss = 0.014959169\n",
      "loss = 0.0650255\n",
      "loss = 0.036731753\n",
      "loss = 0.076099\n",
      "loss = 0.019846568\n",
      "loss = 0.04718481\n",
      "loss = 0.033428226\n",
      "loss = 0.107189976\n",
      "loss = 0.005903435\n",
      "loss = 0.015324423\n",
      "loss = 0.00489734\n",
      "loss = 0.009642085\n",
      "loss = 0.018903878\n",
      "loss = 0.017722797\n",
      "loss = 0.037509058\n",
      "loss = 0.013825198\n",
      "loss = 0.113743015\n",
      "loss = 0.055371337\n",
      "loss = 0.07383043\n",
      "loss = 0.037762135\n",
      "loss = 0.0127746565\n",
      "loss = 0.013644921\n",
      "loss = 0.023994427\n",
      "loss = 0.0068650967\n",
      "loss = 0.017248077\n",
      "loss = 0.010682552\n",
      "loss = 0.050701536\n",
      "loss = 0.011669484\n",
      "loss = 0.01825334\n",
      "loss = 0.027145702\n",
      "loss = 0.009389592\n",
      "loss = 0.0075694015\n",
      "loss = 0.017649556\n",
      "loss = 0.020155324\n",
      "loss = 0.007198632\n",
      "loss = 0.037484176\n",
      "loss = 0.020743655\n",
      "loss = 0.04194569\n",
      "loss = 0.10320806\n",
      "loss = 0.028721832\n",
      "loss = 0.0069987676\n",
      "loss = 0.03507803\n",
      "loss = 0.10957138\n",
      "loss = 0.040512968\n",
      "loss = 0.03823207\n",
      "loss = 0.012826356\n",
      "loss = 0.039764456\n",
      "loss = 0.025641652\n",
      "loss = 0.03379568\n",
      "loss = 0.041018557\n",
      "loss = 0.02973729\n",
      "loss = 0.06756987\n",
      "loss = 0.084430434\n",
      "loss = 0.011947565\n",
      "loss = 0.033941284\n",
      "loss = 0.1069977\n",
      "loss = 0.03317134\n",
      "loss = 0.06935139\n",
      "loss = 0.07148108\n",
      "loss = 0.03591335\n",
      "loss = 0.04418536\n",
      "loss = 0.13363585\n",
      "loss = 0.08931511\n",
      "loss = 0.07046393\n",
      "loss = 0.020821575\n",
      "loss = 0.03223271\n",
      "loss = 0.017620992\n",
      "loss = 0.012775812\n",
      "loss = 0.07268467\n",
      "loss = 0.014268603\n",
      "loss = 0.06381309\n",
      "loss = 0.079902396\n",
      "loss = 0.0246253\n",
      "loss = 0.114432365\n",
      "loss = 0.030805591\n",
      "loss = 0.07577239\n",
      "loss = 0.105437174\n",
      "loss = 0.029598257\n",
      "loss = 0.018084882\n",
      "loss = 0.08476116\n",
      "loss = 0.018233363\n",
      "loss = 0.085411176\n",
      "loss = 0.12936881\n",
      "loss = 0.030131118\n",
      "loss = 0.072321095\n",
      "loss = 0.111142166\n",
      "loss = 0.030031726\n",
      "loss = 0.038881227\n",
      "loss = 0.058299564\n",
      "loss = 0.076620005\n",
      "loss = 0.03585866\n",
      "loss = 0.1243534\n",
      "loss = 0.014989356\n",
      "loss = 0.023955174\n",
      "loss = 0.0048213424\n",
      "loss = 0.11560481\n",
      "loss = 0.0033743514\n",
      "loss = 0.08451866\n",
      "loss = 0.0206657\n",
      "loss = 0.13383532\n",
      "loss = 0.043656703\n",
      "loss = 0.033420518\n",
      "loss = 0.04554013\n",
      "loss = 0.04363536\n",
      "loss = 0.073602\n",
      "loss = 0.075198956\n",
      "loss = 0.066860534\n",
      "loss = 0.110189274\n",
      "loss = 0.0075112553\n",
      "loss = 0.029340137\n",
      "loss = 0.0047087357\n",
      "loss = 0.013329668\n",
      "loss = 0.02708043\n",
      "loss = 0.042128187\n",
      "loss = 0.07706999\n",
      "loss = 0.023513535\n",
      "loss = 0.015719248\n",
      "loss = 0.07187379\n",
      "loss = 0.007640123\n",
      "loss = 0.019799132\n",
      "loss = 0.01045876\n",
      "loss = 0.014348593\n",
      "loss = 0.016686479\n",
      "loss = 0.081531696\n",
      "loss = 0.055832427\n",
      "loss = 0.047490995\n",
      "loss = 0.05384751\n",
      "loss = 0.059880123\n",
      "loss = 0.01384753\n",
      "loss = 0.011643225\n",
      "loss = 0.02874734\n",
      "loss = 0.023132518\n",
      "loss = 0.07826797\n",
      "loss = 0.036752786\n",
      "loss = 0.005658959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.07038678\n",
      "loss = 0.019701652\n",
      "loss = 0.057313696\n",
      "loss = 0.004451047\n",
      "loss = 0.010019872\n",
      "loss = 0.018279428\n",
      "loss = 0.014123433\n",
      "loss = 0.04301817\n",
      "loss = 0.054190256\n",
      "loss = 0.06707129\n",
      "loss = 0.0038228515\n",
      "loss = 0.012448358\n",
      "loss = 0.19665666\n",
      "loss = 0.005345825\n",
      "loss = 0.062106974\n",
      "loss = 0.059948716\n",
      "loss = 0.014820865\n",
      "loss = 0.01911294\n",
      "loss = 0.020431086\n",
      "loss = 0.0037834363\n",
      "loss = 0.039719384\n",
      "loss = 0.048127133\n",
      "loss = 0.027971592\n",
      "loss = 0.15624948\n",
      "loss = 0.036484092\n",
      "loss = 0.012666451\n",
      "loss = 0.020791199\n",
      "loss = 0.015339596\n",
      "loss = 0.025310505\n",
      "loss = 0.0042686244\n",
      "loss = 0.047857024\n",
      "loss = 0.026316341\n",
      "loss = 0.059049092\n",
      "loss = 0.2514958\n",
      "loss = 0.041071787\n",
      "loss = 0.0030554177\n",
      "loss = 0.03122313\n",
      "loss = 0.024900023\n",
      "loss = 0.02597797\n",
      "loss = 0.03333556\n",
      "loss = 0.09503198\n",
      "loss = 0.043940917\n",
      "loss = 0.026967935\n",
      "loss = 0.10391432\n",
      "loss = 0.005172981\n",
      "loss = 0.06533689\n",
      "loss = 0.03382592\n",
      "loss = 0.005471224\n",
      "loss = 0.04250169\n",
      "loss = 0.052157342\n",
      "loss = 0.028292468\n",
      "loss = 0.05101505\n",
      "loss = 0.0124023445\n",
      "loss = 0.028413672\n",
      "loss = 0.11973202\n",
      "loss = 0.07900377\n",
      "loss = 0.009143885\n",
      "loss = 0.023606941\n",
      "loss = 0.028137432\n",
      "loss = 0.062205594\n",
      "loss = 0.0151622975\n",
      "loss = 0.038951747\n",
      "loss = 0.08231511\n",
      "loss = 0.008611199\n",
      "loss = 0.03422521\n",
      "loss = 0.010857229\n",
      "loss = 0.06822898\n",
      "loss = 0.023283802\n",
      "loss = 0.0070957937\n",
      "loss = 0.11192133\n",
      "loss = 0.019816\n",
      "loss = 0.011288569\n",
      "loss = 0.006622621\n",
      "loss = 0.0056466903\n",
      "loss = 0.003338903\n",
      "loss = 0.03944086\n",
      "loss = 0.011387868\n",
      "loss = 0.050275955\n",
      "loss = 0.0076426575\n",
      "loss = 0.10112128\n",
      "loss = 0.045173854\n",
      "loss = 0.06182867\n",
      "loss = 0.023480006\n",
      "loss = 0.079853244\n",
      "loss = 0.011026597\n",
      "loss = 0.010009557\n",
      "loss = 0.028923264\n",
      "loss = 0.023375148\n",
      "loss = 0.01759655\n",
      "loss = 0.016869381\n",
      "loss = 0.059844572\n",
      "loss = 0.0017731616\n",
      "loss = 0.0055565517\n",
      "loss = 0.04636403\n",
      "loss = 0.010980659\n",
      "loss = 0.01217348\n",
      "loss = 0.079846285\n",
      "loss = 0.008603845\n",
      "loss = 0.025201194\n",
      "loss = 0.0033958103\n",
      "loss = 0.016419623\n",
      "loss = 0.010447193\n",
      "loss = 0.007966214\n",
      "loss = 0.03906933\n",
      "loss = 0.026926534\n",
      "loss = 0.030357871\n",
      "loss = 0.032527775\n",
      "loss = 0.04039658\n",
      "loss = 0.009458647\n",
      "loss = 0.084607005\n",
      "loss = 0.012603592\n",
      "loss = 0.040421166\n",
      "loss = 0.0048384536\n",
      "loss = 0.0215002\n",
      "loss = 0.044464167\n",
      "loss = 0.049397156\n",
      "loss = 0.027621515\n",
      "loss = 0.027746953\n",
      "loss = 0.008388622\n",
      "loss = 0.0021833442\n",
      "loss = 0.002607844\n",
      "loss = 0.034184597\n",
      "loss = 0.026851058\n",
      "loss = 0.012932544\n",
      "loss = 0.057568513\n",
      "loss = 0.038141705\n",
      "loss = 0.012478486\n",
      "loss = 0.011305748\n",
      "loss = 0.05193026\n",
      "loss = 0.0110946\n",
      "loss = 0.015232331\n",
      "loss = 0.024166089\n",
      "loss = 0.009634965\n",
      "loss = 0.014538013\n",
      "loss = 0.039945465\n",
      "loss = 0.008087432\n",
      "loss = 0.06643681\n",
      "loss = 0.0064473925\n",
      "loss = 0.12461057\n",
      "loss = 0.008824899\n",
      "loss = 0.019775806\n",
      "loss = 0.012395075\n",
      "loss = 0.08618818\n",
      "loss = 0.009163715\n",
      "loss = 0.016472295\n",
      "loss = 0.003967884\n",
      "loss = 0.03598228\n",
      "loss = 0.05024533\n",
      "loss = 0.0060490053\n",
      "loss = 0.013878169\n",
      "loss = 0.009993902\n",
      "loss = 0.05399602\n",
      "loss = 0.029885542\n",
      "loss = 0.019398656\n",
      "loss = 0.0148705505\n",
      "loss = 0.015771383\n",
      "loss = 0.054197103\n",
      "loss = 0.01068823\n",
      "loss = 0.009405725\n",
      "loss = 0.015152073\n",
      "loss = 0.011685328\n",
      "loss = 0.0022883099\n",
      "loss = 0.017692497\n",
      "loss = 0.0072434205\n",
      "loss = 0.027376758\n",
      "loss = 0.009989015\n",
      "loss = 0.07521351\n",
      "loss = 0.016525783\n",
      "loss = 0.015078745\n",
      "loss = 0.0034655675\n",
      "loss = 0.03380033\n",
      "loss = 0.0038665629\n",
      "loss = 0.0059166937\n",
      "loss = 0.050640184\n",
      "loss = 0.032713644\n",
      "loss = 0.01114539\n",
      "loss = 0.059943203\n",
      "loss = 0.06663677\n",
      "loss = 0.103485845\n",
      "loss = 0.096718684\n",
      "loss = 0.04695276\n",
      "loss = 0.0025162424\n",
      "loss = 0.03717576\n",
      "loss = 0.011971262\n",
      "loss = 0.006222518\n",
      "loss = 0.006418006\n",
      "loss = 0.015343282\n",
      "loss = 0.017912984\n",
      "loss = 0.019619793\n",
      "loss = 0.025465712\n",
      "loss = 0.08623815\n",
      "loss = 0.034399204\n",
      "loss = 0.054205287\n",
      "loss = 0.009338749\n",
      "loss = 0.025603391\n",
      "loss = 0.024389658\n",
      "loss = 0.02719933\n",
      "loss = 0.0152093135\n",
      "loss = 0.0161472\n",
      "loss = 0.018096777\n",
      "loss = 0.030342074\n",
      "loss = 0.05211879\n",
      "loss = 0.052704982\n",
      "loss = 0.008320838\n",
      "loss = 0.014903053\n",
      "loss = 0.0252392\n",
      "loss = 0.015205827\n",
      "loss = 0.1476804\n",
      "loss = 0.024836615\n",
      "loss = 0.015008398\n",
      "loss = 0.0036837952\n",
      "loss = 0.028093621\n",
      "loss = 0.033563588\n",
      "loss = 0.03401515\n",
      "loss = 0.00236682\n",
      "loss = 0.018508049\n",
      "loss = 0.0074406574\n",
      "loss = 0.008250519\n",
      "loss = 0.027147772\n",
      "loss = 0.033944853\n",
      "loss = 0.03458468\n",
      "loss = 0.029670296\n",
      "loss = 0.01848564\n",
      "loss = 0.015745273\n",
      "loss = 0.007608318\n",
      "loss = 0.042918228\n",
      "loss = 0.01778942\n",
      "loss = 0.015124381\n",
      "loss = 0.00659441\n",
      "loss = 0.099341124\n",
      "loss = 0.0037842672\n",
      "loss = 0.07128748\n",
      "loss = 0.007654871\n",
      "loss = 0.007378133\n",
      "loss = 0.019647203\n",
      "loss = 0.14436533\n",
      "loss = 0.018794755\n",
      "loss = 0.009823599\n",
      "loss = 0.032108117\n",
      "loss = 0.018281294\n",
      "loss = 0.04986999\n",
      "loss = 0.023376793\n",
      "loss = 0.031125396\n",
      "loss = 0.05289749\n",
      "loss = 0.017149625\n",
      "loss = 0.06993799\n",
      "loss = 0.0386477\n",
      "loss = 0.17521253\n",
      "loss = 0.02779439\n",
      "loss = 0.007849745\n",
      "loss = 0.015455444\n",
      "loss = 0.007926066\n",
      "loss = 0.012344861\n",
      "loss = 0.006124166\n",
      "loss = 0.009711112\n",
      "loss = 0.037224416\n",
      "loss = 0.009807909\n",
      "loss = 0.01926031\n",
      "loss = 0.06781975\n",
      "loss = 0.00760955\n",
      "loss = 0.034319952\n",
      "loss = 0.0039658705\n",
      "loss = 0.06526969\n",
      "loss = 0.0077878693\n",
      "loss = 0.058425322\n",
      "loss = 0.021946283\n",
      "loss = 0.04546608\n",
      "loss = 0.017416295\n",
      "loss = 0.06298872\n",
      "loss = 0.017993968\n",
      "loss = 0.010035314\n",
      "loss = 0.042226776\n",
      "loss = 0.02820918\n",
      "loss = 0.011769245\n",
      "loss = 0.0043186154\n",
      "loss = 0.08490726\n",
      "loss = 0.011946827\n",
      "loss = 0.0053989547\n",
      "loss = 0.012649061\n",
      "loss = 0.007098122\n",
      "loss = 0.005891119\n",
      "loss = 0.012561731\n",
      "loss = 0.0310955\n",
      "loss = 0.035222165\n",
      "loss = 0.0073435297\n",
      "loss = 0.032980874\n",
      "loss = 0.055052273\n",
      "loss = 0.0069198296\n",
      "loss = 0.063477844\n",
      "loss = 0.020094212\n",
      "loss = 0.0045723184\n",
      "loss = 0.017601654\n",
      "loss = 0.0023443713\n",
      "loss = 0.015601505\n",
      "loss = 0.12606119\n",
      "loss = 0.02342242\n",
      "loss = 0.0034939446\n",
      "loss = 0.051238324\n",
      "loss = 0.03935215\n",
      "loss = 0.027560422\n",
      "loss = 0.025283802\n",
      "loss = 0.010551296\n",
      "loss = 0.015807522\n",
      "loss = 0.09887744\n",
      "loss = 0.03614208\n",
      "loss = 0.02780457\n",
      "loss = 0.048228532\n",
      "loss = 0.008458138\n",
      "loss = 0.008710859\n",
      "loss = 0.008721888\n",
      "loss = 0.026050864\n",
      "loss = 0.022974448\n",
      "loss = 0.014575072\n",
      "loss = 0.04073733\n",
      "loss = 0.007907107\n",
      "loss = 0.026198868\n",
      "loss = 0.02443871\n",
      "loss = 0.026465982\n",
      "loss = 0.007085813\n",
      "loss = 0.07651227\n",
      "loss = 0.020331472\n",
      "loss = 0.032804687\n",
      "loss = 0.05617499\n",
      "loss = 0.014981177\n",
      "loss = 0.018280895\n",
      "loss = 0.018074572\n",
      "loss = 0.0076692137\n",
      "loss = 0.015877033\n",
      "loss = 0.004918774\n",
      "loss = 0.021186583\n",
      "loss = 0.013196709\n",
      "loss = 0.0024061273\n",
      "loss = 0.039031908\n",
      "loss = 0.016487192\n",
      "loss = 0.009664911\n",
      "loss = 0.0074970736\n",
      "loss = 0.040523585\n",
      "loss = 0.05343216\n",
      "loss = 0.010854402\n",
      "loss = 0.006801064\n",
      "loss = 0.0027388223\n",
      "loss = 0.020439632\n",
      "loss = 0.013039726\n",
      "loss = 0.00778995\n",
      "loss = 0.034073435\n",
      "loss = 0.019247333\n",
      "loss = 0.067739576\n",
      "loss = 0.008920346\n",
      "loss = 0.014721048\n",
      "loss = 0.026860185\n",
      "loss = 0.0055008335\n",
      "loss = 0.008491756\n",
      "loss = 0.024733633\n",
      "loss = 0.027430763\n",
      "loss = 0.07538361\n",
      "loss = 0.0052813897\n",
      "loss = 0.07908822\n",
      "loss = 0.039528728\n",
      "loss = 0.03184653\n",
      "loss = 0.0156154465\n",
      "loss = 0.022481138\n",
      "loss = 0.05447958\n",
      "loss = 0.050335974\n",
      "loss = 0.027900068\n",
      "loss = 0.04005555\n",
      "loss = 0.025626674\n",
      "loss = 0.07906026\n",
      "loss = 0.05293395\n",
      "loss = 0.0689556\n",
      "loss = 0.10983768\n",
      "loss = 0.015117009\n",
      "loss = 0.06346308\n",
      "loss = 0.02101719\n",
      "loss = 0.013855533\n",
      "loss = 0.04734436\n",
      "loss = 0.013371152\n",
      "loss = 0.0048060366\n",
      "loss = 0.056072805\n",
      "loss = 0.03282989\n",
      "loss = 0.077933714\n",
      "loss = 0.03656407\n",
      "loss = 0.0059909136\n",
      "loss = 0.03401487\n",
      "loss = 0.14060338\n",
      "loss = 0.0935543\n",
      "loss = 0.02990535\n",
      "loss = 0.016151175\n",
      "loss = 0.004271953\n",
      "loss = 0.019114453\n",
      "loss = 0.040066473\n",
      "loss = 0.08275026\n",
      "loss = 0.039729938\n",
      "loss = 0.021483777\n",
      "loss = 0.026741276\n",
      "loss = 0.006008162\n",
      "loss = 0.016043924\n",
      "loss = 0.010240801\n",
      "loss = 0.0112893535\n",
      "loss = 0.010226455\n",
      "loss = 0.02805526\n",
      "loss = 0.004536609\n",
      "loss = 0.015333345\n",
      "loss = 0.022004591\n",
      "loss = 0.014542123\n",
      "loss = 0.01291183\n",
      "loss = 0.028935967\n",
      "loss = 0.0018924411\n",
      "loss = 0.017890304\n",
      "loss = 0.014309624\n",
      "loss = 0.0128428275\n",
      "loss = 0.019373465\n",
      "loss = 0.069904245\n",
      "loss = 0.03450391\n",
      "loss = 0.05801684\n",
      "loss = 0.025838511\n",
      "loss = 0.009815928\n",
      "loss = 0.01983149\n",
      "loss = 0.014125384\n",
      "loss = 0.02183929\n",
      "loss = 0.018540606\n",
      "loss = 0.013843003\n",
      "loss = 0.004247538\n",
      "loss = 0.011214491\n",
      "loss = 0.012834773\n",
      "loss = 0.030341344\n",
      "loss = 0.009661888\n",
      "loss = 0.010678192\n",
      "loss = 0.01778092\n",
      "loss = 0.018277321\n",
      "loss = 0.09171477\n",
      "loss = 0.06419983\n",
      "loss = 0.06606134\n",
      "loss = 0.09518728\n",
      "loss = 0.0544711\n",
      "loss = 0.09827018\n",
      "loss = 0.03233698\n",
      "loss = 0.056545496\n",
      "loss = 0.019884596\n",
      "loss = 0.010936439\n",
      "loss = 0.0019662892\n",
      "loss = 0.016301852\n",
      "loss = 0.10058546\n",
      "loss = 0.04241422\n",
      "loss = 0.0029651234\n",
      "loss = 0.018634342\n",
      "loss = 0.0057013687\n",
      "loss = 0.0037211492\n",
      "loss = 0.11926892\n",
      "loss = 0.06692465\n",
      "loss = 0.001436013\n",
      "loss = 0.0018737486\n",
      "loss = 0.086702585\n",
      "loss = 0.03912121\n",
      "loss = 0.038432527\n",
      "loss = 0.011378052\n",
      "loss = 0.025656322\n",
      "loss = 0.022357332\n",
      "loss = 0.0152166765\n",
      "loss = 0.02967303\n",
      "loss = 0.040677346\n",
      "loss = 0.0073951264\n",
      "loss = 0.036945008\n",
      "loss = 0.0781537\n",
      "loss = 0.026043646\n",
      "loss = 0.019308148\n",
      "loss = 0.04149232\n",
      "loss = 0.029055249\n",
      "loss = 0.03669057\n",
      "loss = 0.030655773\n",
      "loss = 0.009875192\n",
      "loss = 0.082660645\n",
      "loss = 0.0048550293\n",
      "loss = 0.014002254\n",
      "loss = 0.016491117\n",
      "loss = 0.003807142\n",
      "loss = 0.008524966\n",
      "loss = 0.022849495\n",
      "loss = 0.007833831\n",
      "loss = 0.051814362\n",
      "loss = 0.013670801\n",
      "loss = 0.012263157\n",
      "loss = 0.0055283043\n",
      "loss = 0.009883139\n",
      "loss = 0.0038819762\n",
      "loss = 0.009301703\n",
      "loss = 0.007835265\n",
      "loss = 0.015802907\n",
      "loss = 0.01759192\n",
      "loss = 0.011106096\n",
      "loss = 0.028599616\n",
      "loss = 0.016066095\n",
      "loss = 0.04274518\n",
      "loss = 0.007655648\n",
      "loss = 0.011468522\n",
      "loss = 0.017180506\n",
      "loss = 0.0017195023\n",
      "loss = 0.008316659\n",
      "loss = 0.0049858973\n",
      "loss = 0.0048774276\n",
      "loss = 0.022751939\n",
      "loss = 0.02775215\n",
      "loss = 0.004217213\n",
      "loss = 0.010168163\n",
      "loss = 0.011217601\n",
      "loss = 0.01217605\n",
      "loss = 0.058911145\n",
      "loss = 0.0036595839\n",
      "loss = 0.030932058\n",
      "loss = 0.031367354\n",
      "loss = 0.011831151\n",
      "loss = 0.017217211\n",
      "loss = 0.018393848\n",
      "loss = 0.0028239335\n",
      "loss = 0.02222277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.029806506\n",
      "loss = 0.02560755\n",
      "loss = 0.006996071\n",
      "loss = 0.009468421\n",
      "loss = 0.006064821\n",
      "loss = 0.02357516\n",
      "loss = 0.008683189\n",
      "loss = 0.016629592\n",
      "loss = 0.010519585\n",
      "loss = 0.033958804\n",
      "loss = 0.024373025\n",
      "loss = 0.020621195\n",
      "loss = 0.005827316\n",
      "loss = 0.0053428425\n",
      "loss = 0.025530698\n",
      "loss = 0.014680762\n",
      "loss = 0.008873452\n",
      "loss = 0.033185266\n",
      "loss = 0.011096489\n",
      "loss = 0.04612219\n",
      "loss = 0.021077465\n",
      "loss = 0.026427407\n",
      "loss = 0.011411158\n",
      "loss = 0.040085245\n",
      "loss = 0.007814445\n",
      "loss = 0.008994265\n",
      "loss = 0.01199593\n",
      "loss = 0.0049326876\n",
      "loss = 0.025827408\n",
      "loss = 0.022949308\n",
      "loss = 0.002432733\n",
      "loss = 0.0021530404\n",
      "loss = 0.060607824\n",
      "loss = 0.0033229485\n",
      "loss = 0.0046255626\n",
      "loss = 0.030586757\n",
      "loss = 0.034633163\n",
      "loss = 0.03154418\n",
      "loss = 0.013942622\n",
      "loss = 0.019600268\n",
      "loss = 0.009715652\n",
      "loss = 0.012587656\n",
      "loss = 0.04893401\n",
      "loss = 0.02023156\n",
      "loss = 0.015499842\n",
      "loss = 0.011801081\n",
      "loss = 0.01554328\n",
      "loss = 0.010785278\n",
      "loss = 0.004833388\n",
      "loss = 0.009007864\n",
      "loss = 0.0021434345\n",
      "loss = 0.04975791\n",
      "loss = 0.030370522\n",
      "loss = 0.031593166\n",
      "loss = 0.013990945\n",
      "loss = 0.017457854\n",
      "loss = 0.0050176443\n",
      "loss = 0.0107792225\n",
      "loss = 0.009599698\n",
      "loss = 0.0025954545\n",
      "loss = 0.0061457185\n",
      "loss = 0.029636927\n",
      "loss = 0.026666734\n",
      "loss = 0.009354731\n",
      "loss = 0.022662077\n",
      "loss = 0.011531033\n",
      "loss = 0.035184387\n",
      "loss = 0.037706174\n",
      "loss = 0.01022763\n",
      "loss = 0.003915202\n",
      "loss = 0.017624626\n",
      "loss = 0.03449718\n",
      "loss = 0.0040700557\n",
      "loss = 0.011373243\n",
      "loss = 0.040142193\n",
      "loss = 0.0019510393\n",
      "loss = 0.0156108085\n",
      "loss = 0.023364179\n",
      "loss = 0.061280422\n",
      "loss = 0.046198465\n",
      "loss = 0.018486824\n",
      "loss = 0.0059959106\n",
      "loss = 0.014643421\n",
      "loss = 0.0055834423\n",
      "loss = 0.015613647\n",
      "loss = 0.017846465\n",
      "loss = 0.011249337\n",
      "loss = 0.0037171252\n",
      "loss = 0.09667438\n",
      "loss = 0.018455155\n",
      "loss = 0.023792826\n",
      "loss = 0.008570573\n",
      "loss = 0.0022245385\n",
      "loss = 0.011920289\n",
      "loss = 0.0063262875\n",
      "loss = 0.01027188\n",
      "loss = 0.017990433\n",
      "loss = 0.04774692\n",
      "loss = 0.031199265\n",
      "loss = 0.0073185046\n",
      "loss = 0.011578379\n",
      "loss = 0.092684075\n",
      "loss = 0.027521254\n",
      "loss = 0.007842638\n",
      "loss = 0.04010316\n",
      "loss = 0.0027456095\n",
      "loss = 0.01889915\n",
      "loss = 0.0022508977\n",
      "loss = 0.008041094\n",
      "loss = 0.0034372425\n",
      "loss = 0.024739763\n",
      "loss = 0.017468793\n",
      "loss = 0.019866124\n",
      "loss = 0.016261242\n",
      "loss = 0.015532089\n",
      "loss = 0.012281745\n",
      "loss = 0.009787146\n",
      "loss = 0.005993687\n",
      "loss = 0.011765423\n",
      "loss = 0.016121257\n",
      "loss = 0.007310474\n",
      "loss = 0.04421875\n",
      "loss = 0.019132694\n",
      "loss = 0.0098376535\n",
      "loss = 0.019821724\n",
      "loss = 0.028743504\n",
      "loss = 0.03232973\n",
      "loss = 0.02660979\n",
      "loss = 0.0075327316\n",
      "loss = 0.016948752\n",
      "loss = 0.022485314\n",
      "loss = 0.02646542\n",
      "loss = 0.08127414\n",
      "loss = 0.012419912\n",
      "loss = 0.0008783116\n",
      "loss = 0.08084631\n",
      "loss = 0.016104052\n",
      "loss = 0.004739673\n",
      "loss = 0.06936307\n",
      "loss = 0.024706807\n",
      "loss = 0.006802042\n",
      "loss = 0.025839513\n",
      "loss = 0.012549431\n",
      "loss = 0.0037261778\n",
      "loss = 0.0014029893\n",
      "loss = 0.008875438\n",
      "loss = 0.104181476\n",
      "loss = 0.012689987\n",
      "loss = 0.038899686\n",
      "loss = 0.019708766\n",
      "loss = 0.01500609\n",
      "loss = 0.02105119\n",
      "loss = 0.026221372\n",
      "loss = 0.020361941\n",
      "loss = 0.0056158104\n",
      "loss = 0.006727932\n",
      "loss = 0.016766287\n",
      "loss = 0.02383003\n",
      "loss = 0.06353564\n",
      "loss = 0.026011901\n",
      "loss = 0.028488282\n",
      "loss = 0.032208275\n",
      "loss = 0.008114547\n",
      "loss = 0.056899443\n",
      "loss = 0.00862524\n",
      "loss = 0.0132134\n",
      "loss = 0.012409028\n",
      "loss = 0.01829261\n",
      "loss = 0.0074713356\n",
      "loss = 0.0023266154\n",
      "loss = 0.019848349\n",
      "loss = 0.012713344\n",
      "loss = 0.005139942\n",
      "loss = 0.028416082\n",
      "loss = 0.025659401\n",
      "loss = 0.045621544\n",
      "loss = 0.026009187\n",
      "loss = 0.038526926\n",
      "loss = 0.031629674\n",
      "loss = 0.008300666\n",
      "loss = 0.006626314\n",
      "loss = 0.011798406\n",
      "loss = 0.0027996367\n",
      "loss = 0.024076447\n",
      "loss = 0.019377235\n",
      "loss = 0.029340615\n",
      "loss = 0.01293385\n",
      "loss = 0.015647516\n",
      "loss = 0.0066957064\n",
      "loss = 0.04266087\n",
      "loss = 0.012657901\n",
      "loss = 0.0013147823\n",
      "loss = 0.03277703\n",
      "loss = 0.0067845033\n",
      "loss = 0.0076597016\n",
      "loss = 0.055186145\n",
      "loss = 0.014478805\n",
      "loss = 0.010791142\n",
      "loss = 0.0029295716\n",
      "loss = 0.017079797\n",
      "loss = 0.030198868\n",
      "loss = 0.009035794\n",
      "loss = 0.033322036\n",
      "loss = 0.022264984\n",
      "loss = 0.014317654\n",
      "loss = 0.008101735\n",
      "loss = 0.027053764\n",
      "loss = 0.006282665\n",
      "loss = 0.0025077402\n",
      "loss = 0.020054257\n",
      "loss = 0.009810147\n",
      "loss = 0.03230665\n",
      "loss = 0.025634028\n",
      "loss = 0.0066519803\n",
      "loss = 0.02213948\n",
      "loss = 0.025749259\n",
      "loss = 0.009631959\n",
      "loss = 0.019910455\n",
      "loss = 0.0016948535\n",
      "loss = 0.0069057434\n",
      "loss = 0.018251114\n",
      "loss = 0.021106103\n",
      "loss = 0.015073923\n",
      "loss = 0.025720315\n",
      "loss = 0.090975575\n",
      "loss = 0.015606672\n",
      "loss = 0.07520658\n",
      "loss = 0.011642497\n",
      "loss = 0.015152528\n",
      "loss = 0.018495757\n",
      "loss = 0.013396108\n",
      "loss = 0.009310412\n",
      "loss = 0.0015961095\n",
      "loss = 0.0030621276\n",
      "loss = 0.01861883\n",
      "loss = 0.0075548296\n",
      "loss = 0.019372942\n",
      "loss = 0.0071895146\n",
      "loss = 0.043113433\n",
      "loss = 0.0067616836\n",
      "loss = 0.03840009\n",
      "loss = 0.027488839\n",
      "loss = 0.032822046\n",
      "loss = 0.007683646\n",
      "loss = 0.0042461203\n",
      "loss = 0.011830914\n",
      "loss = 0.009098627\n",
      "loss = 0.01703738\n",
      "loss = 0.014358314\n",
      "loss = 0.034948163\n",
      "loss = 0.002396428\n",
      "loss = 0.025058199\n",
      "loss = 0.010061031\n",
      "loss = 0.018642567\n",
      "loss = 0.027769163\n",
      "loss = 0.02673145\n",
      "loss = 0.006181889\n",
      "loss = 0.044890318\n",
      "loss = 0.014524659\n",
      "loss = 0.005024815\n",
      "loss = 0.011789791\n",
      "loss = 0.008432317\n",
      "loss = 0.0033629797\n",
      "loss = 0.019298531\n",
      "loss = 0.027334305\n",
      "loss = 0.017643686\n",
      "loss = 0.021078529\n",
      "loss = 0.0057434803\n",
      "loss = 0.0091242995\n",
      "loss = 0.017361093\n",
      "loss = 0.0032928279\n",
      "loss = 0.010043315\n",
      "loss = 0.014983271\n",
      "loss = 0.007760616\n",
      "loss = 0.017675014\n",
      "loss = 0.0024449741\n",
      "loss = 0.0064404407\n",
      "loss = 0.012056787\n",
      "loss = 0.036082897\n",
      "loss = 0.022499727\n",
      "loss = 0.0017970208\n",
      "loss = 0.0073959576\n",
      "loss = 0.051544886\n",
      "loss = 0.0056126206\n",
      "loss = 0.0058165286\n",
      "loss = 0.017930336\n",
      "loss = 0.0036274572\n",
      "loss = 0.0024585626\n",
      "loss = 0.01560851\n",
      "loss = 0.027821025\n",
      "loss = 0.045805626\n",
      "loss = 0.02354903\n",
      "loss = 0.030183809\n",
      "loss = 0.009396819\n",
      "loss = 0.019075684\n",
      "loss = 0.000929395\n",
      "loss = 0.029965647\n",
      "loss = 0.03125197\n",
      "loss = 0.04029774\n",
      "loss = 0.017511105\n",
      "loss = 0.01692858\n",
      "loss = 0.011157712\n",
      "loss = 0.009495607\n",
      "loss = 0.016457489\n",
      "loss = 0.035333484\n",
      "loss = 0.0019915844\n",
      "loss = 0.015589578\n",
      "loss = 0.030699637\n",
      "loss = 0.019269072\n",
      "loss = 0.009177535\n",
      "loss = 0.008526386\n",
      "loss = 0.03681619\n",
      "loss = 0.014999878\n",
      "loss = 0.004026335\n",
      "loss = 0.018910041\n",
      "loss = 0.025252026\n",
      "loss = 0.06170694\n",
      "loss = 0.0061433828\n",
      "loss = 0.004379781\n",
      "loss = 0.005058662\n",
      "loss = 0.07132215\n",
      "loss = 0.06103732\n",
      "loss = 0.01290864\n",
      "loss = 0.010083296\n",
      "loss = 0.008220572\n",
      "loss = 0.019012336\n",
      "loss = 0.024812067\n",
      "loss = 0.028542114\n",
      "loss = 0.06571096\n",
      "loss = 0.008496848\n",
      "loss = 0.0063084047\n",
      "loss = 0.00101478\n",
      "loss = 0.008015227\n",
      "loss = 0.007882459\n",
      "loss = 0.011884955\n",
      "loss = 0.004641889\n",
      "loss = 0.0028611836\n",
      "loss = 0.024158344\n",
      "loss = 0.004692433\n",
      "loss = 0.030440735\n",
      "loss = 0.022183493\n",
      "loss = 0.030592937\n",
      "loss = 0.0046486366\n",
      "loss = 0.015130553\n",
      "loss = 0.005936036\n",
      "loss = 0.026604176\n",
      "loss = 0.01439177\n",
      "loss = 0.037387244\n",
      "loss = 0.003592569\n",
      "loss = 0.011874338\n",
      "loss = 0.0058483323\n",
      "loss = 0.0064767683\n",
      "loss = 0.0037017877\n",
      "loss = 0.06621533\n",
      "loss = 0.03221887\n",
      "loss = 0.00037919707\n",
      "loss = 0.013228668\n",
      "loss = 0.0054811887\n",
      "loss = 0.044649027\n",
      "loss = 0.0033703058\n",
      "loss = 0.025652634\n",
      "loss = 0.03895335\n",
      "loss = 0.036887705\n",
      "loss = 0.006349264\n",
      "loss = 0.00946929\n",
      "loss = 0.018599795\n",
      "loss = 0.0022002626\n",
      "loss = 0.029376533\n",
      "loss = 0.017570855\n",
      "loss = 0.0007796035\n",
      "loss = 0.016783517\n",
      "loss = 0.00814166\n",
      "loss = 0.012299173\n",
      "loss = 0.030513264\n",
      "loss = 0.0031828545\n",
      "loss = 0.0032733527\n",
      "loss = 0.019336214\n",
      "loss = 0.013044264\n",
      "loss = 0.051014334\n",
      "loss = 0.017913021\n",
      "loss = 0.017382404\n",
      "loss = 0.01668769\n",
      "loss = 0.0035099594\n",
      "loss = 0.0018338856\n",
      "loss = 0.011034162\n",
      "loss = 0.01648524\n",
      "loss = 0.0011823324\n",
      "loss = 0.0037580351\n",
      "loss = 0.020964907\n",
      "loss = 0.049030352\n",
      "loss = 0.038051207\n",
      "loss = 0.007834913\n",
      "loss = 0.0147768725\n",
      "loss = 0.0027934103\n",
      "loss = 0.078047164\n",
      "loss = 0.010430359\n",
      "loss = 0.008940271\n",
      "loss = 0.0034116479\n",
      "loss = 0.013365496\n",
      "loss = 0.037271824\n",
      "loss = 0.010995188\n",
      "loss = 0.009832992\n",
      "loss = 0.030172385\n",
      "loss = 0.0068882788\n",
      "loss = 0.0066745696\n",
      "loss = 0.016672734\n",
      "loss = 0.022137752\n",
      "loss = 0.0183581\n",
      "loss = 0.035541967\n",
      "loss = 0.028708065\n",
      "loss = 0.035383783\n",
      "loss = 0.040832017\n",
      "loss = 0.013298872\n",
      "loss = 0.015271459\n",
      "loss = 0.010850629\n",
      "loss = 0.019275395\n",
      "loss = 0.034313522\n",
      "loss = 0.008634247\n",
      "loss = 0.018254848\n",
      "loss = 0.029668752\n",
      "loss = 0.041184217\n",
      "loss = 0.0046334993\n",
      "loss = 0.0047563678\n",
      "loss = 0.016162\n",
      "loss = 0.011317084\n",
      "loss = 0.0057982327\n",
      "loss = 0.0106025515\n",
      "loss = 0.010915118\n",
      "loss = 0.01533872\n",
      "loss = 0.017632129\n",
      "loss = 0.0125622805\n",
      "loss = 0.0047706077\n",
      "loss = 0.0070292456\n",
      "loss = 0.006396846\n",
      "loss = 0.0070725987\n",
      "loss = 0.0060041063\n",
      "loss = 0.002235003\n",
      "loss = 0.025542162\n",
      "loss = 0.017475855\n",
      "loss = 0.004784166\n",
      "loss = 0.0025820204\n",
      "loss = 0.03261938\n",
      "loss = 0.0037971472\n",
      "loss = 0.030619696\n",
      "loss = 0.025326788\n",
      "loss = 0.008211351\n",
      "loss = 0.0045826593\n",
      "loss = 0.006098201\n",
      "loss = 0.012305495\n",
      "loss = 0.063099846\n",
      "loss = 0.028466813\n",
      "loss = 0.07145969\n",
      "loss = 0.011766997\n",
      "loss = 0.16554825\n",
      "loss = 0.019810183\n",
      "loss = 0.002006208\n",
      "loss = 0.010948631\n",
      "loss = 0.006286717\n",
      "loss = 0.0075485967\n",
      "loss = 0.02926618\n",
      "loss = 0.024955982\n",
      "loss = 0.005105697\n",
      "loss = 0.0057374034\n",
      "loss = 0.016238717\n",
      "loss = 0.009518528\n",
      "loss = 0.024478706\n",
      "loss = 0.012431474\n",
      "loss = 0.023679592\n",
      "loss = 0.0025767405\n",
      "loss = 0.015279686\n",
      "loss = 0.012296588\n",
      "loss = 0.0027060583\n",
      "loss = 0.026204314\n",
      "loss = 0.0055264765\n",
      "loss = 0.028660337\n",
      "loss = 0.006145915\n",
      "loss = 0.03500051\n",
      "loss = 0.0053599067\n",
      "loss = 0.033120304\n",
      "loss = 0.021565234\n",
      "loss = 0.0022132765\n",
      "loss = 0.0792619\n",
      "loss = 0.0011127018\n",
      "loss = 0.011682276\n",
      "loss = 0.008523421\n",
      "loss = 0.0028963482\n",
      "loss = 0.0077629182\n",
      "loss = 0.05440329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.019627437\n",
      "loss = 0.015772833\n",
      "loss = 0.013877112\n",
      "loss = 0.008727567\n",
      "loss = 0.0064982465\n",
      "loss = 0.008820804\n",
      "loss = 0.015693583\n",
      "loss = 0.003231285\n",
      "loss = 0.012357429\n",
      "loss = 0.030842148\n",
      "loss = 0.016232736\n",
      "loss = 0.0041832887\n",
      "loss = 0.010428225\n",
      "loss = 0.051038273\n",
      "loss = 0.0063601537\n",
      "loss = 0.016920973\n",
      "loss = 0.008867307\n",
      "loss = 0.013806311\n",
      "loss = 0.04185259\n",
      "loss = 0.0026219867\n",
      "loss = 0.0036158622\n",
      "loss = 0.0079434225\n",
      "loss = 0.016670434\n",
      "loss = 0.008419709\n",
      "loss = 0.0016776992\n",
      "loss = 0.02229334\n",
      "loss = 0.006498635\n",
      "loss = 0.0061918898\n",
      "loss = 0.050055586\n",
      "loss = 0.0050632907\n",
      "loss = 0.0035252813\n",
      "loss = 0.0092524905\n",
      "loss = 0.027504204\n",
      "loss = 0.008764325\n",
      "loss = 0.0024977957\n",
      "loss = 0.004651953\n",
      "loss = 0.0062517948\n",
      "loss = 0.11706031\n",
      "loss = 0.0076943035\n",
      "loss = 0.0033258765\n",
      "loss = 0.05007982\n",
      "loss = 0.02640209\n",
      "loss = 0.05834996\n",
      "loss = 0.0039173914\n",
      "loss = 0.0024336413\n",
      "loss = 0.007412999\n",
      "loss = 0.0122365635\n",
      "loss = 0.013058344\n",
      "loss = 0.043495025\n",
      "loss = 0.008439189\n",
      "loss = 0.003885342\n",
      "loss = 0.0096744895\n",
      "loss = 0.017077327\n",
      "loss = 0.0031839802\n",
      "loss = 0.008520139\n",
      "loss = 0.0042820903\n",
      "loss = 0.00046224624\n",
      "loss = 0.00452509\n",
      "loss = 0.007820459\n",
      "loss = 0.01891334\n",
      "loss = 0.017738732\n",
      "loss = 0.027804095\n",
      "loss = 0.009160088\n",
      "loss = 0.019165002\n",
      "loss = 0.0065893913\n",
      "loss = 0.019590814\n",
      "loss = 0.0127672935\n",
      "loss = 0.005036761\n",
      "loss = 0.017900182\n",
      "loss = 0.008838906\n",
      "loss = 0.03639633\n",
      "loss = 0.016415698\n",
      "loss = 0.014080468\n",
      "loss = 0.003974379\n",
      "loss = 0.007356402\n",
      "loss = 0.02054479\n",
      "loss = 0.006197458\n",
      "loss = 0.0062565687\n",
      "loss = 0.01788674\n",
      "loss = 0.0015613051\n",
      "loss = 0.007861953\n",
      "loss = 0.003424313\n",
      "loss = 0.010751395\n",
      "loss = 0.011620045\n",
      "loss = 0.033458218\n",
      "loss = 0.012448619\n",
      "loss = 0.01571067\n",
      "loss = 0.017900528\n",
      "loss = 0.008839038\n",
      "loss = 0.0047891997\n",
      "loss = 0.03557751\n",
      "loss = 0.004436206\n",
      "loss = 0.005152867\n",
      "loss = 0.015139898\n",
      "loss = 0.0013057507\n",
      "loss = 0.0023799932\n",
      "loss = 0.015764069\n",
      "loss = 0.01826559\n",
      "loss = 0.006988834\n",
      "loss = 0.0052705784\n",
      "loss = 0.060423303\n",
      "loss = 0.017262535\n",
      "loss = 0.015142884\n",
      "loss = 0.011137545\n",
      "loss = 0.0023141885\n",
      "loss = 0.0045820978\n",
      "loss = 0.004749606\n",
      "loss = 0.043650538\n",
      "loss = 0.011787679\n",
      "loss = 0.006322935\n",
      "loss = 0.0022130045\n",
      "loss = 0.015359755\n",
      "loss = 0.017536515\n",
      "loss = 0.014516836\n",
      "loss = 0.020431485\n",
      "loss = 0.0067858784\n",
      "loss = 0.0032315906\n",
      "loss = 0.018495534\n",
      "loss = 0.0056689563\n",
      "loss = 0.009646198\n",
      "loss = 0.02702498\n",
      "loss = 0.013263645\n",
      "loss = 0.008679255\n",
      "loss = 0.013125492\n",
      "loss = 0.004322806\n",
      "loss = 0.002634707\n",
      "loss = 0.0023875325\n",
      "loss = 0.018819444\n",
      "loss = 0.018807076\n",
      "loss = 0.0020097983\n",
      "loss = 0.053503916\n",
      "loss = 0.0077421293\n",
      "loss = 0.01975431\n",
      "loss = 0.0045483443\n",
      "loss = 0.009255003\n",
      "loss = 0.025905173\n",
      "loss = 0.0025406496\n",
      "loss = 0.01494808\n",
      "loss = 0.013198097\n",
      "loss = 0.00831328\n",
      "loss = 0.01166437\n",
      "loss = 0.012102343\n",
      "loss = 0.004433057\n",
      "loss = 0.016695347\n",
      "loss = 0.010800403\n",
      "loss = 0.012839888\n",
      "loss = 0.009747134\n",
      "loss = 0.017410796\n",
      "loss = 0.008849982\n",
      "loss = 0.013176874\n",
      "loss = 0.0006230039\n",
      "loss = 0.0027821967\n",
      "loss = 0.008155333\n",
      "loss = 0.006985155\n",
      "loss = 0.01930658\n",
      "loss = 0.011994448\n",
      "loss = 0.0035450903\n",
      "loss = 0.007101045\n",
      "loss = 0.026317421\n",
      "loss = 0.009516466\n",
      "loss = 0.013140852\n",
      "loss = 0.028325658\n",
      "loss = 0.06478728\n",
      "loss = 0.008573586\n",
      "loss = 0.011875296\n",
      "loss = 0.020846132\n",
      "loss = 0.011873993\n",
      "loss = 0.011603897\n",
      "loss = 0.038735118\n",
      "loss = 0.00579628\n",
      "loss = 0.008623666\n",
      "loss = 0.011775381\n",
      "loss = 0.0021326845\n",
      "loss = 0.011590897\n",
      "loss = 0.0065999464\n",
      "loss = 0.004018765\n",
      "loss = 0.06990561\n",
      "loss = 0.0310865\n",
      "loss = 0.002719142\n",
      "loss = 0.0044696946\n",
      "loss = 0.006361188\n",
      "loss = 0.022775486\n",
      "loss = 0.007176009\n",
      "loss = 0.03597388\n",
      "loss = 0.0049991067\n",
      "loss = 0.009989409\n",
      "loss = 0.006170904\n",
      "loss = 0.007310381\n",
      "loss = 0.037318945\n",
      "loss = 0.008404486\n",
      "loss = 0.0013678637\n",
      "loss = 0.002263032\n",
      "loss = 0.009354677\n",
      "loss = 0.012962765\n",
      "loss = 0.0034373642\n",
      "loss = 0.005704536\n",
      "loss = 0.007575431\n",
      "loss = 0.00622159\n",
      "loss = 0.0033306011\n",
      "loss = 0.0012940608\n",
      "loss = 0.019989448\n",
      "loss = 0.012765333\n",
      "loss = 0.008392697\n",
      "loss = 0.011442386\n",
      "loss = 0.009654149\n",
      "loss = 0.010477128\n",
      "loss = 0.0064388188\n",
      "loss = 0.0067875115\n",
      "loss = 0.034077406\n",
      "loss = 0.002339712\n",
      "loss = 0.08516573\n",
      "loss = 0.0054861987\n",
      "loss = 0.006175086\n",
      "loss = 0.03374812\n",
      "loss = 0.0037496244\n",
      "loss = 0.010210676\n",
      "loss = 0.0064177793\n",
      "loss = 0.0067305057\n",
      "loss = 0.035897367\n",
      "loss = 0.0036447493\n",
      "loss = 0.004803916\n",
      "loss = 0.000795448\n",
      "loss = 0.008669042\n",
      "loss = 0.004528884\n",
      "loss = 0.022852782\n",
      "loss = 0.009883607\n",
      "loss = 0.024220705\n",
      "loss = 0.012369865\n",
      "loss = 0.035169736\n",
      "loss = 0.015111413\n",
      "loss = 0.015578751\n",
      "loss = 0.04095808\n",
      "loss = 0.006595862\n",
      "loss = 0.026973862\n",
      "loss = 0.0014894457\n",
      "loss = 0.026299901\n",
      "loss = 0.01213313\n",
      "loss = 0.017535612\n",
      "loss = 0.016106218\n",
      "loss = 0.0012610705\n",
      "loss = 0.027284525\n",
      "loss = 0.007775062\n",
      "loss = 0.034593068\n",
      "loss = 0.019073961\n",
      "loss = 0.0007717106\n",
      "loss = 0.032695\n",
      "loss = 0.0037461454\n",
      "loss = 0.010692863\n",
      "loss = 0.03127331\n",
      "loss = 0.012603597\n",
      "loss = 0.010044458\n",
      "loss = 0.010584937\n",
      "loss = 0.026689544\n",
      "loss = 0.010753049\n",
      "loss = 0.005497469\n",
      "loss = 0.028490394\n",
      "loss = 0.011551538\n",
      "loss = 0.015622003\n",
      "loss = 0.004337732\n",
      "loss = 0.047967806\n",
      "loss = 0.006702171\n",
      "loss = 0.012235435\n",
      "loss = 0.0027199641\n",
      "loss = 0.006965277\n",
      "loss = 0.0022466844\n",
      "loss = 0.024338398\n",
      "loss = 0.0204769\n",
      "loss = 0.0070060883\n",
      "loss = 0.0007660963\n",
      "loss = 0.0145064555\n",
      "loss = 0.018704427\n",
      "loss = 0.012907977\n",
      "loss = 0.005430737\n",
      "loss = 0.002531186\n",
      "loss = 0.022518996\n",
      "loss = 0.010502924\n",
      "loss = 0.0013242972\n",
      "loss = 0.019318774\n",
      "loss = 0.010076888\n",
      "loss = 0.010387467\n",
      "loss = 0.021659944\n",
      "loss = 0.013012179\n",
      "loss = 0.012803746\n",
      "loss = 0.008987283\n",
      "loss = 0.0060544265\n",
      "loss = 0.029173598\n",
      "loss = 0.07701151\n",
      "loss = 0.0059398497\n",
      "loss = 0.0045882743\n",
      "loss = 0.017725892\n",
      "loss = 0.009060673\n",
      "loss = 0.008103306\n",
      "loss = 0.003234292\n",
      "loss = 0.021898154\n",
      "loss = 0.01764568\n",
      "loss = 0.00959996\n",
      "loss = 0.0063220086\n",
      "loss = 0.004069005\n",
      "loss = 0.0027245516\n",
      "loss = 0.021775307\n",
      "loss = 0.015271625\n",
      "loss = 0.007117491\n",
      "loss = 0.012404313\n",
      "loss = 0.0038932404\n",
      "loss = 0.03332047\n",
      "loss = 0.03386409\n",
      "loss = 0.032144617\n",
      "loss = 0.0017898527\n",
      "loss = 0.006567289\n",
      "loss = 0.014443318\n",
      "loss = 0.0017565003\n",
      "loss = 0.040364414\n",
      "loss = 0.016599605\n",
      "loss = 0.003042646\n",
      "loss = 0.0062778676\n",
      "loss = 0.053306077\n",
      "loss = 0.027366001\n",
      "loss = 0.0046357596\n",
      "loss = 0.0034489313\n",
      "loss = 0.0034766125\n",
      "loss = 0.011179097\n",
      "loss = 0.019211315\n",
      "loss = 0.01383259\n",
      "loss = 0.013829801\n",
      "loss = 0.03867972\n",
      "loss = 0.009492263\n",
      "loss = 0.018701522\n",
      "loss = 0.0124726165\n",
      "loss = 0.001125552\n",
      "loss = 0.016989592\n",
      "loss = 0.01486673\n",
      "loss = 0.005815932\n",
      "loss = 0.015708666\n",
      "loss = 0.016192114\n",
      "loss = 0.005151147\n",
      "loss = 0.0056255674\n",
      "loss = 0.003501551\n",
      "loss = 0.024650358\n",
      "loss = 0.015933787\n",
      "loss = 0.006623138\n",
      "loss = 0.0199924\n",
      "loss = 0.014562331\n",
      "loss = 0.0020472892\n",
      "loss = 0.0084163975\n",
      "loss = 0.0061008716\n",
      "loss = 0.012028711\n",
      "loss = 0.01595493\n",
      "loss = 0.0014665911\n",
      "loss = 0.0077667185\n",
      "loss = 0.012980244\n",
      "loss = 0.010758596\n",
      "loss = 0.0059272647\n",
      "loss = 0.0021013473\n",
      "loss = 0.0037988944\n",
      "loss = 0.0031302087\n",
      "loss = 0.005660759\n",
      "loss = 0.007108954\n",
      "loss = 0.013605392\n",
      "loss = 0.008064151\n",
      "loss = 0.014842281\n",
      "loss = 0.011685255\n",
      "loss = 0.014073288\n",
      "loss = 0.019437693\n",
      "loss = 0.0036451109\n",
      "loss = 0.0011099454\n",
      "loss = 0.0027264708\n",
      "loss = 0.014675187\n",
      "loss = 0.013152979\n",
      "loss = 0.010849954\n",
      "loss = 0.008789667\n",
      "loss = 0.0037760406\n",
      "loss = 0.0066566016\n",
      "loss = 0.0069916663\n",
      "loss = 0.006937488\n",
      "loss = 0.0017487175\n",
      "loss = 0.006264888\n",
      "loss = 0.002570888\n",
      "loss = 0.003817055\n",
      "loss = 0.01569486\n",
      "loss = 0.008163136\n",
      "loss = 0.008346486\n",
      "loss = 0.018446838\n",
      "loss = 0.009912917\n",
      "loss = 0.013868446\n",
      "loss = 0.024862789\n",
      "loss = 0.010379313\n",
      "loss = 0.0028577405\n",
      "loss = 0.0075120428\n",
      "loss = 0.010554146\n",
      "loss = 0.00624537\n",
      "loss = 0.021288391\n",
      "loss = 0.0019626732\n",
      "loss = 0.010549884\n",
      "loss = 0.016952882\n",
      "loss = 0.01352884\n",
      "loss = 0.0042893393\n",
      "loss = 0.0024092314\n",
      "loss = 0.026740335\n",
      "loss = 0.0031519758\n",
      "loss = 0.0038318257\n",
      "loss = 0.017306572\n",
      "loss = 0.0027506533\n",
      "loss = 0.0047025033\n",
      "loss = 0.0042215604\n",
      "loss = 0.010753892\n",
      "loss = 0.004828834\n",
      "loss = 0.009742655\n",
      "loss = 0.039828274\n",
      "loss = 0.008131257\n",
      "loss = 0.0072913337\n",
      "loss = 0.01837587\n",
      "loss = 0.013361053\n",
      "loss = 0.0048064496\n",
      "loss = 0.0039252965\n",
      "loss = 0.0494016\n",
      "loss = 0.0039978987\n",
      "loss = 0.010031061\n",
      "loss = 0.0019295071\n",
      "loss = 0.0067288303\n",
      "loss = 0.0069238413\n",
      "loss = 0.006132522\n",
      "loss = 0.012571162\n",
      "loss = 0.029452417\n",
      "loss = 0.015016686\n",
      "loss = 0.0047462755\n",
      "loss = 0.005275034\n",
      "loss = 0.012036255\n",
      "loss = 0.008657156\n",
      "loss = 0.0005670342\n",
      "loss = 0.0022488674\n",
      "loss = 0.013376279\n",
      "loss = 0.004901957\n",
      "loss = 0.0029250854\n",
      "loss = 0.009869553\n",
      "loss = 0.014153289\n",
      "loss = 0.009713121\n",
      "loss = 0.015481437\n",
      "loss = 0.0091232415\n",
      "loss = 0.00680143\n",
      "loss = 0.031682264\n",
      "loss = 0.0033740746\n",
      "loss = 0.003441192\n",
      "loss = 0.023442024\n",
      "loss = 0.020453667\n",
      "loss = 0.0023933128\n",
      "loss = 0.010968488\n",
      "loss = 0.0021135136\n",
      "loss = 0.019272331\n",
      "loss = 0.004682933\n",
      "loss = 0.014689746\n",
      "loss = 0.0028283647\n",
      "loss = 0.014608131\n",
      "loss = 0.016009554\n",
      "loss = 0.012015202\n",
      "loss = 0.0014904002\n",
      "loss = 0.010498835\n",
      "loss = 0.00096521707\n",
      "loss = 0.012031158\n",
      "loss = 0.0016309301\n",
      "loss = 0.0018231603\n",
      "loss = 0.0016280238\n",
      "loss = 0.0043885894\n",
      "loss = 0.007581805\n",
      "loss = 0.0016071602\n",
      "loss = 0.008370098\n",
      "loss = 0.0032535628\n",
      "loss = 0.007782274\n",
      "loss = 0.007391629\n",
      "loss = 0.0004066894\n",
      "loss = 0.0057382165\n",
      "loss = 0.0032732058\n",
      "loss = 0.028265685\n",
      "loss = 0.0026344964\n",
      "loss = 0.0026546484\n",
      "loss = 0.028293775\n",
      "loss = 0.0022254593\n",
      "loss = 0.006488461\n",
      "loss = 0.008937754\n",
      "loss = 0.0068942523\n",
      "loss = 0.015427411\n",
      "loss = 0.0016933631\n",
      "loss = 0.0009091698\n",
      "loss = 0.004392985\n",
      "loss = 0.004097493\n",
      "loss = 0.009035241\n",
      "loss = 0.023831796\n",
      "loss = 0.0050306106\n",
      "loss = 0.005272731\n",
      "loss = 0.0036972521\n",
      "loss = 0.0048717614\n",
      "loss = 0.010269554\n",
      "loss = 0.008359151\n",
      "loss = 0.0031750514\n",
      "loss = 0.011384651\n",
      "loss = 0.004969446\n",
      "loss = 0.051267568\n",
      "loss = 0.005909444\n",
      "loss = 0.0015139363\n",
      "loss = 0.01329222\n",
      "loss = 0.0004976834\n",
      "loss = 0.008375432\n",
      "loss = 0.013797108\n",
      "loss = 0.004598446\n",
      "loss = 0.0048874486\n",
      "loss = 0.0024972495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.0025349944\n",
      "loss = 0.0013021792\n",
      "loss = 0.036504336\n",
      "loss = 0.012204964\n",
      "loss = 0.003760433\n",
      "loss = 0.0006309629\n",
      "loss = 0.002237333\n",
      "loss = 0.017265934\n",
      "loss = 0.006376289\n",
      "loss = 0.0056276224\n",
      "loss = 0.012572588\n",
      "loss = 0.007101979\n",
      "loss = 0.0058157025\n",
      "loss = 0.015402716\n",
      "loss = 0.0019495023\n",
      "loss = 0.01039951\n",
      "loss = 0.014400449\n",
      "loss = 0.0067513925\n",
      "loss = 0.009382986\n",
      "loss = 0.004606572\n",
      "loss = 0.0019783373\n",
      "loss = 0.0034148027\n",
      "loss = 0.0028087178\n",
      "loss = 0.0018519867\n",
      "loss = 0.0072825085\n",
      "loss = 0.011576531\n",
      "loss = 0.0039522\n",
      "loss = 0.015242272\n",
      "loss = 0.006139537\n",
      "loss = 0.037268754\n",
      "loss = 0.0026999633\n",
      "loss = 0.0027168072\n",
      "loss = 0.013668562\n",
      "loss = 0.0033217957\n",
      "loss = 0.001703938\n",
      "loss = 0.004928895\n",
      "loss = 0.013632436\n",
      "loss = 0.002404014\n",
      "loss = 0.003382591\n",
      "loss = 0.025555626\n",
      "loss = 0.0008645135\n",
      "loss = 0.0108883325\n",
      "loss = 0.017736906\n",
      "loss = 0.014766379\n",
      "loss = 0.0039087525\n",
      "loss = 0.0059562866\n",
      "loss = 0.0018127332\n",
      "loss = 0.0038147718\n",
      "loss = 0.003145434\n",
      "loss = 0.003395708\n",
      "loss = 0.014380792\n",
      "loss = 0.0026207801\n",
      "loss = 0.0172635\n",
      "loss = 0.0034536417\n",
      "loss = 0.0074797785\n",
      "loss = 0.022426398\n",
      "loss = 0.03185573\n",
      "loss = 0.013761899\n",
      "loss = 0.016441204\n",
      "loss = 0.01354989\n",
      "loss = 0.0042264354\n",
      "loss = 0.0061466154\n",
      "loss = 0.021097066\n",
      "loss = 0.004036834\n",
      "loss = 0.0038740847\n",
      "loss = 0.0018099527\n",
      "loss = 0.041536123\n",
      "loss = 0.005189175\n",
      "loss = 0.000611076\n",
      "loss = 0.003313695\n",
      "loss = 0.007136646\n",
      "loss = 0.0011133918\n",
      "loss = 0.003997132\n",
      "loss = 0.00610633\n",
      "loss = 0.014055287\n",
      "loss = 0.0060981195\n",
      "loss = 0.035507865\n",
      "loss = 0.005986275\n",
      "loss = 0.0022240789\n",
      "loss = 0.009582206\n",
      "loss = 0.020669557\n",
      "loss = 0.015058611\n",
      "loss = 0.010077005\n",
      "loss = 0.0074894493\n",
      "loss = 0.004067612\n",
      "loss = 0.007596311\n",
      "loss = 0.007685017\n",
      "loss = 0.008069666\n",
      "loss = 0.009964208\n",
      "loss = 0.019172182\n",
      "loss = 0.0038696632\n",
      "loss = 0.018146968\n",
      "loss = 0.009286751\n",
      "loss = 0.009422917\n",
      "loss = 0.005242682\n",
      "loss = 0.016490564\n",
      "loss = 0.027081052\n",
      "loss = 0.005054487\n",
      "loss = 0.0034833762\n",
      "loss = 0.016828507\n",
      "loss = 0.00704633\n",
      "loss = 0.009824862\n",
      "loss = 0.005243846\n",
      "loss = 0.01627937\n",
      "loss = 0.0040190024\n",
      "loss = 0.006714601\n",
      "loss = 0.015991118\n",
      "loss = 0.0031943657\n",
      "loss = 0.0019733878\n",
      "loss = 0.004351657\n",
      "loss = 0.0010453234\n",
      "loss = 0.0069952034\n",
      "loss = 0.014919936\n",
      "loss = 0.021516312\n",
      "loss = 0.015109271\n",
      "loss = 0.016280133\n",
      "loss = 0.014191861\n",
      "loss = 0.003998289\n",
      "loss = 0.002659263\n",
      "loss = 0.0025145956\n",
      "loss = 0.037408073\n",
      "loss = 0.026881622\n",
      "loss = 0.013007075\n",
      "loss = 0.0073197596\n",
      "loss = 0.008711342\n",
      "loss = 0.00975688\n",
      "loss = 0.014495504\n",
      "loss = 0.008443146\n",
      "loss = 0.008329801\n",
      "loss = 0.008259164\n",
      "loss = 0.008105323\n",
      "loss = 0.020901402\n",
      "loss = 0.00387525\n",
      "loss = 0.000885532\n",
      "loss = 0.0018722152\n",
      "loss = 0.0032122608\n",
      "loss = 0.030102579\n",
      "loss = 0.0057628164\n",
      "loss = 0.0064023123\n",
      "loss = 0.024289016\n",
      "loss = 0.0072843777\n",
      "loss = 0.0005374911\n",
      "loss = 0.012117207\n",
      "loss = 0.005613795\n",
      "loss = 0.0012717968\n",
      "loss = 0.0067766346\n",
      "loss = 0.0031530485\n",
      "loss = 0.02238113\n",
      "loss = 0.0006246184\n",
      "loss = 0.016456898\n",
      "loss = 0.0017862506\n",
      "loss = 0.0038530957\n",
      "loss = 0.003778363\n",
      "loss = 0.0028691157\n",
      "loss = 0.0027253793\n",
      "loss = 0.011790616\n",
      "loss = 0.0009527658\n",
      "loss = 0.0024921296\n",
      "loss = 0.0028948742\n",
      "loss = 0.0064140176\n",
      "loss = 0.014696843\n",
      "loss = 0.0027941975\n",
      "loss = 0.014439002\n",
      "loss = 0.004807969\n",
      "loss = 0.010001871\n",
      "loss = 0.012271168\n",
      "loss = 0.0068418286\n",
      "loss = 0.0054046065\n",
      "loss = 0.02836962\n",
      "loss = 0.0060073463\n",
      "loss = 0.024139337\n",
      "loss = 0.002029143\n",
      "loss = 0.0020690004\n",
      "loss = 0.0038654383\n",
      "loss = 0.010306741\n",
      "loss = 0.0017010618\n",
      "loss = 0.0021950859\n",
      "loss = 0.0053561153\n",
      "loss = 0.0012534473\n",
      "loss = 0.027549291\n",
      "loss = 0.0020420619\n",
      "loss = 0.010931312\n",
      "loss = 0.00264287\n",
      "loss = 0.0046779513\n",
      "loss = 0.0033566253\n",
      "loss = 0.0027268315\n",
      "loss = 0.03428783\n",
      "loss = 0.0068865083\n",
      "loss = 0.0041018296\n",
      "loss = 0.0052280636\n",
      "loss = 0.0023874922\n",
      "loss = 0.0074166264\n",
      "loss = 0.023131255\n",
      "loss = 0.023583874\n",
      "loss = 0.00041941126\n",
      "loss = 0.0059104855\n",
      "loss = 0.01952612\n",
      "loss = 0.0028016183\n",
      "loss = 0.0021956912\n",
      "loss = 0.010844326\n",
      "loss = 0.0048153354\n",
      "loss = 0.0020444603\n",
      "loss = 0.0050480156\n",
      "loss = 0.008233635\n",
      "loss = 0.017812386\n",
      "loss = 0.0064527453\n",
      "loss = 0.0061311396\n",
      "loss = 0.014940896\n",
      "loss = 0.009714198\n",
      "loss = 0.00882328\n",
      "loss = 0.00290991\n",
      "loss = 0.001663899\n",
      "loss = 0.0021376805\n",
      "loss = 0.00382611\n",
      "loss = 0.0050144084\n",
      "loss = 0.0019429313\n",
      "loss = 0.016092274\n",
      "loss = 0.029475465\n",
      "loss = 0.0050384514\n",
      "loss = 0.0051364377\n",
      "loss = 0.032492258\n",
      "loss = 0.009726313\n",
      "loss = 0.00960213\n",
      "loss = 0.0011004381\n",
      "loss = 0.0030117568\n",
      "loss = 0.0041353684\n",
      "loss = 0.007143075\n",
      "loss = 0.0077519887\n",
      "loss = 0.010729247\n",
      "loss = 0.005065108\n",
      "loss = 0.010368892\n",
      "loss = 0.008840779\n",
      "loss = 0.0022456723\n",
      "loss = 0.0073626447\n",
      "loss = 0.0069044065\n",
      "loss = 0.0064725964\n",
      "loss = 0.003088897\n",
      "loss = 0.083053365\n",
      "loss = 0.003974117\n",
      "loss = 0.019450752\n",
      "loss = 0.0049695065\n",
      "loss = 0.009506764\n",
      "loss = 0.006306426\n",
      "loss = 0.0019542095\n",
      "loss = 0.00112622\n",
      "loss = 0.0029510818\n",
      "loss = 0.002417614\n",
      "loss = 0.007957734\n",
      "loss = 0.028960869\n",
      "loss = 0.0015972751\n",
      "loss = 0.0057862387\n",
      "loss = 0.045095686\n",
      "loss = 0.0034772006\n",
      "loss = 0.0076848366\n",
      "loss = 0.005892057\n",
      "loss = 0.0053750677\n",
      "loss = 0.008270141\n",
      "loss = 0.0046117017\n",
      "loss = 0.009447253\n",
      "loss = 0.0049449247\n",
      "loss = 0.0010635816\n",
      "loss = 0.013182429\n",
      "loss = 0.0030176411\n",
      "loss = 0.0013966898\n",
      "loss = 0.0038563819\n",
      "loss = 0.0025741244\n",
      "loss = 0.0019878568\n",
      "loss = 0.02809483\n",
      "loss = 0.006462517\n",
      "loss = 0.03911525\n",
      "loss = 0.008991618\n",
      "loss = 0.019496743\n",
      "loss = 0.022253834\n",
      "loss = 0.0071729105\n",
      "loss = 0.0023806738\n",
      "loss = 0.0041410686\n",
      "loss = 0.012368795\n",
      "loss = 0.0069762263\n",
      "loss = 0.0022780169\n",
      "loss = 0.004188294\n",
      "loss = 0.05056369\n",
      "loss = 0.012457111\n",
      "loss = 0.0009888918\n",
      "loss = 0.0071864836\n",
      "loss = 0.0040456657\n",
      "loss = 0.005766641\n",
      "loss = 0.013581504\n",
      "loss = 0.049576\n",
      "loss = 0.011664629\n",
      "loss = 0.0010943584\n",
      "loss = 0.0016631202\n",
      "loss = 0.012361173\n",
      "loss = 0.009769695\n",
      "loss = 0.005185616\n",
      "loss = 0.010875424\n",
      "loss = 0.009868478\n",
      "loss = 0.016894635\n",
      "loss = 0.0020570292\n",
      "loss = 0.0022315378\n",
      "loss = 0.0021967879\n",
      "loss = 0.0031109287\n",
      "loss = 0.0017389092\n",
      "loss = 0.008172251\n",
      "loss = 0.010023633\n",
      "loss = 0.007701462\n",
      "loss = 0.006686507\n",
      "loss = 0.01358473\n",
      "loss = 0.0037028112\n",
      "loss = 0.0031900234\n",
      "loss = 0.007503134\n",
      "loss = 0.0014834728\n",
      "loss = 0.0005054756\n",
      "loss = 0.007105839\n",
      "loss = 0.008425506\n",
      "loss = 0.010686942\n",
      "loss = 0.012724882\n",
      "loss = 0.004097315\n",
      "loss = 0.015639052\n",
      "loss = 0.015625134\n",
      "loss = 0.00050386105\n",
      "loss = 0.028066382\n",
      "loss = 0.008604641\n",
      "loss = 0.003998557\n",
      "loss = 0.028609518\n",
      "loss = 0.0048641153\n",
      "loss = 0.012650747\n",
      "loss = 0.0009460907\n",
      "loss = 0.0044760536\n",
      "loss = 0.015545295\n",
      "loss = 0.005259179\n",
      "loss = 0.002701587\n",
      "loss = 0.0016758896\n",
      "loss = 0.015129541\n",
      "loss = 0.012915069\n",
      "loss = 0.0063884\n",
      "loss = 0.011127837\n",
      "loss = 0.008883042\n",
      "loss = 0.001598409\n",
      "loss = 0.023231834\n",
      "loss = 0.010966849\n",
      "loss = 0.004880907\n",
      "loss = 0.0017734489\n",
      "loss = 0.0013900779\n",
      "loss = 0.0036115744\n",
      "loss = 0.0011386145\n",
      "loss = 0.011483135\n",
      "loss = 0.012252259\n",
      "loss = 0.03148867\n",
      "loss = 0.0058719288\n",
      "loss = 0.00047563243\n",
      "loss = 0.004736594\n",
      "loss = 0.002029619\n",
      "loss = 0.0035700193\n",
      "loss = 0.0018615953\n",
      "loss = 0.00333575\n",
      "loss = 0.0075760568\n",
      "loss = 0.0021286623\n",
      "loss = 0.0034600112\n",
      "loss = 0.012560597\n",
      "loss = 0.0007925236\n",
      "loss = 0.005472221\n",
      "loss = 0.0057060714\n",
      "loss = 0.0014502113\n",
      "loss = 0.0015098678\n",
      "loss = 0.009441478\n",
      "loss = 0.015643507\n",
      "loss = 0.0025708473\n",
      "loss = 0.021165049\n",
      "loss = 0.001035338\n",
      "loss = 0.026300346\n",
      "loss = 0.006286769\n",
      "loss = 0.015621986\n",
      "loss = 0.008341024\n",
      "loss = 0.007934238\n",
      "loss = 0.0044084704\n",
      "loss = 0.0057910252\n",
      "loss = 0.0017011205\n",
      "loss = 0.010727736\n",
      "loss = 0.002548293\n",
      "loss = 0.010736111\n",
      "loss = 0.0029652866\n",
      "loss = 0.006954319\n",
      "loss = 0.0007054666\n",
      "loss = 0.0052198907\n",
      "loss = 0.0037007038\n",
      "loss = 0.006028044\n",
      "loss = 0.022147985\n",
      "loss = 0.0149061605\n",
      "loss = 0.0020587016\n",
      "loss = 0.01051235\n",
      "loss = 0.0067481\n",
      "loss = 0.0015001752\n",
      "loss = 0.016426204\n",
      "loss = 0.018352948\n",
      "loss = 0.012193998\n",
      "loss = 0.00483537\n",
      "loss = 0.019646063\n",
      "loss = 0.0075576375\n",
      "loss = 0.0051284316\n",
      "loss = 0.012772383\n",
      "loss = 0.012173479\n",
      "loss = 0.012697877\n",
      "loss = 0.0038229118\n",
      "loss = 0.003127471\n",
      "loss = 0.005068689\n",
      "loss = 0.019723793\n",
      "loss = 0.010087845\n",
      "loss = 0.0106606195\n",
      "loss = 0.016097333\n",
      "loss = 0.0010669646\n",
      "loss = 0.009526594\n",
      "loss = 0.0101110935\n",
      "loss = 0.012501925\n",
      "loss = 0.0012091956\n",
      "loss = 0.00092005986\n",
      "loss = 0.009121106\n",
      "loss = 0.029876605\n",
      "loss = 0.016418342\n",
      "loss = 0.004752063\n",
      "loss = 0.0048716487\n",
      "loss = 0.0020363512\n",
      "loss = 0.0076351753\n",
      "loss = 0.014409612\n",
      "loss = 0.018375406\n",
      "loss = 0.0015562901\n",
      "loss = 0.01989121\n",
      "loss = 0.0071030855\n",
      "loss = 0.040893774\n",
      "loss = 0.0027857977\n",
      "loss = 0.0040194187\n",
      "loss = 0.0009690616\n",
      "loss = 0.0018894981\n",
      "loss = 0.0066194423\n",
      "loss = 0.010765398\n",
      "loss = 0.009498839\n",
      "loss = 0.011176473\n",
      "loss = 0.008642996\n",
      "loss = 0.034149796\n",
      "loss = 0.00392222\n",
      "loss = 0.0037758183\n",
      "loss = 0.010735714\n",
      "loss = 0.001150215\n",
      "loss = 0.0017328413\n",
      "loss = 0.0008680464\n",
      "loss = 0.00552076\n",
      "loss = 0.0051961434\n",
      "loss = 0.00059373956\n",
      "loss = 0.005898252\n",
      "loss = 0.0015586934\n",
      "loss = 0.00958719\n",
      "loss = 0.0043351674\n",
      "loss = 0.006480444\n",
      "loss = 0.0095881345\n",
      "loss = 0.0017490333\n",
      "loss = 0.008315898\n",
      "loss = 0.0062860907\n",
      "loss = 0.009137433\n",
      "loss = 0.0035251256\n",
      "loss = 0.0027852082\n",
      "loss = 0.0068325163\n",
      "loss = 0.007586038\n",
      "loss = 0.003817537\n",
      "loss = 0.0031073687\n",
      "loss = 0.012472784\n",
      "loss = 0.0022909078\n",
      "loss = 0.015570878\n",
      "loss = 0.0054495996\n",
      "loss = 0.008108741\n",
      "loss = 0.0021200816\n",
      "loss = 0.0013027396\n",
      "loss = 0.010663575\n",
      "loss = 0.0043795984\n",
      "loss = 0.0051452788\n",
      "loss = 0.0056962534\n",
      "loss = 0.0056964057\n",
      "loss = 0.0040170616\n",
      "loss = 0.0012080222\n",
      "loss = 0.0006068317\n",
      "loss = 0.018148864\n",
      "loss = 0.0024306835\n",
      "loss = 0.003436366\n",
      "loss = 0.007909788\n",
      "loss = 0.0057905437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.0034849127\n",
      "loss = 0.0044878935\n",
      "loss = 0.012545699\n",
      "loss = 0.0030442283\n",
      "loss = 0.009287787\n",
      "loss = 0.00976602\n",
      "loss = 0.0042956155\n",
      "loss = 0.0068447455\n",
      "loss = 0.0017256208\n",
      "loss = 0.0020384854\n",
      "loss = 0.0011152847\n",
      "loss = 0.006027259\n",
      "loss = 0.009678149\n",
      "loss = 0.0067937127\n",
      "loss = 0.004579274\n",
      "loss = 0.020172283\n",
      "loss = 0.003384261\n",
      "loss = 0.0026588498\n",
      "loss = 0.0054117283\n",
      "loss = 0.0009291719\n",
      "loss = 0.0010577254\n",
      "loss = 0.00091006927\n",
      "loss = 0.002409616\n",
      "loss = 0.0030182374\n",
      "loss = 0.003847764\n",
      "loss = 0.003467168\n",
      "loss = 0.008913121\n",
      "loss = 0.011687245\n",
      "loss = 0.009616558\n",
      "loss = 0.03208033\n",
      "loss = 0.011633827\n",
      "loss = 0.0013231597\n",
      "loss = 0.00325628\n",
      "loss = 0.0020042388\n",
      "loss = 0.01897935\n",
      "loss = 0.0035515344\n",
      "loss = 0.011557056\n",
      "loss = 0.023358004\n",
      "loss = 0.010459367\n",
      "loss = 0.02700992\n",
      "loss = 0.002864258\n",
      "loss = 0.0007722819\n",
      "loss = 0.0029993376\n",
      "loss = 0.012935834\n",
      "loss = 0.007288661\n",
      "loss = 0.008194501\n",
      "loss = 0.009340947\n",
      "loss = 0.0069564097\n",
      "loss = 0.005073895\n",
      "loss = 0.0063108485\n",
      "loss = 0.0025606442\n",
      "loss = 0.004999387\n",
      "loss = 0.0028720156\n",
      "loss = 0.0050298017\n",
      "loss = 0.0036585866\n",
      "loss = 0.0052571483\n",
      "loss = 0.0033695134\n",
      "loss = 0.0005565579\n",
      "loss = 0.003794122\n",
      "loss = 0.0058843447\n",
      "loss = 0.0046803746\n",
      "loss = 0.0010360552\n",
      "loss = 0.0031751452\n",
      "loss = 0.0028993376\n",
      "loss = 0.0070256004\n",
      "loss = 0.005231063\n",
      "loss = 0.0124653205\n",
      "loss = 0.0027358397\n",
      "loss = 0.0015088089\n",
      "loss = 0.0011703814\n",
      "loss = 0.0007515431\n",
      "loss = 0.0044032712\n",
      "loss = 0.007702498\n",
      "loss = 0.0050844615\n",
      "loss = 0.0038290569\n",
      "loss = 0.004811415\n",
      "loss = 0.0013463437\n",
      "loss = 0.0059587522\n",
      "loss = 0.0003254577\n",
      "loss = 0.008593911\n",
      "loss = 0.0067381947\n",
      "loss = 0.0100353835\n",
      "loss = 0.0044786\n",
      "loss = 0.0032408973\n",
      "loss = 0.011196049\n",
      "loss = 0.0021514283\n",
      "loss = 0.0030358455\n",
      "loss = 0.0043910146\n",
      "loss = 0.0012450358\n",
      "loss = 0.003810935\n",
      "loss = 0.0040559606\n",
      "loss = 0.0037713759\n",
      "loss = 0.0061377585\n",
      "loss = 0.018279128\n",
      "loss = 0.005897415\n",
      "loss = 0.014014515\n",
      "loss = 0.003874431\n",
      "loss = 0.002661003\n",
      "loss = 0.01091886\n",
      "loss = 0.0032331871\n",
      "loss = 0.0061356337\n",
      "loss = 0.010599563\n",
      "loss = 0.004093343\n",
      "loss = 0.0015481261\n",
      "loss = 0.0028633731\n",
      "loss = 0.0059372233\n",
      "loss = 0.004251373\n",
      "loss = 0.0030775613\n",
      "loss = 0.0028882436\n",
      "loss = 0.0032526504\n",
      "loss = 0.0070964005\n",
      "loss = 0.00221717\n",
      "loss = 0.016920801\n",
      "loss = 0.011153312\n",
      "loss = 0.0043905266\n",
      "loss = 0.0052007157\n",
      "loss = 0.00029830754\n",
      "loss = 0.022149803\n",
      "loss = 0.005799434\n",
      "loss = 0.0012531679\n",
      "loss = 0.0014010551\n",
      "loss = 0.0011016269\n",
      "loss = 0.017914927\n",
      "loss = 0.009127508\n",
      "loss = 0.005766146\n",
      "loss = 0.015712045\n",
      "loss = 0.0023758593\n",
      "loss = 0.0046728854\n",
      "loss = 0.0032124142\n",
      "loss = 0.0016516673\n",
      "loss = 0.0024904136\n",
      "loss = 0.0070145116\n",
      "loss = 0.009533387\n",
      "loss = 0.0010665448\n",
      "loss = 0.001316273\n",
      "loss = 0.009038595\n",
      "loss = 0.0013311321\n",
      "loss = 0.002023482\n",
      "loss = 0.003974173\n",
      "loss = 0.0030473277\n",
      "loss = 0.0009596128\n",
      "loss = 0.004632873\n",
      "loss = 0.0058427956\n",
      "loss = 0.002923519\n",
      "loss = 0.0019208043\n",
      "loss = 0.017144185\n",
      "loss = 0.0046579936\n",
      "loss = 0.0019271689\n",
      "loss = 0.0015237303\n",
      "loss = 0.0012991838\n",
      "loss = 0.002419257\n",
      "loss = 0.0025073814\n",
      "loss = 0.006748694\n",
      "loss = 0.00074382586\n",
      "loss = 0.0036078084\n",
      "loss = 0.00020549809\n",
      "loss = 0.009671776\n",
      "loss = 0.00530051\n",
      "loss = 0.0013763586\n",
      "loss = 0.013610503\n",
      "loss = 0.0005901334\n",
      "loss = 0.0068491977\n",
      "loss = 0.009695634\n",
      "loss = 0.0030996767\n",
      "loss = 0.011198521\n",
      "loss = 0.002172445\n",
      "loss = 0.0011204389\n",
      "loss = 0.01840292\n",
      "loss = 0.00471197\n",
      "loss = 0.013431686\n",
      "loss = 0.0046469527\n",
      "loss = 0.0003800121\n",
      "loss = 0.005136869\n",
      "loss = 0.009558528\n",
      "loss = 0.0013617454\n",
      "loss = 0.005140096\n",
      "loss = 0.0059219296\n",
      "loss = 0.03274251\n",
      "loss = 0.0050873184\n",
      "loss = 0.008992603\n",
      "loss = 0.00081663753\n",
      "loss = 0.006432839\n",
      "loss = 0.0039137015\n",
      "loss = 0.0052680504\n",
      "loss = 0.003625458\n",
      "loss = 0.0102045415\n",
      "loss = 0.003351599\n",
      "loss = 0.0048830705\n",
      "loss = 0.0018199765\n",
      "loss = 0.0078038536\n",
      "loss = 0.022373935\n",
      "loss = 0.0027378125\n",
      "loss = 0.023600988\n",
      "loss = 0.005554986\n",
      "loss = 0.010995455\n",
      "loss = 0.0051818723\n",
      "loss = 0.0020998744\n",
      "loss = 0.0036936044\n",
      "loss = 0.014911436\n",
      "loss = 0.012552144\n",
      "loss = 0.0013770749\n",
      "loss = 0.0024991354\n",
      "loss = 0.00572625\n",
      "loss = 0.020099662\n",
      "loss = 0.0026700688\n",
      "loss = 0.03856142\n",
      "loss = 0.008903639\n",
      "loss = 0.0036260511\n",
      "loss = 0.013835678\n",
      "loss = 0.00079309527\n",
      "loss = 0.001095256\n",
      "loss = 0.011169324\n",
      "loss = 0.002240227\n",
      "loss = 0.0014443524\n",
      "loss = 0.02019857\n",
      "loss = 0.0065038293\n",
      "loss = 0.008162667\n",
      "loss = 0.0012797497\n",
      "loss = 0.0036427819\n",
      "loss = 0.00437398\n",
      "loss = 0.007702095\n",
      "loss = 0.02727199\n",
      "loss = 0.008251275\n",
      "loss = 0.015758095\n",
      "loss = 0.0016350771\n",
      "loss = 0.008761911\n",
      "loss = 0.0027820948\n",
      "loss = 0.00084470294\n",
      "loss = 0.0010246923\n",
      "loss = 0.005841338\n",
      "loss = 0.0020346812\n",
      "loss = 0.012225294\n",
      "loss = 0.0056266384\n",
      "loss = 0.004998541\n",
      "loss = 0.0028259286\n",
      "loss = 0.018962853\n",
      "loss = 0.01228529\n",
      "loss = 0.007908628\n",
      "loss = 0.02191869\n",
      "loss = 0.0024922262\n",
      "loss = 0.004130331\n",
      "loss = 0.0008116486\n",
      "loss = 0.0034063142\n",
      "loss = 0.0018061723\n",
      "loss = 0.007484858\n",
      "loss = 0.025105799\n",
      "loss = 0.004661181\n",
      "loss = 0.0062339893\n",
      "loss = 0.0021819083\n",
      "loss = 0.0050425474\n",
      "loss = 0.0035227458\n",
      "loss = 0.023016337\n",
      "loss = 0.017881395\n",
      "loss = 0.0042324355\n",
      "loss = 0.0007259944\n",
      "loss = 0.019651383\n",
      "loss = 0.0018353187\n",
      "loss = 0.0013452121\n",
      "loss = 0.06006097\n",
      "loss = 0.0071054082\n",
      "loss = 0.0043075834\n",
      "loss = 0.0013831976\n",
      "loss = 0.0018319413\n",
      "loss = 0.0073390636\n",
      "loss = 0.010117117\n",
      "loss = 0.0053685196\n",
      "loss = 0.0027915451\n",
      "loss = 0.0015116457\n",
      "loss = 0.0043053124\n",
      "loss = 0.0014942366\n",
      "loss = 0.011368053\n",
      "loss = 0.027433358\n",
      "loss = 0.005950651\n",
      "loss = 0.0114442445\n",
      "loss = 0.0060582757\n",
      "loss = 0.0072765676\n",
      "loss = 0.013653677\n",
      "loss = 0.004259033\n",
      "loss = 0.007801275\n",
      "loss = 0.0056012543\n",
      "loss = 0.00047447023\n",
      "loss = 0.00054310577\n",
      "loss = 0.0020282117\n",
      "loss = 0.0057338052\n",
      "loss = 0.002678893\n",
      "loss = 0.032859877\n",
      "loss = 0.0014107123\n",
      "loss = 0.0045577455\n",
      "loss = 0.00617446\n",
      "loss = 0.008014217\n",
      "loss = 0.00566811\n",
      "loss = 0.0048762127\n",
      "loss = 0.008503879\n",
      "loss = 0.0029386193\n",
      "loss = 0.0007756233\n",
      "loss = 0.0047148676\n",
      "loss = 0.0016216405\n",
      "loss = 0.0035888616\n",
      "loss = 0.019680852\n",
      "loss = 0.010426813\n",
      "loss = 0.021028578\n",
      "loss = 0.0020367112\n",
      "loss = 0.015728759\n",
      "loss = 0.0072113136\n",
      "loss = 0.0044854605\n",
      "loss = 0.004690898\n",
      "loss = 0.0019301653\n",
      "loss = 0.023301492\n",
      "loss = 0.008599346\n",
      "loss = 0.0024138805\n",
      "loss = 0.006158615\n",
      "loss = 0.0044750236\n",
      "loss = 0.0073506413\n",
      "loss = 0.015180883\n",
      "loss = 0.0034437696\n",
      "loss = 0.007589127\n",
      "loss = 0.009510255\n",
      "loss = 0.0038964779\n",
      "loss = 0.007817085\n",
      "loss = 0.00636671\n",
      "loss = 0.0023037232\n",
      "loss = 0.028866988\n",
      "loss = 0.0012198366\n",
      "loss = 0.0040207393\n",
      "loss = 0.019372717\n",
      "loss = 0.00071887614\n",
      "loss = 0.0058104265\n",
      "loss = 0.015491892\n",
      "loss = 0.006040028\n",
      "loss = 0.0019815182\n",
      "loss = 0.0037265837\n",
      "loss = 0.0014171343\n",
      "loss = 0.004536238\n",
      "loss = 0.0058123907\n",
      "loss = 0.00290652\n",
      "loss = 0.022260137\n",
      "loss = 0.0016378141\n",
      "loss = 0.030599933\n",
      "loss = 0.0062503777\n",
      "loss = 0.012359276\n",
      "loss = 0.023308404\n",
      "loss = 0.0020700907\n",
      "loss = 0.0028205756\n",
      "loss = 0.00017496265\n",
      "loss = 0.0026086573\n",
      "loss = 0.010428382\n",
      "loss = 0.003836473\n",
      "loss = 0.0011628525\n",
      "loss = 0.0019734544\n",
      "loss = 0.0012850972\n",
      "loss = 0.011401789\n",
      "loss = 0.0014650805\n",
      "loss = 0.027388662\n",
      "loss = 0.0067952545\n",
      "loss = 0.008943235\n",
      "loss = 0.0043876967\n",
      "loss = 0.0072305175\n",
      "loss = 0.028348763\n",
      "loss = 0.014895169\n",
      "loss = 0.01085823\n",
      "loss = 0.019179113\n",
      "loss = 0.00522735\n",
      "loss = 0.0098897135\n",
      "loss = 0.0009600438\n",
      "loss = 0.005470651\n",
      "loss = 0.004638007\n",
      "loss = 0.005676276\n",
      "loss = 0.0027729403\n",
      "loss = 0.009061865\n",
      "loss = 0.0046480284\n",
      "loss = 0.01069107\n",
      "loss = 0.0025071753\n",
      "loss = 0.00590106\n",
      "loss = 0.0046091606\n",
      "loss = 0.004504825\n",
      "loss = 0.006100769\n",
      "loss = 0.010286991\n",
      "loss = 0.010610243\n",
      "loss = 0.0009201369\n",
      "loss = 0.0038875397\n",
      "loss = 0.010727538\n",
      "loss = 0.0074485173\n",
      "loss = 0.004820615\n",
      "loss = 0.008928502\n",
      "loss = 0.0070752804\n",
      "loss = 0.009410231\n",
      "loss = 0.0041429624\n",
      "loss = 0.000368275\n",
      "loss = 0.0028267852\n",
      "loss = 0.002223453\n",
      "loss = 0.0012897993\n",
      "loss = 0.013761076\n",
      "loss = 0.014157701\n",
      "loss = 0.0025999628\n",
      "loss = 0.004605279\n",
      "loss = 0.001901817\n",
      "loss = 0.0021153132\n",
      "loss = 0.002044188\n",
      "loss = 0.0048063444\n",
      "loss = 0.0064332606\n",
      "loss = 0.00513641\n",
      "loss = 0.0006047907\n",
      "loss = 0.000447808\n",
      "loss = 0.006729184\n",
      "loss = 0.03006246\n",
      "loss = 0.0017713034\n",
      "loss = 0.011153707\n",
      "loss = 0.0024447083\n",
      "loss = 0.0013661002\n",
      "loss = 0.00065213494\n",
      "loss = 0.00026684708\n",
      "loss = 0.0046844725\n",
      "loss = 0.00018129204\n",
      "loss = 0.007215257\n",
      "loss = 0.0006343558\n",
      "loss = 0.0070951656\n",
      "loss = 0.008272424\n",
      "loss = 0.023471761\n",
      "loss = 0.0024350204\n",
      "loss = 0.012483014\n",
      "loss = 0.0028620935\n",
      "loss = 0.0056819217\n",
      "loss = 0.0022691023\n",
      "loss = 0.0020188298\n",
      "loss = 0.024004946\n",
      "loss = 0.0052663954\n",
      "loss = 0.009718493\n",
      "loss = 0.009787476\n",
      "loss = 0.0040977737\n",
      "loss = 0.0010203657\n",
      "loss = 0.0011298052\n",
      "loss = 0.0021324214\n",
      "loss = 0.025666483\n",
      "loss = 0.00423679\n",
      "loss = 0.004347424\n",
      "loss = 0.0166117\n",
      "loss = 0.0040742764\n",
      "loss = 0.0027807904\n",
      "loss = 0.0005604513\n",
      "loss = 0.027036592\n",
      "loss = 0.0031684262\n",
      "loss = 0.004320844\n",
      "loss = 0.008517887\n",
      "loss = 0.008891473\n",
      "loss = 0.0038774386\n",
      "loss = 0.0106711015\n",
      "loss = 0.0027455639\n",
      "loss = 0.008380372\n",
      "loss = 0.0019194047\n",
      "loss = 0.0027217064\n",
      "loss = 0.0049698846\n",
      "loss = 0.008230271\n",
      "loss = 0.0018225317\n",
      "loss = 0.00084683206\n",
      "loss = 0.0016155881\n",
      "loss = 0.0045238975\n",
      "loss = 0.0019358424\n",
      "loss = 0.0075124647\n",
      "loss = 0.0024714281\n",
      "loss = 0.0011533896\n",
      "loss = 0.0015073196\n",
      "loss = 0.016456047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.0008515624\n",
      "loss = 0.0033994168\n",
      "loss = 0.0013668279\n",
      "loss = 0.0020607556\n",
      "loss = 0.00072222867\n",
      "loss = 0.004199508\n",
      "loss = 0.003824462\n",
      "loss = 0.005591838\n",
      "loss = 0.010939723\n",
      "loss = 0.0032276078\n",
      "loss = 0.0033667944\n",
      "loss = 0.008948762\n",
      "loss = 0.0020801995\n",
      "loss = 0.016543385\n",
      "loss = 0.0073009315\n",
      "loss = 0.0040638694\n",
      "loss = 0.00796435\n",
      "loss = 0.0014331401\n",
      "loss = 0.029089456\n",
      "loss = 0.007909868\n",
      "loss = 0.01374239\n",
      "loss = 0.003037663\n",
      "loss = 0.0023368155\n",
      "loss = 0.0008067337\n",
      "loss = 0.00027735115\n",
      "loss = 0.008500137\n",
      "loss = 0.0070646303\n",
      "loss = 0.010219771\n",
      "loss = 0.0015747686\n",
      "loss = 0.0034479215\n",
      "loss = 0.004352605\n",
      "loss = 0.0016816563\n",
      "loss = 0.0033077616\n",
      "loss = 0.0047475817\n",
      "loss = 0.0020510664\n",
      "loss = 0.0069297254\n",
      "loss = 0.0025641387\n",
      "loss = 0.0078177685\n",
      "loss = 0.0037170914\n",
      "loss = 0.004421402\n",
      "loss = 0.003600461\n",
      "loss = 0.010775741\n",
      "loss = 0.0011624446\n",
      "loss = 0.00793022\n",
      "loss = 0.004930324\n",
      "loss = 0.0018849856\n",
      "loss = 0.0008409409\n",
      "loss = 0.007167451\n",
      "loss = 0.0032510846\n",
      "loss = 0.0030535816\n",
      "loss = 0.0049818316\n",
      "loss = 0.006527517\n",
      "loss = 0.013134694\n",
      "loss = 0.0064694616\n",
      "loss = 0.011493957\n",
      "loss = 0.002193573\n",
      "loss = 0.0020829525\n",
      "loss = 0.00694422\n",
      "loss = 0.0066960384\n",
      "loss = 0.001768548\n",
      "loss = 0.0053525716\n",
      "loss = 0.0026775398\n",
      "loss = 0.0065697725\n",
      "loss = 0.0016119811\n",
      "loss = 0.006310751\n",
      "loss = 0.00519886\n",
      "loss = 0.0073356507\n",
      "loss = 0.0010016708\n",
      "loss = 0.0032249242\n",
      "loss = 0.006041268\n",
      "loss = 0.0017284651\n",
      "loss = 0.0025883778\n",
      "loss = 0.0037204106\n",
      "loss = 0.0023432183\n",
      "loss = 0.0015693062\n",
      "loss = 0.0043346016\n",
      "loss = 0.0049191667\n",
      "loss = 0.0042284504\n",
      "loss = 0.00851916\n",
      "loss = 0.0015231906\n",
      "loss = 0.0076958635\n",
      "loss = 0.012601262\n",
      "loss = 0.008503096\n",
      "loss = 0.004296786\n",
      "loss = 0.0030108925\n",
      "loss = 0.019613985\n",
      "loss = 0.0020471248\n",
      "loss = 0.0029867312\n",
      "loss = 0.0040625175\n",
      "loss = 0.003826336\n",
      "loss = 0.0035398947\n",
      "loss = 0.004101917\n",
      "loss = 0.0049954713\n",
      "loss = 0.0027726537\n",
      "loss = 0.021084188\n",
      "loss = 0.006283669\n",
      "loss = 0.0026886312\n",
      "loss = 0.0031250427\n",
      "loss = 0.013270163\n",
      "loss = 0.0056197736\n",
      "loss = 0.010118667\n",
      "loss = 0.016262095\n",
      "loss = 0.0065501826\n",
      "loss = 0.0012191646\n",
      "loss = 0.0012951852\n",
      "loss = 0.014138393\n",
      "loss = 0.0030279458\n",
      "loss = 0.00087184005\n",
      "loss = 0.016654756\n",
      "loss = 7.055231e-05\n",
      "loss = 0.02326379\n",
      "loss = 0.0060859993\n",
      "loss = 0.0045294934\n",
      "loss = 0.013413775\n",
      "loss = 0.01459798\n",
      "loss = 0.0034143045\n",
      "loss = 0.0024320567\n",
      "loss = 0.0018210412\n",
      "loss = 0.002185283\n",
      "loss = 0.0061941156\n",
      "loss = 0.0018611348\n",
      "loss = 0.006795355\n",
      "loss = 0.0004521424\n",
      "loss = 0.0022923057\n",
      "loss = 0.0023708432\n",
      "loss = 0.00920259\n",
      "loss = 0.010231147\n",
      "loss = 0.0008079897\n",
      "loss = 0.0020874261\n",
      "loss = 0.0012218778\n",
      "loss = 0.0007944404\n",
      "loss = 0.00087547774\n",
      "loss = 0.010380657\n",
      "loss = 0.004731686\n",
      "loss = 0.035535093\n",
      "loss = 0.011793821\n",
      "loss = 0.0060688513\n",
      "loss = 0.0025803708\n",
      "loss = 0.008817889\n",
      "loss = 0.004147786\n",
      "loss = 0.002099787\n",
      "loss = 0.0024431963\n",
      "loss = 0.0024012695\n",
      "loss = 0.0009782226\n",
      "loss = 0.0068358425\n",
      "loss = 0.001922553\n",
      "loss = 0.0011976861\n",
      "loss = 0.003398899\n",
      "loss = 0.0022162506\n",
      "loss = 0.013224648\n",
      "loss = 0.00071668497\n",
      "loss = 0.011867869\n",
      "loss = 0.006599595\n",
      "loss = 0.004506788\n",
      "loss = 0.002929122\n",
      "loss = 0.0025714485\n",
      "loss = 0.0022273317\n",
      "loss = 0.0017257048\n",
      "loss = 0.0027699694\n",
      "loss = 0.0034550286\n",
      "loss = 0.0023284585\n",
      "loss = 0.010951023\n",
      "loss = 0.0015773419\n",
      "loss = 0.0019175274\n",
      "loss = 0.0069757337\n",
      "loss = 0.0013142768\n",
      "loss = 0.0012728448\n",
      "loss = 0.001288633\n",
      "loss = 0.0030494875\n",
      "loss = 0.0045815473\n",
      "loss = 0.0033065395\n",
      "loss = 0.0047899424\n",
      "loss = 0.0053610746\n",
      "loss = 0.0034075715\n",
      "loss = 0.002307424\n",
      "loss = 0.0056491946\n",
      "loss = 0.00075710786\n",
      "loss = 0.0026350166\n",
      "loss = 0.0042096567\n",
      "loss = 0.002288812\n",
      "loss = 0.0050439495\n",
      "loss = 0.006884126\n",
      "loss = 0.0028229393\n",
      "loss = 0.0028024544\n",
      "loss = 0.00073113653\n",
      "loss = 0.00816067\n",
      "loss = 0.00085006776\n",
      "loss = 0.010313433\n",
      "loss = 0.0043154415\n",
      "loss = 0.006518754\n",
      "loss = 0.004211865\n",
      "loss = 0.0046619526\n",
      "loss = 0.00050547905\n",
      "loss = 0.004814693\n",
      "loss = 0.009040535\n",
      "loss = 0.0028837856\n",
      "loss = 0.0014549588\n",
      "loss = 0.0048418804\n",
      "loss = 0.00057800824\n",
      "loss = 0.0040646824\n",
      "loss = 0.0029711816\n",
      "loss = 0.0054869996\n",
      "loss = 0.006023542\n",
      "loss = 0.0025658614\n",
      "loss = 0.0026627507\n",
      "loss = 0.0035282485\n",
      "loss = 0.0036602917\n",
      "loss = 0.00064542633\n",
      "loss = 0.001294792\n",
      "loss = 0.0030278275\n",
      "loss = 0.0013114947\n",
      "loss = 0.0028535214\n",
      "loss = 0.0046185805\n",
      "loss = 0.004163424\n",
      "loss = 0.0016051056\n",
      "loss = 0.00074102817\n",
      "loss = 0.0033848253\n",
      "loss = 0.003360073\n",
      "loss = 0.009267794\n",
      "loss = 0.011037692\n",
      "loss = 0.00056789373\n",
      "loss = 0.005814219\n",
      "loss = 0.00052814966\n",
      "loss = 0.0064517804\n",
      "loss = 0.0009832262\n",
      "loss = 0.00074909924\n",
      "loss = 0.0014015482\n",
      "loss = 0.006082756\n",
      "loss = 0.0027268056\n",
      "loss = 0.004134711\n",
      "loss = 0.00538511\n",
      "loss = 0.002021507\n",
      "loss = 0.0018951438\n",
      "loss = 0.0045346003\n",
      "loss = 0.0022243443\n",
      "loss = 0.0069930134\n",
      "loss = 0.007494455\n",
      "loss = 0.0016759472\n",
      "loss = 0.0030889753\n",
      "loss = 0.0012921694\n",
      "loss = 0.0021249903\n",
      "loss = 0.0041716653\n",
      "loss = 0.007818361\n",
      "loss = 0.019708509\n",
      "loss = 0.0030208344\n",
      "loss = 0.0025584453\n",
      "loss = 0.003711992\n",
      "loss = 0.003401464\n",
      "loss = 0.0030887222\n",
      "loss = 0.005682265\n",
      "loss = 0.008258682\n",
      "loss = 0.0032033504\n",
      "loss = 0.0007342181\n",
      "loss = 0.00018808413\n",
      "loss = 0.011038671\n",
      "loss = 0.00027777482\n",
      "loss = 0.0077100135\n",
      "loss = 0.0061070896\n",
      "loss = 0.0019821739\n",
      "loss = 0.00013836999\n",
      "loss = 0.0024630746\n",
      "loss = 0.0011737002\n",
      "loss = 0.004402779\n",
      "loss = 0.004231159\n",
      "loss = 0.0038545015\n",
      "loss = 9.878036e-05\n",
      "loss = 0.0027086902\n",
      "loss = 0.00097260845\n",
      "loss = 0.008812945\n",
      "loss = 0.001506594\n",
      "loss = 0.0015077088\n",
      "loss = 0.0016066211\n",
      "loss = 0.00011372805\n",
      "loss = 0.0015202523\n",
      "loss = 0.0038100185\n",
      "loss = 0.00091491773\n",
      "loss = 0.00959538\n",
      "loss = 0.0014317121\n",
      "loss = 0.0031969314\n",
      "loss = 0.0018522792\n",
      "loss = 0.0010108724\n",
      "loss = 0.009331977\n",
      "loss = 0.0046738796\n",
      "loss = 0.0062780846\n",
      "loss = 0.002388309\n",
      "loss = 0.00530147\n",
      "loss = 0.003873777\n",
      "loss = 0.00036637596\n",
      "loss = 6.981094e-05\n",
      "loss = 0.00067257334\n",
      "loss = 0.0036791153\n",
      "loss = 0.0034898906\n",
      "loss = 0.001629557\n",
      "loss = 0.005858139\n",
      "loss = 0.0006000367\n",
      "loss = 0.005377089\n",
      "loss = 8.85232e-05\n",
      "loss = 0.0007161235\n",
      "loss = 0.0007020048\n",
      "loss = 0.0007900187\n",
      "loss = 0.0055823326\n",
      "loss = 0.0038666988\n",
      "loss = 0.0027302916\n",
      "loss = 0.00079404755\n",
      "loss = 0.002670249\n",
      "loss = 0.0028376277\n",
      "loss = 0.002432885\n",
      "loss = 0.003391005\n",
      "loss = 0.0010956007\n",
      "loss = 0.0006283273\n",
      "loss = 0.001994424\n",
      "loss = 0.0023148428\n",
      "loss = 0.00100638\n",
      "loss = 0.004195297\n",
      "loss = 0.0022434897\n",
      "loss = 0.0023342175\n",
      "loss = 0.002421357\n",
      "loss = 0.019583771\n",
      "loss = 0.0008454866\n",
      "loss = 0.0017364423\n",
      "loss = 0.0014420431\n",
      "loss = 0.0038187078\n",
      "loss = 0.004445855\n",
      "loss = 0.0044751163\n",
      "loss = 0.0048778653\n",
      "loss = 0.013140402\n",
      "loss = 0.0005549007\n",
      "loss = 0.006535745\n",
      "loss = 0.002434153\n",
      "loss = 0.0027615817\n",
      "loss = 0.0019725969\n",
      "loss = 0.026933663\n",
      "loss = 0.0035369473\n",
      "loss = 0.005793484\n",
      "loss = 0.0021006074\n",
      "loss = 0.013009538\n",
      "loss = 0.0039324355\n",
      "loss = 0.006552343\n",
      "loss = 0.0010137887\n",
      "loss = 0.0065250993\n",
      "loss = 0.007286032\n",
      "loss = 0.0011919048\n",
      "loss = 0.00875407\n",
      "loss = 0.0021340312\n",
      "loss = 0.001125845\n",
      "loss = 0.0007060089\n",
      "loss = 0.0027660322\n",
      "loss = 0.009160616\n",
      "loss = 0.007795739\n",
      "loss = 0.08672107\n",
      "loss = 0.00064682495\n",
      "loss = 0.0015516145\n",
      "loss = 0.0020602911\n",
      "loss = 0.009258984\n",
      "loss = 0.0023445026\n",
      "loss = 0.005337316\n",
      "loss = 0.088791706\n",
      "loss = 0.0010899545\n",
      "loss = 0.00862708\n",
      "loss = 0.028392011\n",
      "loss = 0.002852346\n",
      "loss = 0.014462328\n",
      "loss = 0.0037852821\n",
      "loss = 0.013459662\n",
      "loss = 0.07495887\n",
      "loss = 0.062276796\n",
      "loss = 0.025839003\n",
      "loss = 0.0062599946\n",
      "loss = 0.00941361\n",
      "loss = 0.0052458476\n",
      "loss = 0.014238398\n",
      "loss = 0.011393264\n",
      "loss = 0.010563666\n",
      "loss = 0.0034633167\n",
      "loss = 0.018436309\n",
      "loss = 0.0015287934\n",
      "loss = 0.031813633\n",
      "loss = 0.0047634835\n",
      "loss = 0.005569646\n",
      "loss = 0.0029394503\n",
      "loss = 0.015290789\n",
      "loss = 0.023206966\n",
      "loss = 0.0058734035\n",
      "loss = 0.005073183\n",
      "loss = 0.039953936\n",
      "loss = 0.00073390163\n",
      "loss = 0.0042829383\n",
      "loss = 0.01197262\n",
      "loss = 0.09217165\n",
      "loss = 0.0045326776\n",
      "loss = 0.0030457142\n",
      "loss = 0.0116317365\n",
      "loss = 0.0023518344\n",
      "loss = 0.015667325\n",
      "loss = 0.05829786\n",
      "loss = 0.0042977943\n",
      "loss = 0.004398223\n",
      "loss = 0.024809374\n",
      "loss = 0.0026912657\n",
      "loss = 0.00014668409\n",
      "loss = 0.0009970906\n",
      "loss = 0.042824518\n",
      "loss = 0.008504741\n",
      "loss = 0.0069647217\n",
      "loss = 0.010826933\n",
      "loss = 0.010302499\n",
      "loss = 0.0044036494\n",
      "loss = 0.0059119104\n",
      "loss = 0.0031626285\n",
      "loss = 0.037011836\n",
      "loss = 0.03221864\n",
      "loss = 0.13106386\n",
      "loss = 0.033282828\n",
      "loss = 0.014349315\n",
      "loss = 0.010548154\n",
      "loss = 0.0032725357\n",
      "loss = 0.010529163\n",
      "loss = 0.009025165\n",
      "loss = 0.019625997\n",
      "loss = 0.0023530424\n",
      "loss = 0.034518544\n",
      "loss = 0.0018104077\n",
      "loss = 0.014678358\n",
      "loss = 0.012121018\n",
      "loss = 0.0019593774\n",
      "loss = 0.020742375\n",
      "loss = 0.036228962\n",
      "loss = 0.00752753\n",
      "loss = 0.019150473\n",
      "loss = 0.0045804274\n",
      "loss = 0.0011793745\n",
      "loss = 0.0020155963\n",
      "loss = 0.014174776\n",
      "loss = 0.003218308\n",
      "loss = 0.005219359\n",
      "loss = 0.0022183629\n",
      "loss = 0.03474578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.0015796134\n",
      "loss = 0.019285321\n",
      "loss = 0.0015915368\n",
      "loss = 0.0022865105\n",
      "loss = 0.002524803\n",
      "loss = 0.034382157\n",
      "loss = 0.0075416835\n",
      "loss = 0.0064512677\n",
      "loss = 0.002134298\n",
      "loss = 0.0025945199\n",
      "loss = 0.124580584\n",
      "loss = 0.008813777\n",
      "loss = 0.029192898\n",
      "loss = 0.008714962\n",
      "loss = 0.007902132\n",
      "loss = 0.005816263\n",
      "loss = 0.003509906\n",
      "loss = 0.0044618114\n",
      "loss = 0.024391932\n",
      "loss = 0.0025359797\n",
      "loss = 0.0068604294\n",
      "loss = 0.004324278\n",
      "loss = 0.035423066\n",
      "loss = 0.011022284\n",
      "loss = 0.003593376\n",
      "loss = 0.028794114\n",
      "loss = 0.0032522026\n",
      "loss = 0.0038037803\n",
      "loss = 0.0057010134\n",
      "loss = 0.005306922\n",
      "loss = 0.032754947\n",
      "loss = 0.0068284906\n",
      "loss = 0.059042934\n",
      "loss = 0.006193228\n",
      "loss = 0.004691128\n",
      "loss = 0.0035050146\n",
      "loss = 0.001422155\n",
      "loss = 0.013324776\n",
      "loss = 0.030499535\n",
      "loss = 0.011733592\n",
      "loss = 0.0054803\n",
      "loss = 0.0005183639\n",
      "loss = 0.00113795\n",
      "loss = 0.0029114191\n",
      "loss = 0.03942277\n",
      "loss = 0.008844061\n",
      "loss = 0.067033336\n",
      "loss = 0.025568632\n",
      "loss = 0.040845178\n",
      "loss = 0.0014379303\n",
      "loss = 0.0054355003\n",
      "loss = 0.011358873\n",
      "loss = 0.069592535\n",
      "loss = 0.00435727\n",
      "loss = 0.027043661\n",
      "loss = 0.005158102\n",
      "loss = 0.059576467\n",
      "loss = 0.0039727455\n",
      "loss = 0.03795276\n",
      "loss = 0.004212482\n",
      "loss = 0.0009369647\n",
      "loss = 0.02096236\n",
      "loss = 0.043785214\n",
      "loss = 0.02045295\n",
      "loss = 0.007133791\n",
      "loss = 0.004390637\n",
      "loss = 0.0316702\n",
      "loss = 0.006960021\n",
      "loss = 0.0067007393\n",
      "loss = 0.0070748325\n",
      "loss = 0.029893925\n",
      "loss = 0.0021666659\n",
      "loss = 0.0034450656\n",
      "loss = 0.016734246\n",
      "loss = 0.0023502451\n",
      "loss = 0.0040465165\n",
      "loss = 0.0075233523\n",
      "loss = 0.005144965\n",
      "loss = 0.0006542895\n",
      "loss = 0.015272831\n",
      "loss = 0.0062988577\n",
      "loss = 0.0040948284\n",
      "loss = 0.01206724\n",
      "loss = 0.047725264\n",
      "loss = 0.0015801194\n",
      "loss = 0.023839569\n",
      "loss = 0.0025602856\n",
      "loss = 0.0032736051\n",
      "loss = 0.022695636\n",
      "loss = 0.022467557\n",
      "loss = 0.0002589159\n",
      "loss = 0.0024604956\n",
      "loss = 0.01218456\n",
      "loss = 0.0051486366\n",
      "loss = 0.016110508\n",
      "loss = 0.019504005\n",
      "loss = 0.0038185497\n",
      "loss = 0.0032864572\n",
      "loss = 0.0012536729\n",
      "loss = 0.026481207\n",
      "loss = 0.009718758\n",
      "loss = 0.00038797615\n",
      "loss = 0.0061302087\n",
      "loss = 0.015848747\n",
      "loss = 0.008678707\n",
      "loss = 0.0001204343\n",
      "loss = 0.0003148359\n",
      "loss = 0.007151649\n",
      "loss = 0.0073240087\n",
      "loss = 0.0062571764\n",
      "loss = 0.0044910912\n",
      "loss = 0.00041209807\n",
      "loss = 0.0060059177\n",
      "loss = 0.002053289\n",
      "loss = 0.000998985\n",
      "loss = 0.00046189447\n",
      "loss = 0.04296559\n",
      "loss = 0.013750026\n",
      "loss = 0.0043217177\n",
      "loss = 0.0045796135\n",
      "loss = 0.018390128\n",
      "loss = 0.001953378\n",
      "loss = 0.005566327\n",
      "loss = 0.0075316527\n",
      "loss = 0.0014600992\n",
      "loss = 0.003533776\n",
      "loss = 0.007083171\n",
      "loss = 0.0016209994\n",
      "loss = 0.04534762\n",
      "loss = 0.0007059014\n",
      "loss = 0.017594855\n",
      "loss = 0.005757369\n",
      "loss = 0.00081103866\n",
      "loss = 0.003399569\n",
      "loss = 0.009189766\n",
      "loss = 0.0348551\n",
      "loss = 0.0045415997\n",
      "loss = 0.011973311\n",
      "loss = 0.0017133765\n",
      "loss = 0.01384665\n",
      "loss = 0.0059443326\n",
      "loss = 0.016074358\n",
      "loss = 0.010536145\n",
      "loss = 0.012589874\n",
      "loss = 0.0007978464\n",
      "loss = 0.0034778744\n",
      "loss = 0.008556223\n",
      "loss = 0.021584108\n",
      "loss = 0.017127808\n",
      "loss = 0.006875433\n",
      "loss = 0.019654613\n",
      "loss = 0.02386466\n",
      "loss = 0.02729138\n",
      "loss = 0.0034216896\n",
      "loss = 0.0056989035\n",
      "loss = 0.0034194794\n",
      "loss = 0.017404513\n",
      "loss = 0.005359207\n",
      "loss = 0.002912558\n",
      "loss = 0.00097507203\n",
      "loss = 0.0013986568\n",
      "loss = 0.0011679294\n",
      "loss = 0.015780708\n",
      "loss = 0.0063162283\n",
      "loss = 0.0051748017\n",
      "loss = 0.010228882\n",
      "loss = 0.0015611782\n",
      "loss = 0.01549997\n",
      "loss = 0.0010146896\n",
      "loss = 0.0055224546\n",
      "loss = 0.010381728\n",
      "loss = 0.006519313\n",
      "loss = 0.007925684\n",
      "loss = 0.002236253\n",
      "loss = 0.000787767\n",
      "loss = 0.01321527\n",
      "loss = 0.00434712\n",
      "loss = 0.0064472193\n",
      "loss = 0.0003681417\n",
      "loss = 0.00070755923\n",
      "loss = 0.0018819364\n",
      "loss = 0.010299517\n",
      "loss = 0.00051571254\n",
      "loss = 0.0003130074\n",
      "loss = 0.016096037\n",
      "loss = 0.0071267206\n",
      "loss = 0.02605079\n",
      "loss = 0.011823078\n",
      "loss = 0.006554058\n",
      "loss = 0.00065106136\n",
      "loss = 0.0011502409\n",
      "loss = 0.0018041972\n",
      "loss = 0.014977934\n",
      "loss = 0.0018022886\n",
      "loss = 0.0027801213\n",
      "loss = 0.0006774131\n",
      "loss = 0.02129265\n",
      "loss = 0.0036472229\n",
      "loss = 0.0010253557\n",
      "loss = 0.0004043965\n",
      "loss = 0.00505934\n",
      "loss = 0.0018165256\n",
      "loss = 0.008196142\n",
      "loss = 0.00068827893\n",
      "loss = 0.013299966\n",
      "loss = 0.0017650329\n",
      "loss = 0.036234993\n",
      "loss = 0.0030487143\n",
      "loss = 0.0010788947\n",
      "loss = 0.001194192\n",
      "loss = 0.0034596627\n",
      "loss = 0.0051529687\n",
      "loss = 0.0036482376\n",
      "loss = 0.0004797071\n",
      "loss = 0.006121249\n",
      "loss = 0.0008231938\n",
      "loss = 0.0069743795\n",
      "loss = 0.0024276066\n",
      "loss = 0.0038131766\n",
      "loss = 0.0053771487\n",
      "loss = 0.0037372354\n",
      "loss = 0.001978181\n",
      "loss = 0.008960448\n",
      "loss = 0.013488063\n",
      "loss = 0.0028515963\n",
      "loss = 0.008251348\n",
      "loss = 0.0024296737\n",
      "loss = 0.00013996454\n",
      "loss = 0.0020097871\n",
      "loss = 0.004293078\n",
      "loss = 0.013267719\n",
      "loss = 0.016863216\n",
      "loss = 0.00054266915\n",
      "loss = 0.010916811\n",
      "loss = 0.009332616\n",
      "loss = 0.0026009993\n",
      "loss = 0.002378992\n",
      "loss = 0.0006349533\n",
      "loss = 0.006313163\n",
      "loss = 0.010975992\n",
      "loss = 0.07160115\n",
      "loss = 0.0066942265\n",
      "loss = 0.003384896\n",
      "loss = 0.00989955\n",
      "loss = 0.0003383496\n",
      "loss = 0.019287203\n",
      "loss = 0.0012594317\n",
      "loss = 0.015993806\n",
      "loss = 0.0047606975\n",
      "loss = 0.025421387\n",
      "loss = 0.08284448\n",
      "loss = 0.0042167385\n",
      "loss = 0.021639287\n",
      "loss = 0.005071641\n",
      "loss = 0.0053513707\n",
      "loss = 0.003316012\n",
      "loss = 0.0007755405\n",
      "loss = 0.033384897\n",
      "loss = 0.0031059657\n",
      "loss = 0.006221166\n",
      "loss = 0.004787013\n",
      "loss = 0.0026192833\n",
      "loss = 0.0058130487\n",
      "loss = 0.00022978858\n",
      "loss = 0.0008981136\n",
      "loss = 0.0028445567\n",
      "loss = 0.0011297642\n",
      "loss = 0.019578274\n",
      "loss = 0.015976712\n",
      "loss = 0.009997155\n",
      "loss = 0.0019477961\n",
      "loss = 0.0018714587\n",
      "loss = 0.0048758755\n",
      "loss = 0.0025916507\n",
      "loss = 0.015382939\n",
      "loss = 0.0018506794\n",
      "loss = 0.0024868057\n",
      "loss = 0.0023399855\n",
      "loss = 0.0055780406\n",
      "loss = 0.016164823\n",
      "loss = 0.0031963058\n",
      "loss = 0.012121697\n",
      "loss = 0.0007002313\n",
      "loss = 0.007742316\n",
      "loss = 0.0012394802\n",
      "loss = 0.007303136\n",
      "loss = 0.0020973438\n",
      "loss = 0.03526717\n",
      "loss = 0.00801626\n",
      "loss = 0.01328596\n",
      "loss = 0.0017352958\n",
      "loss = 0.014000271\n",
      "loss = 0.010855665\n",
      "loss = 0.0005459029\n",
      "loss = 8.605541e-05\n",
      "loss = 0.034420762\n",
      "loss = 0.011181053\n",
      "loss = 0.00465133\n",
      "loss = 0.076618664\n",
      "loss = 0.012840507\n",
      "loss = 0.007987\n",
      "loss = 0.0028895487\n",
      "loss = 0.0033727884\n",
      "loss = 0.0010978974\n",
      "loss = 0.0003019347\n",
      "loss = 0.0040550455\n",
      "loss = 0.0007567208\n",
      "loss = 0.000908024\n",
      "loss = 0.014491449\n",
      "loss = 0.01233809\n",
      "loss = 0.0058372\n",
      "loss = 0.0033445475\n",
      "loss = 0.014009923\n",
      "loss = 0.0007079419\n",
      "loss = 0.0021357134\n",
      "loss = 0.0025922435\n",
      "loss = 0.0017320442\n",
      "loss = 0.0064396467\n",
      "loss = 0.0075189755\n",
      "loss = 0.019934723\n",
      "loss = 0.007984154\n",
      "loss = 0.00044085746\n",
      "loss = 0.0035282841\n",
      "loss = 0.011011181\n",
      "loss = 0.01968995\n",
      "loss = 0.0008342514\n",
      "loss = 0.004310905\n",
      "loss = 0.002340807\n",
      "loss = 0.01797962\n",
      "loss = 0.009001918\n",
      "loss = 0.0036582048\n",
      "loss = 0.0041700737\n",
      "loss = 0.0076492066\n",
      "loss = 0.008409176\n",
      "loss = 0.0015094823\n",
      "loss = 0.0060459264\n",
      "loss = 0.0038003277\n",
      "loss = 0.0022733898\n",
      "loss = 0.00658115\n",
      "loss = 0.004237597\n",
      "loss = 0.0024908471\n",
      "loss = 0.0013384705\n",
      "loss = 0.00019533999\n",
      "loss = 0.003283944\n",
      "loss = 0.0015465127\n",
      "loss = 0.0015695224\n",
      "loss = 0.0050614164\n",
      "loss = 0.023009855\n",
      "loss = 0.0007400515\n",
      "loss = 0.00067527965\n",
      "loss = 0.05447969\n",
      "loss = 0.012329672\n",
      "loss = 0.0025875955\n",
      "loss = 0.011248467\n",
      "loss = 0.00042200656\n",
      "loss = 0.00012334793\n",
      "loss = 0.008037614\n",
      "loss = 0.00639335\n",
      "loss = 0.0025576828\n",
      "loss = 0.0032258527\n",
      "loss = 0.006500353\n",
      "loss = 0.0029009732\n",
      "loss = 0.0034852033\n",
      "loss = 0.0035701278\n",
      "loss = 0.0011188557\n",
      "loss = 0.003561302\n",
      "loss = 0.007475787\n",
      "loss = 0.0013333448\n",
      "loss = 0.00932134\n",
      "loss = 0.0006369652\n",
      "loss = 0.0012589734\n",
      "loss = 0.001326926\n",
      "loss = 0.0025227533\n",
      "loss = 0.0021922884\n",
      "loss = 0.0020616455\n",
      "loss = 0.0030819215\n",
      "loss = 0.0041267225\n",
      "loss = 0.018269721\n",
      "loss = 0.006280328\n",
      "loss = 0.026434837\n",
      "loss = 0.00042451677\n",
      "loss = 0.00053945254\n",
      "loss = 0.0004999968\n",
      "loss = 0.0010817528\n",
      "loss = 0.0014067768\n",
      "loss = 0.005638135\n",
      "loss = 0.00045912713\n",
      "loss = 0.002240689\n",
      "loss = 0.005619718\n",
      "loss = 0.017294466\n",
      "loss = 0.0030256654\n",
      "loss = 0.0028768834\n",
      "loss = 0.0006679569\n",
      "loss = 0.004976263\n",
      "loss = 0.014431699\n",
      "loss = 0.004614627\n",
      "loss = 0.0018741129\n",
      "loss = 0.0050792727\n",
      "loss = 0.00064226217\n",
      "loss = 0.0046357764\n",
      "loss = 0.0019548037\n",
      "loss = 0.0043509537\n",
      "loss = 0.0047090026\n",
      "loss = 0.004431415\n",
      "loss = 0.0024835016\n",
      "loss = 0.0022149696\n",
      "loss = 9.8766584e-05\n",
      "loss = 0.002351049\n",
      "loss = 0.011637434\n",
      "loss = 0.00508739\n",
      "loss = 0.00030105156\n",
      "loss = 0.007757104\n",
      "loss = 0.007402488\n",
      "loss = 0.001446696\n",
      "loss = 0.008991712\n",
      "loss = 0.0010372448\n",
      "loss = 0.00077968516\n",
      "loss = 0.0007136999\n",
      "loss = 0.0027658036\n",
      "loss = 0.0022757389\n",
      "loss = 0.0066005266\n",
      "loss = 0.0012143787\n",
      "loss = 0.0010390143\n",
      "loss = 0.0031513837\n",
      "loss = 0.0036329303\n",
      "loss = 0.00050839025\n",
      "loss = 0.001140631\n",
      "loss = 0.002179648\n",
      "loss = 0.0022794744\n",
      "loss = 0.011357082\n",
      "loss = 0.00042435975\n",
      "loss = 0.0025032521\n",
      "loss = 0.00033433392\n",
      "loss = 0.014073645\n",
      "loss = 0.0022370806\n",
      "loss = 0.0014167456\n",
      "loss = 0.00041820505\n",
      "loss = 0.003908349\n",
      "loss = 0.0059183575\n",
      "loss = 0.0036665339\n",
      "loss = 0.002668658\n",
      "loss = 0.001607256\n",
      "loss = 0.006002075\n",
      "loss = 0.0011684117\n",
      "loss = 0.0033783584\n",
      "loss = 0.00052239856\n",
      "loss = 0.0015472808\n",
      "loss = 0.0014096255\n",
      "loss = 0.00061479793\n",
      "loss = 0.0023633437\n",
      "loss = 0.0026925965\n",
      "loss = 0.009147908\n",
      "loss = 0.002293168\n",
      "loss = 0.00022239742\n",
      "loss = 0.00845113\n",
      "loss = 0.0026212551\n",
      "loss = 0.0033647427\n",
      "loss = 0.0020654236\n",
      "loss = 0.0012320533\n",
      "loss = 0.002038253\n",
      "loss = 0.0008489974\n",
      "loss = 0.0019081903\n",
      "loss = 0.0009797353\n",
      "loss = 0.0029033872\n",
      "loss = 0.008509727\n",
      "loss = 0.0026133647\n",
      "loss = 0.0020020579\n",
      "loss = 0.0025670233\n",
      "loss = 0.0017365527\n",
      "loss = 0.00091587484\n",
      "loss = 0.0016688545\n",
      "loss = 0.006543803\n",
      "loss = 0.008809206\n",
      "loss = 0.0009176734\n",
      "loss = 0.0054072733\n",
      "loss = 0.00089847785\n",
      "loss = 0.0031402055\n",
      "loss = 0.0015535842\n",
      "loss = 0.001272407\n",
      "loss = 0.0011557804\n",
      "loss = 0.00033212602\n",
      "loss = 0.0017064873\n",
      "loss = 0.0019576957\n",
      "loss = 0.00036950118\n",
      "loss = 0.0061293626\n",
      "loss = 0.006150346\n",
      "loss = 0.008652883\n",
      "loss = 0.0025040747\n",
      "loss = 0.004310796\n",
      "loss = 0.00030994142\n",
      "loss = 0.00011907464\n",
      "loss = 0.00023908756\n",
      "loss = 0.0020152102\n",
      "loss = 0.0008973393\n",
      "loss = 0.010625728\n",
      "loss = 0.0032424454\n",
      "loss = 0.0015825772\n",
      "loss = 0.002271522\n",
      "loss = 0.006159229\n",
      "loss = 0.0048593935\n",
      "loss = 0.0060251285\n",
      "loss = 0.0004990468\n",
      "loss = 0.0033474811\n",
      "loss = 0.0016230617\n",
      "loss = 0.008211413\n",
      "loss = 0.022931991\n",
      "loss = 0.0012803811\n",
      "loss = 0.0005235824\n",
      "loss = 0.0025086629\n",
      "loss = 0.0043220175\n",
      "loss = 0.0017381252\n",
      "loss = 0.00073360826\n",
      "loss = 0.0021195738\n",
      "loss = 0.020217637\n",
      "loss = 0.009614771\n",
      "loss = 0.000833983\n",
      "loss = 0.0041069966\n",
      "loss = 0.004603648\n",
      "loss = 0.0022206022\n",
      "loss = 0.00072279974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.015648196\n",
      "loss = 0.00018153427\n",
      "loss = 0.0013035411\n",
      "loss = 0.012106754\n",
      "loss = 0.013445343\n",
      "loss = 0.0009616504\n",
      "loss = 0.005220372\n",
      "loss = 0.005558486\n",
      "loss = 0.0022316938\n",
      "loss = 0.0016260187\n",
      "loss = 0.0068591037\n",
      "loss = 0.0025694934\n",
      "loss = 0.0019067292\n",
      "loss = 0.00023172767\n",
      "loss = 0.0014976999\n",
      "loss = 0.00063646614\n",
      "loss = 0.0063176984\n",
      "loss = 0.0044128937\n",
      "loss = 0.0016031818\n",
      "loss = 0.00092741346\n",
      "loss = 0.003271976\n",
      "loss = 0.0010449421\n",
      "loss = 0.0044989856\n",
      "loss = 0.0026881122\n",
      "loss = 0.00083003746\n",
      "loss = 0.0012582031\n",
      "loss = 0.009955349\n",
      "loss = 0.0006870092\n",
      "loss = 0.0024827\n",
      "loss = 0.007029506\n",
      "loss = 0.0038645063\n",
      "loss = 0.017832259\n",
      "loss = 0.00030605265\n",
      "loss = 0.0010360597\n",
      "loss = 0.002411119\n",
      "loss = 0.018049022\n",
      "loss = 0.0015706476\n",
      "loss = 0.008170791\n",
      "loss = 0.001539404\n",
      "loss = 0.00053233176\n",
      "loss = 0.001112401\n",
      "loss = 0.00093371706\n",
      "loss = 0.0004906315\n",
      "loss = 0.016933778\n",
      "loss = 0.00680248\n",
      "loss = 0.0028235528\n",
      "loss = 0.00031689374\n",
      "loss = 0.004443346\n",
      "loss = 0.0058068032\n",
      "loss = 0.0050032884\n",
      "loss = 0.0061359056\n",
      "loss = 0.0055983188\n",
      "loss = 0.0050892346\n",
      "loss = 0.0008432805\n",
      "loss = 0.0013756305\n",
      "loss = 0.0012012245\n",
      "loss = 0.004369741\n",
      "loss = 0.0016056291\n",
      "loss = 0.0053102216\n",
      "loss = 0.0014018903\n",
      "loss = 0.00013994324\n",
      "loss = 0.0012454926\n",
      "loss = 0.0010345627\n",
      "loss = 0.00327682\n",
      "loss = 0.0017690661\n",
      "loss = 0.0024947785\n",
      "loss = 0.0036949075\n",
      "loss = 0.0025561368\n",
      "loss = 0.0049605104\n",
      "loss = 0.00032491153\n",
      "loss = 0.005942691\n",
      "loss = 0.0040176837\n",
      "loss = 0.021246877\n",
      "loss = 0.00055075507\n",
      "loss = 0.0069558094\n",
      "loss = 0.004448998\n",
      "loss = 0.022759661\n",
      "loss = 0.00355491\n",
      "loss = 0.0014754673\n",
      "loss = 0.0015824835\n",
      "loss = 0.0065053143\n",
      "loss = 0.005294509\n",
      "loss = 0.002713399\n",
      "loss = 0.0036993138\n",
      "loss = 0.0008950797\n",
      "loss = 0.0015079597\n",
      "loss = 0.0067199366\n",
      "loss = 0.0027363144\n",
      "loss = 0.00329169\n",
      "loss = 0.0012738882\n",
      "loss = 0.00081167684\n",
      "loss = 0.001198458\n",
      "loss = 0.014448167\n",
      "loss = 0.008533495\n",
      "loss = 0.0003198253\n",
      "loss = 0.0004998929\n",
      "loss = 0.002031642\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "iters = 5000\n",
    "train_history = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for _ in range(iters):\n",
    "        # pay attention to methods of `mnist` module\n",
    "        X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: X_batch, y: y_batch}\n",
    "        loss_value, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "        train_history.append(loss_value)\n",
    "        \n",
    "    for _ in range(iters):\n",
    "        X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "        feed_dict = {X: X_batch, y: y_batch}\n",
    "        loss_value, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "        print 'loss = %s' % loss_value\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Compute loss on the validation set and display it after every epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\*Extra task \n",
    "\n",
    "If you are already comfortable with the basics of `tensorflow`, you can tackle a more advanced topic of `Variable` scoping and reusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable scope\n",
    "\n",
    "Variable's `scope` can be defined explicitly in `tensorflow`. We might need it when we need to re-run code where we define variables.\n",
    "\n",
    "Below we have a function where variables are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def model_run(input, n_features, n_examples):\n",
    "    w = tf.get_variable('w', [n_features], initializer=tf.ones_initializer())\n",
    "    biases = tf.get_variable('biases', 1, initializer=tf.ones_initializer())\n",
    "    result = input * w + biases\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try running it for different inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable w already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-34-59411449affd>\", line 6, in model_run\n    w = tf.get_variable('w', [n_features], initializer=tf.ones_initializer())\n  File \"<ipython-input-35-de99fbd45762>\", line 5, in <module>\n    res1 = model_run(input1, n_features, 1)\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-de99fbd45762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mres2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-59411449affd>\u001b[0m in \u001b[0;36mmodel_run\u001b[0;34m(input, n_features, n_examples)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biases'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1315\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1318\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1319\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    731\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 733\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    734\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable w already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-34-59411449affd>\", line 6, in model_run\n    w = tf.get_variable('w', [n_features], initializer=tf.ones_initializer())\n  File \"<ipython-input-35-de99fbd45762>\", line 5, in <module>\n    res1 = model_run(input1, n_features, 1)\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(np.array([1, 2, 3, 4]), dtype=tf.float32)\n",
    "input2 = tf.constant(np.array([10, 20, 30, 40, 50, 60]), dtype=tf.float32)\n",
    "\n",
    "n_features = int(input1.shape[0])\n",
    "res1 = model_run(input1, n_features, 1)\n",
    "\n",
    "n_features = int(input2.shape[0])\n",
    "res2 = model_run(input2, n_features, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get an error saying that `Variable w already exists`. In order to avoid that we can compute results for different inputs in their own scopes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2., 3., 4., 5.], dtype=float32), array([11., 21., 31., 41., 51., 61.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input1 = tf.constant(np.array([1,2,3,4]), dtype=tf.float32)\n",
    "input2 = tf.constant(np.array([10, 20, 30, 40, 50, 60]), dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope(\"model1\"):\n",
    "    n_features = int(input1.shape[0])\n",
    "    res1 = model_run(input1, n_features, 1)\n",
    "\n",
    "with tf.variable_scope(\"model2\"):\n",
    "    n_features = int(input2.shape[0])\n",
    "    res2 = model_run(input2, n_features, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run((res1, res2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing variables\n",
    "\n",
    "Sometimes we want to reuse a variable in different parts of a model. We can do that by setting `reuse` parameter of a scope to `True`, so that it can access variables that already exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'collide/v:0', u'collide/v:0', True)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"collide\"):\n",
    "    v = tf.get_variable(\"v\", [1])              # create a variable\n",
    "\n",
    "with tf.variable_scope(\"collide\", reuse=True):\n",
    "    v1 = tf.get_variable(\"v\")                  # reuse the existing variable\n",
    "print(v.name, v1.name, v == v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable collide/v already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-60-f9ac86539ede>\", line 6, in <module>\n    v = tf.get_variable(\"v\", [1])\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-f9ac86539ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#tf.get_variable_scope().reuse_variables() # the properties of scope can be changed on the fly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1315\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1318\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1319\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    731\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 733\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    734\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable collide/v already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-60-f9ac86539ede>\", line 6, in <module>\n    v = tf.get_variable(\"v\", [1])\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "print(tf.get_variable_scope().reuse)\n",
    "\n",
    "with tf.variable_scope(\"collide\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    \n",
    "    #tf.get_variable_scope().reuse_variables() # the properties of scope can be changed on the fly\n",
    "    print(tf.get_variable_scope().reuse)\n",
    "    \n",
    "    v1 = tf.get_variable(\"v\")             \n",
    "print(v.name, v1.name, v == v1)\n",
    "\n",
    "#get_variable_scope()- returns the current variable scope\n",
    "#reuse_variables() - reuse variables in this scope\n",
    "#compared to previos In[] we don't set reuse=True, that why returns Error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Try commenting out the line `tf.get_variable_scope().reuse_variables()` and explain the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable `scopes` can be nested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first/second/a:0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"first\"):\n",
    "    with tf.variable_scope(\"second\"):\n",
    "        v = tf.get_variable('a', shape=[1, 2]) \n",
    "\n",
    "print(v.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
