{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepPavlov sequence-to-sequence tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we are going to implement sequence-to-sequence [[original paper]](https://arxiv.org/abs/1409.3215) model in DeepPavlov.\n",
    "\n",
    "Sequence-to-sequence is the concept of mapping input sequence to target sequence. Sequence-to-sequence models consist of two main components: encoder and decoder. Encoder is used to encode the input sequence to dense representation and decoder uses this dense representation to generate target sequence.\n",
    "\n",
    "![sequence-to-sequence](img/seq2seq.png)\n",
    "\n",
    "Here, input sequence is ABC, special token <EOS\\> (end of sequence) is used as indicator to start decoding target sequence WXYZ.\n",
    "\n",
    "To implement this model in DeepPavlov we have to code some DeepPavlov abstractions:\n",
    "* **DatasetReader** to read the data\n",
    "* **DatasetIterator** to generate batches\n",
    "* **Vocabulary** to convert words to indexes\n",
    "* **Model** to train it and then use it\n",
    "* and some other components for pre- and postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import deeppavlov\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from itertools import chain\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-09 21:27:10.661 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): lnsigo.mipt.ru\n",
      "2018-07-09 21:27:12.364 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://lnsigo.mipt.ru:80 \"GET /export/datasets/personachat_v2.tar.gz HTTP/1.1\" 200 223217972\n",
      "2018-07-09 21:27:12.370 INFO in 'deeppavlov.core.data.utils'['utils'] at line 65: Downloading from http://lnsigo.mipt.ru/export/datasets/personachat_v2.tar.gz to /Users/yaroina-kente/personachat/personachat_v2.tar.gz\n",
      "100%|██████████| 223M/223M [1:02:56<00:00, 59.1kB/s] \n",
      "2018-07-09 22:30:08.427 INFO in 'deeppavlov.core.data.utils'['utils'] at line 149: Extracting personachat/personachat_v2.tar.gz archive into personachat\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.data.utils import download_decompress\n",
    "download_decompress('http://lnsigo.mipt.ru/export/datasets/personachat_v2.tar.gz', './personachat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DatasetReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DatasetReader is used to read and parse data from files. Here, we define new PersonaChatDatasetReader which reads [PersonaChat dataset](https://arxiv.org/abs/1801.07243). PersonaChat dataset consists of dialogs and user personalities.\n",
    "\n",
    "User personality is described by four sentences, e.g.:\n",
    "\n",
    "    i like to remodel homes.\n",
    "    i like to go hunting.\n",
    "    i like to shoot a bow.\n",
    "    my favorite holiday is halloween."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.commands.train import build_model_from_config\n",
    "from deeppavlov.core.data.dataset_reader import DatasetReader\n",
    "from deeppavlov.core.data.utils import download_decompress\n",
    "from deeppavlov.core.common.registry import register\n",
    "\n",
    "@register('personachat_dataset_reader')\n",
    "class PersonaChatDatasetReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    PersonaChat dataset from\n",
    "    Zhang S. et al. Personalizing Dialogue Agents: I have a dog, do you have pets too?\n",
    "    https://arxiv.org/abs/1801.07243\n",
    "    Also, this dataset is used in ConvAI2 http://convai.io/\n",
    "    This class reads dataset to the following format:\n",
    "    [{\n",
    "        'persona': [list of persona sentences],\n",
    "        'x': input utterance,\n",
    "        'y': output utterance,\n",
    "        'dialog_history': list of previous utterances\n",
    "        'candidates': [list of candidate utterances]\n",
    "        'y_idx': index of y utt in candidates list\n",
    "      },\n",
    "       ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    def read(self, dir_path: str, mode='self_original'):\n",
    "        dir_path = Path(dir_path)\n",
    "        dataset = {}\n",
    "        for dt in ['train', 'valid', 'test']:\n",
    "            dataset[dt] = self._parse_data(dir_path / '{}_{}.txt'.format(dt, mode))\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_data(filename):\n",
    "        examples = []\n",
    "        print(filename)\n",
    "        curr_persona = []\n",
    "        curr_dialog_history = []\n",
    "        persona_done = False\n",
    "        with filename.open('r') as fin:\n",
    "            for line in fin:\n",
    "                line = ' '.join(line.strip().split(' ')[1:])\n",
    "                your_persona_pref = 'your persona: '\n",
    "                if line[:len(your_persona_pref)] == your_persona_pref and persona_done:\n",
    "                    curr_persona = [line[len(your_persona_pref):]]\n",
    "                    curr_dialog_history = []\n",
    "                    persona_done = False\n",
    "                elif line[:len(your_persona_pref)] == your_persona_pref:\n",
    "                    curr_persona.append(line[len(your_persona_pref):])\n",
    "                else:\n",
    "                    persona_done = True\n",
    "                    x, y, _, candidates = line.split('\\t')\n",
    "                    candidates = candidates.split('|')\n",
    "                    example = {\n",
    "                        'persona': curr_persona,\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'dialog_history': curr_dialog_history[:],\n",
    "                        'candidates': candidates,\n",
    "                        'y_idx': candidates.index(y)\n",
    "                    }\n",
    "                    curr_dialog_history.extend([x, y])\n",
    "                    examples.append(example)\n",
    "\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personachat/train_self_original.txt\n",
      "personachat/valid_self_original.txt\n",
      "personachat/test_self_original.txt\n"
     ]
    }
   ],
   "source": [
    "data = PersonaChatDatasetReader().read('./personachat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 65719\n",
      "valid 7801\n",
      "test 7512\n"
     ]
    }
   ],
   "source": [
    "for k in data:\n",
    "    print(k, len(data[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persona': ['i like to remodel homes.',\n",
       "  'i like to go hunting.',\n",
       "  'i like to shoot a bow.',\n",
       "  'my favorite holiday is halloween.'],\n",
       " 'x': 'hi , how are you doing ? i am getting ready to do some cheetah chasing to stay in shape .',\n",
       " 'y': 'you must be very fast . hunting is one of my favorite hobbies .',\n",
       " 'dialog_history': [],\n",
       " 'candidates': ['my mom was single with 3 boys , so we never left the projects .',\n",
       "  'i try to wear all black every day . it makes me feel comfortable .',\n",
       "  'well nursing stresses you out so i wish luck with sister',\n",
       "  'yeah just want to pick up nba nfl getting old',\n",
       "  'i really like celine dion . what about you ?',\n",
       "  'no . i live near farms .',\n",
       "  'i wish i had a daughter , i am a boy mom . they are beautiful boys though still lucky',\n",
       "  'yeah when i get bored i play gone with the wind my favorite movie .',\n",
       "  'hi how are you ? i am eating dinner with my hubby and 2 kids .',\n",
       "  'were you married to your high school sweetheart ? i was .',\n",
       "  'that is great to hear ! are you a competitive rider ?',\n",
       "  'hi , i am doing ok . i am a banker . how about you ?',\n",
       "  'i am 5 years old',\n",
       "  'hi there . how are you today ?',\n",
       "  'i totally understand how stressful that can be .',\n",
       "  'yeah sometimes you do not know what you are actually watching',\n",
       "  'mother taught me to cook ! we are looking for an exterminator .',\n",
       "  'i enjoy romantic movie . what is your favorite season ? mine is summer .',\n",
       "  'editing photos takes a lot of work .',\n",
       "  'you must be very fast . hunting is one of my favorite hobbies .'],\n",
       " 'y_idx': 19}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset iterator is used to generate batches from parsed dataset (DatasetReader). Let's extract only *x* and *y* from parsed dataset and use them to predict sentence *y* by sentence *x*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.data.data_learning_iterator import DataLearningIterator\n",
    "\n",
    "@register('personachat_iterator')\n",
    "class PersonaChatIterator(DataLearningIterator):\n",
    "    def split(self, *args, **kwargs):\n",
    "        for dt in ['train', 'valid', 'test']:\n",
    "            setattr(self, dt, self._to_tuple(getattr(self, dt)))\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_tuple(data):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            list of (persona, x, candidates), y\n",
    "        \"\"\"\n",
    "        return list(map(lambda x: (x['x'], x['y']), data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look on data in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: it certainly does . i love my daily walks with toto in the countryside\n",
      "y: toto your dog ? yeah i use to live in kansas .\n",
      "----------\n",
      "x: i am the supervisor at a power plant so it really sets the tone .\n",
      "y: i work from home . i am deaf so its just easier for me .\n",
      "----------\n",
      "x: i am doing ok i just got done fishing\n",
      "y: sounds cool , i am reading about traveling to cancun\n",
      "----------\n",
      "x: hello , how are you ? where do you live ? i am in california .\n",
      "y: hi i am mad about work but will be ok how are you\n",
      "----------\n",
      "x: i am a teacher already , what do you do ?\n",
      "y: inbetween jobs now , i am just enjoying sports right now .\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "iterator = PersonaChatIterator(data)\n",
    "batch = [el for el in iterator.gen_batches(5, 'train')][0]\n",
    "for x, y in zip(*batch):\n",
    "    print('x:', x)\n",
    "    print('y:', y)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer is used to extract tokens from utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'my', 'friend']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deeppavlov.models.preprocessors.lazy_tokenizer import LazyTokenizer\n",
    "tokenizer = LazyTokenizer()\n",
    "tokenizer(['Hello my friend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary prepares mapping from tokens to token indexes. It uses train data to build this mapping.\n",
    "\n",
    "We will implement DialogVocab (inherited from SimpleVocabulary) wich adds all tokens from *x* and *y* utterances to vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 00:48:33.61 WARNING in 'deeppavlov.core.common.registry'['registry'] at line 47: Registry name \"dialog_vocab\" has been already registered and will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "@register('dialog_vocab')\n",
    "class DialogVocab(SimpleVocabulary):\n",
    "    def fit(self, *args):\n",
    "        tokens = chain(*args)\n",
    "        super().fit(tokens)\n",
    "\n",
    "    def __call__(self, batch, **kwargs):\n",
    "        indices_batch = []\n",
    "        for utt in batch:\n",
    "            tokens = [self[token] for token in utt]\n",
    "            indices_batch.append(tokens)\n",
    "        return indices_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create instance of DialogVocab. We define save and load paths, minimal frequence of tokens which are added to vocabulary and set of special tokens.\n",
    "\n",
    "Special tokens are:\n",
    "* <PAD\\> - padding\n",
    "* <BOS\\> - begin of sequence\n",
    "* <EOS\\> - end of sequence\n",
    "* <UNK\\> - unknown token - token which is not presented in vocabulary\n",
    "\n",
    "And fit it on tokens from *x* and *y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 00:49:16.961 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 83: [saving vocabulary to /Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict]\n"
     ]
    }
   ],
   "source": [
    "vocab = DialogVocab(\n",
    "    save_path='/Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict', # change this path\n",
    "    load_path='/Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict', # change this path\n",
    "    min_freq=2,\n",
    "    special_tokens=('<PAD>','<BOS>', '<EOS>', '<UNK>',),\n",
    "    unk_token='<UNK>'\n",
    ")\n",
    "    \n",
    "vocab.fit(tokenizer(iterator.get_instances(data_type='train')[0]) + tokenizer(iterator.get_instances(data_type='train')[1]))\n",
    "vocab.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most frequent tokens in train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 103487),\n",
       " ('.', 101599),\n",
       " ('you', 48296),\n",
       " ('?', 43771),\n",
       " (',', 39500),\n",
       " ('a', 34214),\n",
       " ('to', 32105),\n",
       " ('do', 30574),\n",
       " ('is', 28579),\n",
       " ('my', 26953)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.freqs.most_common(10)\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of tokens in vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11595"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use built vocabulary to encode some tokenized sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 70, 13, 240, 3, 3, 2, 0]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab([['<BOS>', 'hello', 'my', 'friend', 'there_is_no_such_word_in_dataset', 'and_this', '<EOS>', '<PAD>']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed sequences of token indexes to neural model we should make their lengths equal. If sequence is too short we add <PAD\\> symbols to the end of sequence. If sequence is too long we just cut it.\n",
    "\n",
    "SentencePadder implements such behavior, it also adds <BOS\\> and <EOS\\> tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 00:55:57.866 WARNING in 'deeppavlov.core.common.registry'['registry'] at line 47: Registry name \"sentence_padder\" has been already registered and will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.models.component import Component\n",
    "\n",
    "@register('sentence_padder')\n",
    "class SentencePadder(Component):\n",
    "    def __init__(self, length_limit, pad_token_id=0, start_token_id=1, end_token_id=2, *args, **kwargs):\n",
    "        self.length_limit = length_limit\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.start_token_id = start_token_id\n",
    "        self.end_token_id = end_token_id\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        for i in range(len(batch)):\n",
    "            batch[i] = batch[i][:self.length_limit]\n",
    "            batch[i] = [self.start_token_id] + batch[i] + [self.end_token_id]\n",
    "            batch[i] += [self.pad_token_id] * (self.length_limit + 2 - len(batch[i]))\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<BOS>', 'hello', 'my', 'friend', '<UNK>', '<UNK>', '<EOS>', '<PAD>']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padder = SentencePadder(length_limit=6)\n",
    "vocab(padder(vocab([['hello', 'my', 'friend', 'there_is_no_such_word_in_dataset', 'and_this']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq Model\n",
    "Model consists of two main components: encoder and decoder. We can implement them independently and then put them together in one Seq2Seq model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder\n",
    "Encoder builds hidden representation of input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(inputs, inputs_len, embedding_matrix, cell_size, keep_prob=1.0):\n",
    "    # inputs: tf.int32 tensor with shape bs x seq_len with token ids\n",
    "    # inputs_len: tf.int32 tensor with shape bs\n",
    "    # embedding_matrix: tf.float32 tensor with shape vocab_size x vocab_dim\n",
    "    # cell_size: hidden size of recurrent cell\n",
    "    # keep_prob: dropout keep probability\n",
    "    with tf.variable_scope('encoder'):\n",
    "     \n",
    "        # first of all we should embed every token in input sequence (use tf.nn.embedding_lookup, don't forget about dropout)\n",
    "\n",
    "        encoder_inputs_embedded = tf.nn.embedding_lookup(embedding_matrix, inputs)\n",
    "\n",
    "\n",
    "        # define recurrent cell (GRU or LSTM)\n",
    "\n",
    "        encoder_cell = tf.contrib.rnn.LSTMCell(cell_size)\n",
    "\n",
    "        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "                                                encoder_cell, encoder_inputs_embedded,\n",
    "                                                dtype=tf.float32, time_major=False,\n",
    "                                                )\n",
    "\n",
    "        \n",
    "        # use tf.nn.dynamic_rnn to encode input sequence, use actual length of input sequence\n",
    "        # encoder_outputs, encoder_state = tf.nn.dynamic_rnn(...)\n",
    "\n",
    "    return encoder_outputs, encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your encoder implementation:\n",
    "\n",
    "next cell output shapes are\n",
    "\n",
    "32 x 10 x 100 and 32 x 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'encoder/rnn/transpose_1:0' shape=(32, 10, 100) dtype=float32>,\n",
       " LSTMStateTuple(c=<tf.Tensor 'encoder/rnn/while/Exit_3:0' shape=(32, 100) dtype=float32>, h=<tf.Tensor 'encoder/rnn/while/Exit_4:0' shape=(32, 100) dtype=float32>))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vocab_size = 100\n",
    "hidden_dim = 100\n",
    "inputs = tf.cast(tf.random_uniform(shape=[32, 10]) * vocab_size, tf.int32) # bs x seq_len\n",
    "mask = tf.cast(tf.random_uniform(shape=[32, 10]) * 2, tf.int32) # bs x seq_len\n",
    "inputs_len = tf.reduce_sum(mask, axis=1)\n",
    "embedding_matrix = tf.random_uniform(shape=[vocab_size, hidden_dim])\n",
    "\n",
    "encoder(inputs, inputs_len, embedding_matrix, hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder\n",
    "Decoder uses encoder outputs and encoder state to produce output sequence.\n",
    "\n",
    "Here, you should write code:\n",
    "* define your decoder_cell (GRU or LSTM)\n",
    "\n",
    "it will be your baseline seq2seq model.\n",
    "\n",
    "\n",
    "And, to improve the model:\n",
    "* add Teacher Forcing\n",
    "* add Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(encoder_outputs, encoder_state, embedding_matrix, mask,\n",
    "            cell_size, max_length, y_ph,\n",
    "            start_token_id=1, keep_prob=1.0,\n",
    "            teacher_forcing_rate_ph = None,\n",
    "            use_attention = False, is_train=False):    \n",
    "    # decoder\n",
    "    # encoder_outputs: tf.float32 tensor with shape bs x seq_len x encoder_cell_size\n",
    "    # encoder_state: tf.float32 tensor with shape bs x encoder_cell_size\n",
    "    # embedding_matrix: tf.float32 tensor with shape vocab_size x vocab_dim\n",
    "    # mask: tf.int32 tensor with shape bs x seq_len with zeros for masked sequence elements\n",
    "    # cell_size: hidden size of recurrent cell\n",
    "    # max_length: max length of output sequence\n",
    "    # start_token_id: id of <BOS> token in vocabulary\n",
    "    # keep_prob: dropout keep probability\n",
    "    # teacher_forcing_rate_ph: rate of using teacher forcing on each decoding step\n",
    "    # use_attention: use attention on encoder outputs or use only encoder_state\n",
    "    # is_train: is it training or inference? at inference time we can't use teacher forcing\n",
    "    with tf.variable_scope('decoder'):\n",
    "        # define decoder recurrent cell with cell_size\n",
    "        \n",
    "        decoder_cell = tf.contrib.rnn.LSTMCell(cell_size)\n",
    "        # initial value of output_token on previsous step is start_token\n",
    "        output_token = tf.ones(shape=(tf.shape(encoder_outputs)[0],), dtype=tf.int32) * start_token_id\n",
    "        # get embeddings_dim from embedding_matrix\n",
    "        embeddings_dim = embedding_matrix.get_shape()[1]\n",
    "        # let's define initial value of decoder state with encoder_state\n",
    "        decoder_state = encoder_state\n",
    "\n",
    "        pred_tokens = []\n",
    "        logits = []\n",
    "\n",
    "        # use for loop to sequentially call recurrent cell\n",
    "        for i in range(max_length):\n",
    "             \n",
    "            input_token_emb = tf.nn.embedding_lookup(embedding_matrix, output_token) \n",
    "            \n",
    "            input_token = tf.cond(tf.logical_and(is_train, tf.logical_and(tf.greater(i,0),\n",
    "                                                 tf.less(tf.random_uniform(shape=()), teacher_forcing_rate_ph))),\n",
    "                                 lambda: y_ph[:, i-1], lambda: tf.cast(output_token, tf.int32)) \n",
    "\n",
    "            input_token_emb = tf.nn.embedding_lookup(embedding_matrix, input_token)\n",
    "\n",
    "            att = dot_attention(encoder_outputs, encoder_state, mask)\n",
    "            input_token_emb = tf.concat([input_token_emb, att], axis=1)\n",
    "            \n",
    "            input_token_emb = tf.nn.dropout(input_token_emb, keep_prob=keep_prob)\n",
    "            # call recurrent cell\n",
    "            decoder_outputs, decoder_state = decoder_cell(input_token_emb, decoder_state)\n",
    "            decoder_outputs = tf.nn.dropout(decoder_outputs, keep_prob=keep_prob)\n",
    "            # project decoder output to embeddings dimension\n",
    "            output_proj = tf.layers.dense(decoder_outputs, embeddings_dim, activation=tf.nn.tanh,\n",
    "                                          kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                          name='proj', reuse=tf.AUTO_REUSE)\n",
    "            # compute logits\n",
    "            output_logits = tf.matmul(output_proj, embedding_matrix, transpose_b=True)\n",
    "\n",
    "            logits.append(output_logits)\n",
    "            output_probs = tf.nn.softmax(output_logits)\n",
    "            output_token = tf.argmax(output_probs, axis=-1)\n",
    "            pred_tokens.append(output_token)\n",
    "        \n",
    "        # ids of output tokens, they will be used as model prediction\n",
    "        y_pred_tokens = tf.transpose(tf.stack(pred_tokens, axis=0), [1, 0])\n",
    "        # output logits of predicted tokens on each step, they will be used to compute loss function\n",
    "        y_logits = tf.transpose(tf.stack(logits, axis=0), [1, 0, 2])\n",
    "        \n",
    "    return y_pred_tokens, y_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of next cell should be with shapes:\n",
    "\n",
    "    32 x 10\n",
    "    32 x 10 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'decoder/transpose:0' shape=(32, 10) dtype=int64>,\n",
       " <tf.Tensor 'decoder/transpose_1:0' shape=(32, 10, 100) dtype=float32>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vocab_size = 100\n",
    "hidden_dim = 100\n",
    "inputs = tf.cast(tf.random_uniform(shape=[32, 10]) * vocab_size, tf.int32) # bs x seq_len\n",
    "mask = tf.cast(tf.random_uniform(shape=[32, 10]) * 2, tf.int32) # bs x seq_len\n",
    "inputs_len = tf.reduce_sum(mask, axis=1)\n",
    "embedding_matrix = tf.random_uniform(shape=[vocab_size, hidden_dim])\n",
    "\n",
    "teacher_forcing_rate = tf.random_uniform(shape=())\n",
    "y = tf.cast(tf.random_uniform(shape=[32, 10]) * vocab_size, tf.int32)\n",
    "\n",
    "encoder_outputs, encoder_state = encoder(inputs, inputs_len, embedding_matrix, hidden_dim)\n",
    "decoder(encoder_outputs, encoder_state, embedding_matrix, mask, hidden_dim, max_length=10,\n",
    "        y_ph=y, teacher_forcing_rate_ph=teacher_forcing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq model should be inherited from TFModel class and implement following methods:\n",
    "* train_on_batch - this method is called in training phase\n",
    "* \\_\\_call\\_\\_ - this method is called to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 01:03:09.662 WARNING in 'deeppavlov.core.common.registry'['registry'] at line 47: Registry name \"seq2seq\" has been already registered and will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from deeppavlov.core.models.tf_model import TFModel\n",
    "\n",
    "@register('seq2seq')\n",
    "class Seq2Seq(TFModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        # hyperparameters\n",
    "        \n",
    "        # dimenstion of word dense representation\n",
    "        self.embeddings_dim = kwargs.get('embeddings_dim', 100)\n",
    "        # size of recurrent cell in encoder and decoder\n",
    "        self.cell_size = kwargs.get('cell_size', 200)\n",
    "        # dropout keep_probability\n",
    "        self.keep_prob = kwargs.get('keep_prob', 0.8)\n",
    "        # learning rate\n",
    "        self.learning_rate = kwargs.get('learning_rate', 3e-04)\n",
    "        # max length of output sequence\n",
    "        self.max_length = kwargs.get('max_length', 20)\n",
    "        self.grad_clip = kwargs.get('grad_clip', 5.0)\n",
    "        self.start_token_id = kwargs.get('start_token_id', 1)\n",
    "        self.vocab_size = kwargs.get('vocab_size', 11595)\n",
    "        self.teacher_forcing_rate = kwargs.get('teacher_forcing_rate', 0.0)\n",
    "        self.use_attention = kwargs.get('use_attention', True)\n",
    "        \n",
    "        # create tensorflow session to run computational graph in it\n",
    "        self.sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "        self.sess_config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=self.sess_config)\n",
    "        \n",
    "        self.init_graph()\n",
    "        \n",
    "        # define train op\n",
    "        self.train_op = self.get_train_op(self.loss, self.lr_ph,\n",
    "                                          optimizer=tf.train.AdamOptimizer,\n",
    "                                          clip_norm=self.grad_clip)\n",
    "        # initialize graph variables\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        # load saved model if there is one\n",
    "        if self.load_path is not None:\n",
    "            self.load()\n",
    "        \n",
    "    def init_graph(self):\n",
    "        # create placeholders\n",
    "        self.init_placeholders()\n",
    "\n",
    "        self.x_mask = tf.cast(self.x_ph, tf.int32) \n",
    "        self.y_mask = tf.cast(self.y_ph, tf.int32) \n",
    "        \n",
    "        self.x_len = tf.reduce_sum(self.x_mask, axis=1)\n",
    "        \n",
    "        # create embeddings matrix for tokens\n",
    "        self.embeddings = tf.Variable(tf.random_uniform((self.vocab_size, self.embeddings_dim), -0.1, 0.1, name='embeddings'), dtype=tf.float32)\n",
    "\n",
    "        encoder_outputs, encoder_state = encoder(self.x_ph, self.x_len, self.embeddings, self.cell_size, self.keep_prob_ph)\n",
    "\n",
    "        self.y_pred_tokens, y_logits = decoder(encoder_outputs, encoder_state, self.embeddings, self.x_mask,\n",
    "                                                      self.cell_size, self.max_length,\n",
    "                                                      self.y_ph, self.start_token_id, self.keep_prob_ph,\n",
    "                                                      self.teacher_forcing_rate_ph, self.use_attention, self.is_train_ph)\n",
    "        \n",
    "        # loss\n",
    "        self.y_ohe = tf.one_hot(self.y_ph, depth=self.vocab_size)\n",
    "        self.y_mask = tf.cast(self.y_mask, tf.float32)\n",
    "        self.loss = tf.nn.softmax_cross_entropy_with_logits(labels=self.y_ohe, logits=y_logits) * self.y_mask\n",
    "        self.loss = tf.reduce_sum(self.loss) / tf.reduce_sum(self.y_mask)\n",
    "    \n",
    "    def init_placeholders(self):\n",
    "        # placeholders for inputs\n",
    "        self.x_ph = tf.placeholder(shape=(None, None), dtype=tf.int32, name='x_ph')\n",
    "        \n",
    "        # y_ph is used node of computational graph at inference time when teacher forcing is activated, so we add dummy default value\n",
    "        # this dummy value is not actually used at inference\n",
    "        self.y_ph = tf.placeholder_with_default(tf.zeros_like(self.x_ph), shape=(None, None), name='y_ph')\n",
    "\n",
    "        # placeholders for model parameters\n",
    "        self.lr_ph = tf.placeholder(dtype=tf.float32, shape=[], name='lr_ph')\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name='keep_prob_ph')\n",
    "        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name='is_train_ph')\n",
    "        self.teacher_forcing_rate_ph = tf.placeholder_with_default(0.0, shape=[], name='teacher_forcing_rate_ph')\n",
    "            \n",
    "    def _build_feed_dict(self, x, y=None):\n",
    "        feed_dict = {\n",
    "            self.x_ph: x,\n",
    "        }\n",
    "        if y is not None:\n",
    "            feed_dict.update({\n",
    "                self.y_ph: y,\n",
    "                self.lr_ph: self.learning_rate,\n",
    "                self.keep_prob_ph: self.keep_prob,\n",
    "                self.is_train_ph: True,\n",
    "                self.teacher_forcing_rate_ph: self.teacher_forcing_rate,\n",
    "            })\n",
    "        return feed_dict\n",
    "    \n",
    "    def train_on_batch(self, x, y):\n",
    "        feed_dict = self._build_feed_dict(x, y)\n",
    "        loss, _ = self.sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n",
    "        return loss\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        feed_dict = self._build_feed_dict(x)\n",
    "        y_pred = self.sess.run(self.y_pred_tokens, feed_dict=feed_dict)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create model with random weights and default parameters, change path to model, otherwise it will be stored in deeppavlov/download folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s = Seq2Seq(\n",
    "    save_path='/Users/yaroina-kente/DeepPavlov/download/vocabs/model',\n",
    "    load_path='/Users/yaroina-kente/DeepPavlov/download/vocabs/model'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we firstly run all preprocessing steps and call seq2seq model, and then convert token indexes to tokens. As result we should get some random sequence of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['itunes',\n",
       "  'limit',\n",
       "  'trades',\n",
       "  'chats',\n",
       "  'fresh',\n",
       "  'hilton',\n",
       "  'cousins',\n",
       "  'cousins',\n",
       "  'can',\n",
       "  'precious',\n",
       "  'simpsons',\n",
       "  'eighth',\n",
       "  'eighth',\n",
       "  'cattle',\n",
       "  'watson',\n",
       "  'tank',\n",
       "  'seas',\n",
       "  'studio',\n",
       "  'hippy',\n",
       "  'whoops']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(s2s(padder(vocab([['hello', 'my', 'friend', 'there_is_no_such_word_in_dataset', 'and_this']]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention mechanism\n",
    "Attention mechanism [[paper](https://arxiv.org/abs/1409.0473)] allows to aggregate information from \"memory\" according to current state. By aggregating we suppose weighted sum of \"memory\" items. Weight of each memory item depends on current state. \n",
    "\n",
    "![attention](img/attention.png)\n",
    "\n",
    "One of the simpliest ways to compute attention weights (*a_ij*) is to compute them by dot product between memory items and state and then apply softmax function. Other ways of computing *multiplicative* attention could be found in this [paper](https://arxiv.org/abs/1508.04025).\n",
    "\n",
    "We also need a mask to skip some sequence elements like <PAD\\>. To make weight of undesired memory items close to zero we can add big negative value to logits (result of dot product) before applying softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_mask(values, mask):\n",
    "    # adds big negative to masked values\n",
    "    INF = 1e30\n",
    "    return -INF * (1 - tf.cast(mask, tf.float32)) + values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_attention(memory, state, mask, scope=\"dot_attention\"):\n",
    "    # inputs: bs x seq_len x hidden_dim\n",
    "    # state: bs x hidden_dim\n",
    "    # mask: bs x seq_len\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        # YOUR CODE HERE\n",
    "        # dot product between each item in memory and state\n",
    "        # logits = ...\n",
    "        BS, ML, MH = tf.unstack(tf.shape(memory))\n",
    "        memory_do = tf.nn.dropout(memory, keep_prob=1.0, noise_shape=[BS, 1, MH])\n",
    "        logits = tf.layers.dense(tf.layers.dense(memory_do, 100, activation=tf.nn.tanh), 1, use_bias=False)\n",
    "   \n",
    "        # apply mask to logits\n",
    "        # logits = softmax_mask(logits, mask)\n",
    "        \n",
    "        logits = softmax_mask(tf.squeeze(logits, [2]), mask)          \n",
    "        # apply softmax to logits\n",
    "        # att_weights = ...\n",
    "        att_weights = tf.expand_dims(tf.nn.softmax(logits), axis=2)\n",
    "                                                                                                                                                   \n",
    "        # compute weighted sum of items in memory\n",
    "        # att = tf.reduce_sum(...) \n",
    "        \n",
    "        att = tf.reduce_sum(att_weights * memory, axis=1)\n",
    "                                   \n",
    "        return att  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your implementation:\n",
    "\n",
    "outputs should be with shapes 32 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dot_attention/Sum:0' shape=(32, 100) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "memory = tf.random_normal(shape=[32, 10, 100]) # bs x seq_len x hidden_dim\n",
    "state = tf.random_normal(shape=[32, 100]) # bs x hidden_dim\n",
    "mask = tf.cast(tf.random_normal(shape=[32, 10]), tf.int32) # bs x seq_len\n",
    "dot_attention(memory, state, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teacher forcing\n",
    "\n",
    "We have implemented decoder, which takes as input it's own output during training and inference time. But, at early stages of training it could be hard for model to produce long sequences depending on it's own close to random output. Teacher forcing can help with this: instead of feeding model's output we can feed ground truth tokens. It helps model on training time, but on inference we still can rely only on it's own output.\n",
    "\n",
    "\n",
    "Using model's output:\n",
    "\n",
    "<img src=\"img/sampling.png\" alt=\"sampling\" width=50%/>\n",
    "\n",
    "Teacher forcing:\n",
    "\n",
    "<img src=\"img/teacher_forcing.png\" alt=\"teacher_forcing\" width=50%/>\n",
    "\n",
    "It is not necessary to feed ground truth tokens on each time step - we can randomly choose with some rate if we want ground truth input or predicted by model.\n",
    "*teacher_forcing_rate* parameter of seq2seq model can control such behavior.\n",
    "\n",
    "More details about teacher forcing could be found in DeepLearningBook [Chapter 10.2.1](http://www.deeplearningbook.org/contents/rnn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In postprocessing step we are going to remove all <PAD\\>, <BOS\\>, <EOS\\> tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register('postprocessing')\n",
    "class SentencePostprocessor(Component):\n",
    "    def __init__(self, pad_token='<PAD>', start_token='<BOS>', end_token='<EOS>', *args, **kwargs):\n",
    "        self.pad_token = pad_token\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        for i in range(len(batch)):\n",
    "            batch[i] = ' '.join(self._postproc(batch[i]))\n",
    "        return batch\n",
    "    \n",
    "    def _postproc(self, utt):\n",
    "        if self.end_token in utt:\n",
    "            utt = utt[:utt.index(self.end_token)]\n",
    "        return utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess = SentencePostprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['itunes limit trades chats fresh hilton cousins cousins can precious simpsons eighth eighth cattle watson tank seas studio hippy whoops']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocess(vocab(s2s(padder(vocab([['hello', 'my', 'friend', 'there_is_no_such_word_in_dataset', 'and_this']])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create config file\n",
    "Let's put is all together in one config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"dataset_reader\": {\n",
    "    \"name\": \"personachat_dataset_reader\",\n",
    "    \"data_path\": \"/Users/yaroina-kente/personachat/\" # change this path\n",
    "  },\n",
    "  \"dataset_iterator\": {\n",
    "    \"name\": \"personachat_iterator\",\n",
    "    \"seed\": 1337,\n",
    "    \"shuffle\": True\n",
    "  },\n",
    "  \"chainer\": {\n",
    "    \"in\": [\"x\"],\n",
    "    \"in_y\": [\"y\"],\n",
    "    \"pipe\": [\n",
    "      {\n",
    "        \"name\": \"lazy_tokenizer\",\n",
    "        \"id\": \"tokenizer\",\n",
    "        \"in\": [\"x\"],\n",
    "        \"out\": [\"x_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"lazy_tokenizer\",\n",
    "        \"id\": \"tokenizer\",\n",
    "        \"in\": [\"y\"],\n",
    "        \"out\": [\"y_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"dialog_vocab\",\n",
    "        \"id\": \"vocab\",\n",
    "        \"save_path\": \"/Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict\", # change this path\n",
    "        \"load_path\": \"/Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict\", # change this path\n",
    "        \"min_freq\": 2,\n",
    "        \"special_tokens\": [\"<PAD>\",\"<BOS>\", \"<EOS>\", \"<UNK>\"],\n",
    "        \"unk_token\": \"<UNK>\",\n",
    "        \"fit_on\": [\"x_tokens\", \"y_tokens\"],\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"out\": [\"x_tokens_ids\"]\n",
    "      },\n",
    "      {\n",
    "        \"ref\": \"vocab\",\n",
    "        \"in\": [\"y_tokens\"],\n",
    "        \"out\": [\"y_tokens_ids\"]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"sentence_padder\",\n",
    "        \"id\": \"padder\",\n",
    "        \"length_limit\": 20,\n",
    "        \"in\": [\"x_tokens_ids\"],\n",
    "        \"out\": [\"x_tokens_ids\"]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"sentence_padder\",\n",
    "        \"id\": \"y_padder\",\n",
    "        \"length_limit\": 10,\n",
    "        \"in\": [\"y_tokens_ids\"],\n",
    "        \"out\": [\"y_tokens_ids\"]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"seq2seq\",\n",
    "        \"id\": \"s2s\",\n",
    "        \"max_length\": \"#y_padder.length_limit+2\",\n",
    "        \"cell_size\": 250,\n",
    "        \"embeddings_dim\": 50,\n",
    "        \"vocab_size\": 11595,\n",
    "        \"keep_prob\": 0.8,\n",
    "        \"learning_rate\": 3e-04,\n",
    "        \"teacher_forcing_rate\": 0.2, # change this parameter to use teacher forcing\n",
    "        \"use_attention\": True, # change this parameter to use attention\n",
    "        \"save_path\": \"/Users/yaroina-kente/DeepPavlov/download/vocabs/model\", # change this path\n",
    "        \"load_path\": \"/Users/yaroina-kente/DeepPavlov/download/vocabs/model\", # change this path\n",
    "        \"in\": [\"x_tokens_ids\"],\n",
    "        \"in_y\": [\"y_tokens_ids\"],\n",
    "        \"out\": [\"y_predicted_tokens_ids\"],\n",
    "      },\n",
    "      {\n",
    "        \"ref\": \"vocab\",\n",
    "        \"in\": [\"y_predicted_tokens_ids\"],\n",
    "        \"out\": [\"y_predicted_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"postprocessing\",\n",
    "        \"in\": [\"y_predicted_tokens\"],\n",
    "        \"out\": [\"y_predicted_tokens\"]\n",
    "      }\n",
    "    ],\n",
    "    \"out\": [\"y_predicted_tokens\"]\n",
    "  },\n",
    "  \"train\": {\n",
    "    \"log_every_n_batches\": 100,\n",
    "    \"val_every_n_epochs\":0,\n",
    "    \"batch_size\": 64,\n",
    "    \"validation_patience\": 0,\n",
    "    \"epochs\": 20,\n",
    "    \"metrics\": [\"bleu\"],\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with model using config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 01:07:24.64 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 94: [loading vocabulary from /Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict]\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.commands.infer import build_model_from_config\n",
    "model = build_model_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fin fin es es canadian mail clark haven mermaid price price price',\n",
       " 'fin fin es es lifelong insta insta kool kool aggression aggression aggression']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['Hi, how are you?', 'Any ideas my dear friend?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiments with and without attention, with teacher forcing and without. Change config parameters if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.commands.train import train_evaluate_model_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(config, open('seq2seq.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yaroina-kente/personachat/train_self_original.txt\n",
      "/Users/yaroina-kente/personachat/valid_self_original.txt\n",
      "/Users/yaroina-kente/personachat/test_self_original.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 01:08:25.768 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 94: [loading vocabulary from /Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict]\n",
      "2018-07-11 01:09:01.76 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 83: [saving vocabulary to /Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict]\n",
      "/Users/yaroina-kente/deeppavlov-env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/yaroina-kente/deeppavlov-env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/yaroina-kente/deeppavlov-env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 100, \"examples_seen\": 6400, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:02:57\", \"loss\": 9.323235940933227}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 200, \"examples_seen\": 12800, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:05:58\", \"loss\": 9.223115634918212}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 300, \"examples_seen\": 19200, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:08:47\", \"loss\": 9.20089792251587}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 400, \"examples_seen\": 25600, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:11:30\", \"loss\": 9.208646421432496}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 500, \"examples_seen\": 32000, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:14:41\", \"loss\": 9.18961205482483}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 600, \"examples_seen\": 38400, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:18:06\", \"loss\": 9.210968952178956}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 700, \"examples_seen\": 44800, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:20:38\", \"loss\": 9.223729581832886}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 800, \"examples_seen\": 51200, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:23:03\", \"loss\": 9.209772109985352}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 900, \"examples_seen\": 57600, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:25:28\", \"loss\": 9.207072496414185}}\n",
      "{\"train\": {\"epochs_done\": 0, \"batches_seen\": 1000, \"examples_seen\": 64000, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:27:52\", \"loss\": 9.203881130218505}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1100, \"examples_seen\": 70391, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:30:16\", \"loss\": 9.09847661972046}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1200, \"examples_seen\": 76791, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:34:05\", \"loss\": 9.038146476745606}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1300, \"examples_seen\": 83191, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:36:34\", \"loss\": 9.026655750274658}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1400, \"examples_seen\": 89591, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:39:07\", \"loss\": 9.009532413482667}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1500, \"examples_seen\": 95991, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:41:38\", \"loss\": 9.02277219772339}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1600, \"examples_seen\": 102391, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:44:19\", \"loss\": 9.020556564331054}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1700, \"examples_seen\": 108791, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:46:54\", \"loss\": 9.021482429504395}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1800, \"examples_seen\": 115191, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:49:40\", \"loss\": 9.02883768081665}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 1900, \"examples_seen\": 121591, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:52:22\", \"loss\": 9.017003269195557}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 2000, \"examples_seen\": 127991, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:55:07\", \"loss\": 9.017666444778442}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2100, \"examples_seen\": 134382, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:57:54\", \"loss\": 8.95307523727417}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2200, \"examples_seen\": 140782, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:00:38\", \"loss\": 8.926977224349976}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2300, \"examples_seen\": 147182, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:03:18\", \"loss\": 8.919712295532227}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2400, \"examples_seen\": 153582, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:06:14\", \"loss\": 8.933180923461913}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2500, \"examples_seen\": 159982, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:09:06\", \"loss\": 8.926231479644775}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2600, \"examples_seen\": 166382, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:11:57\", \"loss\": 8.937515125274658}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2700, \"examples_seen\": 172782, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:14:33\", \"loss\": 8.933625192642213}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2800, \"examples_seen\": 179182, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:17:13\", \"loss\": 8.949534120559692}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 2900, \"examples_seen\": 185582, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:19:44\", \"loss\": 8.929429941177368}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 3000, \"examples_seen\": 191982, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:22:15\", \"loss\": 8.93186824798584}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3100, \"examples_seen\": 198373, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:24:48\", \"loss\": 8.922611265182494}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3200, \"examples_seen\": 204773, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:27:19\", \"loss\": 8.822256088256836}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3300, \"examples_seen\": 211173, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:30:09\", \"loss\": 8.836940107345582}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3400, \"examples_seen\": 217573, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:33:18\", \"loss\": 8.819535646438599}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3500, \"examples_seen\": 223973, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:36:27\", \"loss\": 8.859295635223388}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3600, \"examples_seen\": 230373, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:39:38\", \"loss\": 8.839831161499024}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3700, \"examples_seen\": 236773, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:42:15\", \"loss\": 8.843657360076904}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3800, \"examples_seen\": 243173, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:44:57\", \"loss\": 8.862129497528077}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 3900, \"examples_seen\": 249573, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:47:30\", \"loss\": 8.87404622077942}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 4000, \"examples_seen\": 255973, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:50:00\", \"loss\": 8.89517032623291}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 4100, \"examples_seen\": 262373, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:52:26\", \"loss\": 8.877525863647461}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 4200, \"examples_seen\": 268764, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:54:56\", \"loss\": 8.769452238082886}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 4300, \"examples_seen\": 275164, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"1:57:30\", \"loss\": 8.744235305786132}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 4400, \"examples_seen\": 281564, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:00:04\", \"loss\": 8.746169137954713}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 4500, \"examples_seen\": 287964, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:02:38\", \"loss\": 8.766605758666993}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 4600, \"examples_seen\": 294364, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:05:12\", \"loss\": 8.763456468582154}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 4700, \"examples_seen\": 300764, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:07:46\", \"loss\": 8.75873745918274}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 4800, \"examples_seen\": 307164, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:10:19\", \"loss\": 8.778625650405884}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 4900, \"examples_seen\": 313564, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:23:24\", \"loss\": 8.803223543167114}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 5000, \"examples_seen\": 319964, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:25:48\", \"loss\": 8.796702690124512}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 5100, \"examples_seen\": 326364, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:28:12\", \"loss\": 8.813693542480468}}\n",
      "{\"train\": {\"epochs_done\": 5, \"batches_seen\": 5200, \"examples_seen\": 332755, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:30:37\", \"loss\": 8.71240954399109}}\n",
      "{\"train\": {\"epochs_done\": 5, \"batches_seen\": 5300, \"examples_seen\": 339155, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:33:01\", \"loss\": 8.666679773330689}}\n",
      "{\"train\": {\"epochs_done\": 5, \"batches_seen\": 5400, \"examples_seen\": 345555, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"2:35:26\", \"loss\": 8.68321972846985}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 03:59:39.796 INFO in 'deeppavlov.core.commands.train'['train'] at line 367: Stopped training\n",
      "2018-07-11 03:59:39.798 INFO in 'deeppavlov.core.commands.train'['train'] at line 370: Saving model\n",
      "2018-07-11 03:59:39.800 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 49: [saving model to /Users/yaroina-kente/DeepPavlov/download/vocabs/model]\n",
      "2018-07-11 03:59:40.657 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 94: [loading vocabulary from /Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict]\n",
      "2018-07-11 03:59:47.595 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 40: [loading model from /Users/yaroina-kente/DeepPavlov/download/vocabs/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/yaroina-kente/DeepPavlov/download/vocabs/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 03:59:47.626 INFO in 'tensorflow'['tf_logging'] at line 116: Restoring parameters from /Users/yaroina-kente/DeepPavlov/download/vocabs/model\n",
      "2018-07-11 03:59:47.812 INFO in 'deeppavlov.core.commands.train'['train'] at line 174: Testing the best saved model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 7801, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:00:33\"}}\n",
      "{\"test\": {\"eval_examples_count\": 7512, \"metrics\": {\"bleu\": 0.0}, \"time_spent\": \"0:00:28\"}}\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_model_from_config('seq2seq.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 04:00:48.65 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 94: [loading vocabulary from /Users/yaroina-kente/DeepPavlov/download/vocabs/vocab.dict]\n",
      "2018-07-11 04:00:54.577 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 40: [loading model from /Users/yaroina-kente/DeepPavlov/download/vocabs/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/yaroina-kente/DeepPavlov/download/vocabs/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 04:00:54.600 INFO in 'tensorflow'['tf_logging'] at line 116: Restoring parameters from /Users/yaroina-kente/DeepPavlov/download/vocabs/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['oh oh am am am just . . .',\n",
       " 'oh oh am am like . . .',\n",
       " 'oh oh am am like just . . .',\n",
       " 'oh oh am am like mostly . . .']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model_from_config(config)\n",
    "model(['hi, how are you?', 'any ideas my dear friend?', 'okay, i agree with you', 'good bye!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeppavlov-env",
   "language": "python",
   "name": "deeppavlov-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
